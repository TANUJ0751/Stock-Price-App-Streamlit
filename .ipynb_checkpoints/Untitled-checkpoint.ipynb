{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e61db464-5580-482d-a984-f553ce0a122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump,load\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def fetch_data(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(period=\"max\")  # Fetch 5 years of data\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0817f7a2-988f-40ed-b25a-be8733531885",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list=pd.read_csv('nasdaq-listed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "421a56ca-0add-461d-a395-17c359f3d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data):\n",
    "    # Feature engineering: Create relevant columns\n",
    "    data['open-close'] = data['Open'] - data['Close']\n",
    "    data['high-low'] = data['High'] - data['Low']\n",
    "    data['price-change'] = data['Close'].pct_change()\n",
    "    data['is_quarter_end'] = np.where((data['Date'].dt.month % 3 == 0) & (data['Date'].dt.day > 23), 1, 0)\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['SMA_200'] = data['Close'].rolling(window=200).mean()\n",
    "    data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "    data['EMA_200'] = data['Close'].ewm(span=200, adjust=False).mean()\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['Dividends', 'Stock Splits'], axis=1, errors='ignore')\n",
    "    data.dropna(inplace=True)  # Handle missing values\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8653f251-024d-4212-b1a1-7ad24ae1abae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STOCK   Accuracy Symbol\n",
      "0    NaN  55.911330   AACG\n",
      "1    NaN  54.248366   AADI\n",
      "2    NaN  53.197674   AADR\n",
      "3    NaN  49.354839    AAL\n",
      "4    NaN  67.598017   AAME\n",
      "5    NaN  49.715370   AAOI\n",
      "6    NaN  52.986023   AAON\n",
      "7    NaN  51.851852   AAPB\n",
      "8    NaN  55.555556   AAPD\n",
      "9    NaN  50.527281   AAPL\n"
     ]
    }
   ],
   "source": [
    "accuracy_list=pd.read_csv(\"Accuracy_Data_NASDAQ.csv\")\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51fac55b-fd50-41b1-9597-3cc75a65a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABVX   31\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        15\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.38      0.50      0.43        20\n",
      "weighted avg       0.56      0.75      0.64        20\n",
      "\n",
      "Accuracy List Length : 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACAD   32\n",
      "Accuracy: 0.5406218655967904\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70       538\n",
      "           1       0.52      0.03      0.06       459\n",
      "\n",
      "    accuracy                           0.54       997\n",
      "   macro avg       0.53      0.50      0.38       997\n",
      "weighted avg       0.53      0.54      0.40       997\n",
      "\n",
      "Accuracy List Length : 39\n",
      "ACB   33\n",
      "Accuracy: 0.5564681724845996\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71       276\n",
      "           1       0.27      0.01      0.03       211\n",
      "\n",
      "    accuracy                           0.56       487\n",
      "   macro avg       0.42      0.49      0.37       487\n",
      "weighted avg       0.44      0.56      0.42       487\n",
      "\n",
      "Accuracy List Length : 40\n",
      "ACCD   34\n",
      "Accuracy: 0.5508021390374331\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69       102\n",
      "           1       0.53      0.11      0.18        85\n",
      "\n",
      "    accuracy                           0.55       187\n",
      "   macro avg       0.54      0.51      0.43       187\n",
      "weighted avg       0.54      0.55      0.46       187\n",
      "\n",
      "Accuracy List Length : 41\n",
      "ACDC   35\n",
      "Accuracy: 0.5376344086021505\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69        52\n",
      "           1       0.33      0.05      0.09        41\n",
      "\n",
      "    accuracy                           0.54        93\n",
      "   macro avg       0.44      0.49      0.39        93\n",
      "weighted avg       0.46      0.54      0.42        93\n",
      "\n",
      "Accuracy List Length : 42\n",
      "ACET   36\n",
      "Accuracy: 0.5372168284789643\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       163\n",
      "           1       0.58      0.08      0.13       146\n",
      "\n",
      "    accuracy                           0.54       309\n",
      "   macro avg       0.56      0.51      0.41       309\n",
      "weighted avg       0.56      0.54      0.42       309\n",
      "\n",
      "Accuracy List Length : 43\n",
      "ACGL   37\n",
      "Accuracy: 0.49477351916376305\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.93      0.64       695\n",
      "           1       0.57      0.08      0.14       740\n",
      "\n",
      "    accuracy                           0.49      1435\n",
      "   macro avg       0.53      0.51      0.39      1435\n",
      "weighted avg       0.53      0.49      0.39      1435\n",
      "\n",
      "Accuracy List Length : 44\n",
      "ACGLN   38\n",
      "Accuracy: 0.5428571428571428\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.89      0.68        76\n",
      "           1       0.50      0.12      0.20        64\n",
      "\n",
      "    accuracy                           0.54       140\n",
      "   macro avg       0.52      0.51      0.44       140\n",
      "weighted avg       0.53      0.54      0.46       140\n",
      "\n",
      "Accuracy List Length : 45\n",
      "ACGLO   39\n",
      "Accuracy: 0.4954682779456193\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.83      0.61       156\n",
      "           1       0.57      0.19      0.29       175\n",
      "\n",
      "    accuracy                           0.50       331\n",
      "   macro avg       0.52      0.51      0.45       331\n",
      "weighted avg       0.53      0.50      0.44       331\n",
      "\n",
      "Accuracy List Length : 46\n",
      "ACHC   40\n",
      "Accuracy: 0.582010582010582\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       880\n",
      "           1       0.50      0.01      0.02       632\n",
      "\n",
      "    accuracy                           0.58      1512\n",
      "   macro avg       0.54      0.50      0.38      1512\n",
      "weighted avg       0.55      0.58      0.44      1512\n",
      "\n",
      "Accuracy List Length : 47\n",
      "ACHL   41\n",
      "Accuracy: 0.610738255033557\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74        89\n",
      "           1       0.56      0.15      0.24        60\n",
      "\n",
      "    accuracy                           0.61       149\n",
      "   macro avg       0.59      0.54      0.49       149\n",
      "weighted avg       0.59      0.61      0.54       149\n",
      "\n",
      "Accuracy List Length : 48\n",
      "ACHV   42\n",
      "Accuracy: 0.5821104122990916\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.74       835\n",
      "           1       0.38      0.01      0.01       596\n",
      "\n",
      "    accuracy                           0.58      1431\n",
      "   macro avg       0.48      0.50      0.37      1431\n",
      "weighted avg       0.50      0.58      0.43      1431\n",
      "\n",
      "Accuracy List Length : 49\n",
      "ACIC   43\n",
      "Accuracy: 0.6561360874848117\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.78       541\n",
      "           1       0.49      0.10      0.16       282\n",
      "\n",
      "    accuracy                           0.66       823\n",
      "   macro avg       0.58      0.52      0.47       823\n",
      "weighted avg       0.61      0.66      0.57       823\n",
      "\n",
      "Accuracy List Length : 50\n",
      "ACIU   44\n",
      "Accuracy: 0.5186170212765957\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       200\n",
      "           1       0.33      0.03      0.05       176\n",
      "\n",
      "    accuracy                           0.52       376\n",
      "   macro avg       0.43      0.49      0.36       376\n",
      "weighted avg       0.44      0.52      0.38       376\n",
      "\n",
      "Accuracy List Length : 51\n",
      "ACIW   45\n",
      "Accuracy: 0.5023923444976076\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.10       728\n",
      "           1       0.50      0.94      0.66       735\n",
      "\n",
      "    accuracy                           0.50      1463\n",
      "   macro avg       0.50      0.50      0.38      1463\n",
      "weighted avg       0.50      0.50      0.38      1463\n",
      "\n",
      "Accuracy List Length : 52\n",
      "ACLS   46\n",
      "Accuracy: 0.5234899328859061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.94      0.67       616\n",
      "           1       0.55      0.08      0.14       576\n",
      "\n",
      "    accuracy                           0.52      1192\n",
      "   macro avg       0.53      0.51      0.41      1192\n",
      "weighted avg       0.53      0.52      0.41      1192\n",
      "\n",
      "Accuracy List Length : 53\n",
      "ACLX   47\n",
      "Accuracy: 0.41509433962264153\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.07      0.11        61\n",
      "           1       0.41      0.89      0.56        45\n",
      "\n",
      "    accuracy                           0.42       106\n",
      "   macro avg       0.43      0.48      0.34       106\n",
      "weighted avg       0.43      0.42      0.30       106\n",
      "\n",
      "Accuracy List Length : 54\n",
      "ACMR   48\n",
      "Accuracy: 0.528125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.91      0.67       172\n",
      "           1       0.45      0.09      0.15       148\n",
      "\n",
      "    accuracy                           0.53       320\n",
      "   macro avg       0.49      0.50      0.41       320\n",
      "weighted avg       0.50      0.53      0.43       320\n",
      "\n",
      "Accuracy List Length : 55\n",
      "ACNB   49\n",
      "Accuracy: 0.6339522546419099\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.99      0.77       947\n",
      "           1       0.65      0.04      0.07       561\n",
      "\n",
      "    accuracy                           0.63      1508\n",
      "   macro avg       0.64      0.51      0.42      1508\n",
      "weighted avg       0.64      0.63      0.51      1508\n",
      "\n",
      "Accuracy List Length : 56\n",
      "ACNT   50\n",
      "Accuracy: 0.598017124831005\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75      1326\n",
      "           1       0.53      0.01      0.02       893\n",
      "\n",
      "    accuracy                           0.60      2219\n",
      "   macro avg       0.57      0.50      0.38      2219\n",
      "weighted avg       0.57      0.60      0.45      2219\n",
      "\n",
      "Accuracy List Length : 57\n",
      "ACON   52\n",
      "Accuracy: 0.5416666666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70        52\n",
      "           1       0.50      0.02      0.04        44\n",
      "\n",
      "    accuracy                           0.54        96\n",
      "   macro avg       0.52      0.50      0.37        96\n",
      "weighted avg       0.52      0.54      0.40        96\n",
      "\n",
      "Accuracy List Length : 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ACONW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m stock\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStocks\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m=\u001b[39mfetch_data(stock)\n\u001b[1;32m----> 4\u001b[0m data\u001b[38;5;241m=\u001b[39mpreprocess_data(data)\n\u001b[0;32m      5\u001b[0m model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_dir):\n",
      "Cell \u001b[1;32mIn[56], line 6\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh-low\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice-change\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpct_change()\n\u001b[1;32m----> 6\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_quarter_end\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m23\u001b[39m), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMA_10\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      8\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMA_50\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:643\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 643\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "for index, row in stock_list.iloc[31:].iterrows():\n",
    "    stock=row['Stocks']\n",
    "    data=fetch_data(stock)\n",
    "    if not data.empty:\n",
    "        data=preprocess_data(data)\n",
    "        model_dir=f\"./models/{stock}/\"\n",
    "        if not os.path.exists(model_dir):\n",
    "                    os.mkdir(model_dir)\n",
    "        accuracy_list.to_csv(\"Accuracy_Data_NASDAQ.csv\",index=False)\n",
    "        # Define features (X) and target (y)\n",
    "        features = data[['open-close', 'high-low', 'Volume', 'is_quarter_end','SMA_10','SMA_50',\"SMA_200\",'EMA_10','EMA_50',\"EMA_200\"]]\n",
    "        target = np.where(data['Close'].shift(-1) > data['Close'], 1, 0)  # 1 foSr price increase, 0 otherwise\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # Initialize and train the model\n",
    "        model = SVC(kernel='poly', probability=True, random_state=42)  \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the scaler and model for reuse\n",
    "        \n",
    "        dump(scaler, f\"{model_dir}{stock}_scaler.joblib\")\n",
    "        dump(model, f\"{model_dir}{stock}_predictor.joblib\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        print(stock,\" \",index)\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        stock_accuracy=pd.DataFrame({\"Symbol\":[row['Stocks']],\"Accuracy\":[accuracy_score(y_test,y_pred)*100]})\n",
    "        accuracy_list=pd.concat([accuracy_list,stock_accuracy])\n",
    "        print(\"Accuracy List Length :\",len(accuracy_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bae035-00ac-4d50-8f0d-e2eadfec3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list.to_csv(\"Accuracy_Data_NASDAQ.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d531d-1620-4f00-9a1c-e1069a43b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
