{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61db464-5580-482d-a984-f553ce0a122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump,load\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def fetch_data(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(period=\"max\")  # Fetch 5 years of data\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0817f7a2-988f-40ed-b25a-be8733531885",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list=pd.read_csv('nasdaq-listed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421a56ca-0add-461d-a395-17c359f3d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data):\n",
    "    # Feature engineering: Create relevant columns\n",
    "    data['open-close'] = data['Open'] - data['Close']\n",
    "    data['high-low'] = data['High'] - data['Low']\n",
    "    data['price-change'] = data['Close'].pct_change()\n",
    "    data['is_quarter_end'] = np.where((data['Date'].dt.month % 3 == 0) & (data['Date'].dt.day > 23), 1, 0)\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['SMA_200'] = data['Close'].rolling(window=200).mean()\n",
    "    data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "    data['EMA_200'] = data['Close'].ewm(span=200, adjust=False).mean()\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['Dividends', 'Stock Splits'], axis=1, errors='ignore')\n",
    "    data.dropna(inplace=True)  # Handle missing values\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8653f251-024d-4212-b1a1-7ad24ae1abae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      STOCK   Accuracy Symbol\n",
      "0       NaN  55.911330   AACG\n",
      "1       NaN  54.248366   AADI\n",
      "2       NaN  53.197674   AADR\n",
      "3       NaN  49.354839    AAL\n",
      "4       NaN  67.598017   AAME\n",
      "...     ...        ...    ...\n",
      "1140    NaN  52.322738   EDIT\n",
      "1141    NaN  52.459016   EDOC\n",
      "1142    NaN  56.164384   EDRY\n",
      "1143    NaN  62.427746   EDSA\n",
      "1144    NaN  54.347826   EDTK\n",
      "\n",
      "[1145 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list=pd.read_csv(\"Accuracy_Data_NASDAQ.csv\")\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51fac55b-fd50-41b1-9597-3cc75a65a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINW   1569\n",
      "Accuracy: 0.5897435897435898\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72        73\n",
      "           1       0.38      0.14      0.20        44\n",
      "\n",
      "    accuracy                           0.59       117\n",
      "   macro avg       0.50      0.50      0.46       117\n",
      "weighted avg       0.53      0.59      0.53       117\n",
      "\n",
      "Accuracy List Length : 1362\n",
      "FINX   1570\n",
      "Accuracy: 0.5105820105820106\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.01      0.02       182\n",
      "           1       0.51      0.97      0.67       196\n",
      "\n",
      "    accuracy                           0.51       378\n",
      "   macro avg       0.40      0.49      0.35       378\n",
      "weighted avg       0.40      0.51      0.36       378\n",
      "\n",
      "Accuracy List Length : 1363\n",
      "FIP   1571\n",
      "Accuracy: 0.4642857142857143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.24      0.33        45\n",
      "           1       0.45      0.72      0.55        39\n",
      "\n",
      "    accuracy                           0.46        84\n",
      "   macro avg       0.48      0.48      0.44        84\n",
      "weighted avg       0.48      0.46      0.43        84\n",
      "\n",
      "Accuracy List Length : 1364\n",
      "FISI   1572\n",
      "Accuracy: 0.5269076305220883\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.94      0.68       650\n",
      "           1       0.54      0.07      0.13       595\n",
      "\n",
      "    accuracy                           0.53      1245\n",
      "   macro avg       0.53      0.51      0.40      1245\n",
      "weighted avg       0.53      0.53      0.41      1245\n",
      "\n",
      "Accuracy List Length : 1365\n",
      "FITB   1573\n",
      "Accuracy: 0.5218566922036953\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.94      0.68      1171\n",
      "           1       0.45      0.05      0.10      1048\n",
      "\n",
      "    accuracy                           0.52      2219\n",
      "   macro avg       0.49      0.50      0.39      2219\n",
      "weighted avg       0.49      0.52      0.40      2219\n",
      "\n",
      "Accuracy List Length : 1366\n",
      "FITBI   1574\n",
      "Accuracy: 0.4942084942084942\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.05      0.10       269\n",
      "           1       0.49      0.97      0.65       249\n",
      "\n",
      "    accuracy                           0.49       518\n",
      "   macro avg       0.58      0.51      0.37       518\n",
      "weighted avg       0.58      0.49      0.36       518\n",
      "\n",
      "Accuracy List Length : 1367\n",
      "FITBO   1575\n",
      "Accuracy: 0.4801762114537445\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.77      0.61       119\n",
      "           1       0.39      0.16      0.22       108\n",
      "\n",
      "    accuracy                           0.48       227\n",
      "   macro avg       0.44      0.47      0.42       227\n",
      "weighted avg       0.45      0.48      0.43       227\n",
      "\n",
      "Accuracy List Length : 1368\n",
      "FITBP   1576\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.88      0.62       107\n",
      "           1       0.62      0.17      0.27       123\n",
      "\n",
      "    accuracy                           0.50       230\n",
      "   macro avg       0.55      0.52      0.44       230\n",
      "weighted avg       0.55      0.50      0.43       230\n",
      "\n",
      "Accuracy List Length : 1369\n",
      "FIVE   1577\n",
      "Accuracy: 0.504258943781942\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.11      0.18       297\n",
      "           1       0.50      0.91      0.64       290\n",
      "\n",
      "    accuracy                           0.50       587\n",
      "   macro avg       0.53      0.51      0.41       587\n",
      "weighted avg       0.53      0.50      0.41       587\n",
      "\n",
      "Accuracy List Length : 1370\n",
      "FIVN   1578\n",
      "Accuracy: 0.49101796407185627\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.08      0.14       260\n",
      "           1       0.48      0.93      0.64       241\n",
      "\n",
      "    accuracy                           0.49       501\n",
      "   macro avg       0.53      0.51      0.39       501\n",
      "weighted avg       0.53      0.49      0.38       501\n",
      "\n",
      "Accuracy List Length : 1371\n",
      "FIXD   1579\n",
      "Accuracy: 0.5210084033613446\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.21      0.30       173\n",
      "           1       0.52      0.82      0.64       184\n",
      "\n",
      "    accuracy                           0.52       357\n",
      "   macro avg       0.52      0.51      0.47       357\n",
      "weighted avg       0.52      0.52      0.47       357\n",
      "\n",
      "Accuracy List Length : 1372\n",
      "FIZZ   1580\n",
      "Accuracy: 0.5457875457875457\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.68       905\n",
      "           1       0.47      0.12      0.19       733\n",
      "\n",
      "    accuracy                           0.55      1638\n",
      "   macro avg       0.51      0.51      0.44      1638\n",
      "weighted avg       0.52      0.55      0.46      1638\n",
      "\n",
      "Accuracy List Length : 1373\n",
      "FJP   1581\n",
      "Accuracy: 0.5161787365177196\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.19      0.29       326\n",
      "           1       0.51      0.84      0.63       323\n",
      "\n",
      "    accuracy                           0.52       649\n",
      "   macro avg       0.53      0.52      0.46       649\n",
      "weighted avg       0.53      0.52      0.46       649\n",
      "\n",
      "Accuracy List Length : 1374\n",
      "FKU   1582\n",
      "Accuracy: 0.5123558484349259\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.16      0.24       291\n",
      "           1       0.52      0.84      0.64       316\n",
      "\n",
      "    accuracy                           0.51       607\n",
      "   macro avg       0.50      0.50      0.44       607\n",
      "weighted avg       0.50      0.51      0.45       607\n",
      "\n",
      "Accuracy List Length : 1375\n",
      "FKWL   1583\n",
      "Accuracy: 0.6642771804062126\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       544\n",
      "           1       0.88      0.05      0.09       293\n",
      "\n",
      "    accuracy                           0.66       837\n",
      "   macro avg       0.77      0.52      0.44       837\n",
      "weighted avg       0.74      0.66      0.55       837\n",
      "\n",
      "Accuracy List Length : 1376\n",
      "FLD   1584\n",
      "Accuracy: 0.660377358490566\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.80        73\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.66       106\n",
      "   macro avg       0.34      0.48      0.40       106\n",
      "weighted avg       0.47      0.66      0.55       106\n",
      "\n",
      "Accuracy List Length : 1377\n",
      "FLDB   1585\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Accuracy List Length : 1378\n",
      "FLDDU   1586\n",
      "Accuracy: 0.7610619469026548\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86        85\n",
      "           1       1.00      0.04      0.07        28\n",
      "\n",
      "    accuracy                           0.76       113\n",
      "   macro avg       0.88      0.52      0.47       113\n",
      "weighted avg       0.82      0.76      0.67       113\n",
      "\n",
      "Accuracy List Length : 1379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FLDDW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLEX   1588\n",
      "Accuracy: 0.5129053606882858\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67       766\n",
      "           1       0.62      0.03      0.06       745\n",
      "\n",
      "    accuracy                           0.51      1511\n",
      "   macro avg       0.57      0.51      0.37      1511\n",
      "weighted avg       0.57      0.51      0.37      1511\n",
      "\n",
      "Accuracy List Length : 1380\n",
      "FLGC   1589\n",
      "Accuracy: 0.5555555555555556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71        82\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.56       144\n",
      "   macro avg       0.28      0.49      0.36       144\n",
      "weighted avg       0.32      0.56      0.41       144\n",
      "\n",
      "Accuracy List Length : 1381\n",
      "FLGT   1590\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.85      0.63       192\n",
      "           1       0.46      0.14      0.21       184\n",
      "\n",
      "    accuracy                           0.50       376\n",
      "   macro avg       0.48      0.49      0.42       376\n",
      "weighted avg       0.49      0.50      0.43       376\n",
      "\n",
      "Accuracy List Length : 1382\n",
      "FLIC   1591\n",
      "Accuracy: 0.6430096051227321\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78      1204\n",
      "           1       0.51      0.04      0.08       670\n",
      "\n",
      "    accuracy                           0.64      1874\n",
      "   macro avg       0.58      0.51      0.43      1874\n",
      "weighted avg       0.60      0.64      0.53      1874\n",
      "\n",
      "Accuracy List Length : 1383\n",
      "FLL   1592\n",
      "Accuracy: 0.6203763789746918\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       954\n",
      "           1       0.60      0.01      0.02       587\n",
      "\n",
      "    accuracy                           0.62      1541\n",
      "   macro avg       0.61      0.50      0.39      1541\n",
      "weighted avg       0.61      0.62      0.48      1541\n",
      "\n",
      "Accuracy List Length : 1384\n",
      "FLN   1593\n",
      "Accuracy: 0.5523076923076923\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.70       356\n",
      "           1       0.54      0.07      0.12       294\n",
      "\n",
      "    accuracy                           0.55       650\n",
      "   macro avg       0.55      0.51      0.41       650\n",
      "weighted avg       0.55      0.55      0.44       650\n",
      "\n",
      "Accuracy List Length : 1385\n",
      "FLNC   1594\n",
      "Accuracy: 0.55\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.89      0.67        62\n",
      "           1       0.61      0.19      0.29        58\n",
      "\n",
      "    accuracy                           0.55       120\n",
      "   macro avg       0.58      0.54      0.48       120\n",
      "weighted avg       0.57      0.55      0.49       120\n",
      "\n",
      "Accuracy List Length : 1386\n",
      "FLNT   1595\n",
      "Accuracy: 0.5826193390452876\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       475\n",
      "           1       0.57      0.01      0.02       342\n",
      "\n",
      "    accuracy                           0.58       817\n",
      "   macro avg       0.58      0.50      0.38       817\n",
      "weighted avg       0.58      0.58      0.44       817\n",
      "\n",
      "Accuracy List Length : 1387\n",
      "FLUX   1596\n",
      "Accuracy: 0.4972375690607735\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.65       102\n",
      "           1       0.23      0.06      0.10        79\n",
      "\n",
      "    accuracy                           0.50       181\n",
      "   macro avg       0.38      0.45      0.38       181\n",
      "weighted avg       0.40      0.50      0.41       181\n",
      "\n",
      "Accuracy List Length : 1388\n",
      "FLWS   1597\n",
      "Accuracy: 0.5048387096774194\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65       639\n",
      "           1       0.44      0.08      0.14       601\n",
      "\n",
      "    accuracy                           0.50      1240\n",
      "   macro avg       0.48      0.49      0.40      1240\n",
      "weighted avg       0.48      0.50      0.40      1240\n",
      "\n",
      "Accuracy List Length : 1389\n",
      "FLXS   1599\n",
      "Accuracy: 0.5935105903560163\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.74      1323\n",
      "           1       0.39      0.01      0.02       896\n",
      "\n",
      "    accuracy                           0.59      2219\n",
      "   macro avg       0.49      0.50      0.38      2219\n",
      "weighted avg       0.51      0.59      0.45      2219\n",
      "\n",
      "Accuracy List Length : 1390\n",
      "FLYW   1601\n",
      "Accuracy: 0.5070422535211268\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.23      0.34        79\n",
      "           1       0.47      0.86      0.61        63\n",
      "\n",
      "    accuracy                           0.51       142\n",
      "   macro avg       0.57      0.54      0.47       142\n",
      "weighted avg       0.58      0.51      0.46       142\n",
      "\n",
      "Accuracy List Length : 1391\n",
      "FMAO   1602\n",
      "Accuracy: 0.6725082146768894\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80       612\n",
      "           1       0.53      0.05      0.10       301\n",
      "\n",
      "    accuracy                           0.67       913\n",
      "   macro avg       0.61      0.52      0.45       913\n",
      "weighted avg       0.63      0.67      0.57       913\n",
      "\n",
      "Accuracy List Length : 1392\n",
      "FMB   1603\n",
      "Accuracy: 0.5423387096774194\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.12      0.20       238\n",
      "           1       0.53      0.93      0.68       258\n",
      "\n",
      "    accuracy                           0.54       496\n",
      "   macro avg       0.58      0.53      0.44       496\n",
      "weighted avg       0.58      0.54      0.45       496\n",
      "\n",
      "Accuracy List Length : 1393\n",
      "FMBH   1604\n",
      "Accuracy: 0.7315329626687848\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84       921\n",
      "           1       0.50      0.04      0.08       338\n",
      "\n",
      "    accuracy                           0.73      1259\n",
      "   macro avg       0.62      0.51      0.46      1259\n",
      "weighted avg       0.67      0.73      0.64      1259\n",
      "\n",
      "Accuracy List Length : 1394\n",
      "FMED   1605\n",
      "Accuracy: 0.6410256410256411\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.43      0.56        21\n",
      "           1       0.57      0.89      0.70        18\n",
      "\n",
      "    accuracy                           0.64        39\n",
      "   macro avg       0.69      0.66      0.63        39\n",
      "weighted avg       0.70      0.64      0.62        39\n",
      "\n",
      "Accuracy List Length : 1395\n",
      "FMET   1606\n",
      "Accuracy: 0.4895833333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.31      0.35        42\n",
      "           1       0.54      0.63      0.58        54\n",
      "\n",
      "    accuracy                           0.49        96\n",
      "   macro avg       0.47      0.47      0.46        96\n",
      "weighted avg       0.48      0.49      0.48        96\n",
      "\n",
      "Accuracy List Length : 1396\n",
      "FMHI   1607\n",
      "Accuracy: 0.5825545171339563\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.15      0.25       145\n",
      "           1       0.57      0.94      0.71       176\n",
      "\n",
      "    accuracy                           0.58       321\n",
      "   macro avg       0.62      0.54      0.48       321\n",
      "weighted avg       0.62      0.58      0.50       321\n",
      "\n",
      "Accuracy List Length : 1397\n",
      "FMNB   1608\n",
      "Accuracy: 0.6154452324665091\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       767\n",
      "           1       0.64      0.06      0.12       502\n",
      "\n",
      "    accuracy                           0.62      1269\n",
      "   macro avg       0.63      0.52      0.44      1269\n",
      "weighted avg       0.62      0.62      0.50      1269\n",
      "\n",
      "Accuracy List Length : 1398\n",
      "FMST   1609\n",
      "Accuracy: 0.56\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.70        14\n",
      "           1       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.56        25\n",
      "   macro avg       0.53      0.51      0.43        25\n",
      "weighted avg       0.54      0.56      0.46        25\n",
      "\n",
      "Accuracy List Length : 1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FMSTW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNGR   1611\n",
      "Accuracy: 0.6077844311377245\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       200\n",
      "           1       0.67      0.04      0.08       134\n",
      "\n",
      "    accuracy                           0.61       334\n",
      "   macro avg       0.64      0.51      0.42       334\n",
      "weighted avg       0.63      0.61      0.48       334\n",
      "\n",
      "Accuracy List Length : 1400\n",
      "FNK   1612\n",
      "Accuracy: 0.46615384615384614\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.04      0.07       335\n",
      "           1       0.47      0.92      0.62       315\n",
      "\n",
      "    accuracy                           0.47       650\n",
      "   macro avg       0.41      0.48      0.35       650\n",
      "weighted avg       0.41      0.47      0.34       650\n",
      "\n",
      "Accuracy List Length : 1401\n",
      "FNKO   1613\n",
      "Accuracy: 0.4735202492211838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.26      0.34       168\n",
      "           1       0.47      0.71      0.56       153\n",
      "\n",
      "    accuracy                           0.47       321\n",
      "   macro avg       0.48      0.48      0.45       321\n",
      "weighted avg       0.48      0.47      0.45       321\n",
      "\n",
      "Accuracy List Length : 1402\n",
      "FNLC   1614\n",
      "Accuracy: 0.5491143317230274\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.94      0.69       681\n",
      "           1       0.51      0.08      0.14       561\n",
      "\n",
      "    accuracy                           0.55      1242\n",
      "   macro avg       0.53      0.51      0.42      1242\n",
      "weighted avg       0.53      0.55      0.44      1242\n",
      "\n",
      "Accuracy List Length : 1403\n",
      "FNWB   1615\n",
      "Accuracy: 0.48695652173913045\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.89      0.63       227\n",
      "           1       0.47      0.09      0.16       233\n",
      "\n",
      "    accuracy                           0.49       460\n",
      "   macro avg       0.48      0.49      0.39       460\n",
      "weighted avg       0.48      0.49      0.39       460\n",
      "\n",
      "Accuracy List Length : 1404\n",
      "FNWD   1616\n",
      "Accuracy: 0.8046153846153846\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89      1048\n",
      "           1       0.25      0.00      0.01       252\n",
      "\n",
      "    accuracy                           0.80      1300\n",
      "   macro avg       0.53      0.50      0.45      1300\n",
      "weighted avg       0.70      0.80      0.72      1300\n",
      "\n",
      "Accuracy List Length : 1405\n",
      "FNX   1617\n",
      "Accuracy: 0.5288574793875147\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.05      0.08       386\n",
      "           1       0.54      0.93      0.68       463\n",
      "\n",
      "    accuracy                           0.53       849\n",
      "   macro avg       0.45      0.49      0.38       849\n",
      "weighted avg       0.46      0.53      0.41       849\n",
      "\n",
      "Accuracy List Length : 1406\n",
      "FNY   1618\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.01      0.01       318\n",
      "           1       0.51      0.97      0.67       332\n",
      "\n",
      "    accuracy                           0.50       650\n",
      "   macro avg       0.34      0.49      0.34       650\n",
      "weighted avg       0.35      0.50      0.35       650\n",
      "\n",
      "Accuracy List Length : 1407\n",
      "FOLD   1619\n",
      "Accuracy: 0.4787234042553192\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.91      0.63       416\n",
      "           1       0.42      0.06      0.11       430\n",
      "\n",
      "    accuracy                           0.48       846\n",
      "   macro avg       0.45      0.49      0.37       846\n",
      "weighted avg       0.45      0.48      0.37       846\n",
      "\n",
      "Accuracy List Length : 1408\n",
      "FONR   1620\n",
      "Accuracy: 0.6102012166588676\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76      1307\n",
      "           1       0.00      0.00      0.00       830\n",
      "\n",
      "    accuracy                           0.61      2137\n",
      "   macro avg       0.31      0.50      0.38      2137\n",
      "weighted avg       0.37      0.61      0.46      2137\n",
      "\n",
      "Accuracy List Length : 1409\n",
      "FORA   1621\n",
      "Accuracy: 0.6038961038961039\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.91      0.74        95\n",
      "           1       0.44      0.12      0.19        59\n",
      "\n",
      "    accuracy                           0.60       154\n",
      "   macro avg       0.53      0.51      0.46       154\n",
      "weighted avg       0.55      0.60      0.53       154\n",
      "\n",
      "Accuracy List Length : 1410\n",
      "FORD   1622\n",
      "Accuracy: 0.5693974272173324\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72       848\n",
      "           1       0.35      0.01      0.02       629\n",
      "\n",
      "    accuracy                           0.57      1477\n",
      "   macro avg       0.46      0.50      0.37      1477\n",
      "weighted avg       0.48      0.57      0.43      1477\n",
      "\n",
      "Accuracy List Length : 1411\n",
      "FORL   1623\n",
      "Accuracy: 0.7441860465116279\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85        34\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.39      0.47      0.43        43\n",
      "weighted avg       0.62      0.74      0.67        43\n",
      "\n",
      "Accuracy List Length : 1412\n",
      "FORLU   1624\n",
      "Accuracy: 0.9215686274509803\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        48\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.92        51\n",
      "   macro avg       0.47      0.49      0.48        51\n",
      "weighted avg       0.88      0.92      0.90        51\n",
      "\n",
      "Accuracy List Length : 1413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FORLW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORM   1626\n",
      "Accuracy: 0.5047801147227533\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66       537\n",
      "           1       0.43      0.05      0.09       509\n",
      "\n",
      "    accuracy                           0.50      1046\n",
      "   macro avg       0.47      0.49      0.38      1046\n",
      "weighted avg       0.47      0.50      0.38      1046\n",
      "\n",
      "Accuracy List Length : 1414\n",
      "FORR   1627\n",
      "Accuracy: 0.5094614264919942\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.91      0.65       686\n",
      "           1       0.55      0.11      0.18       688\n",
      "\n",
      "    accuracy                           0.51      1374\n",
      "   macro avg       0.53      0.51      0.42      1374\n",
      "weighted avg       0.53      0.51      0.42      1374\n",
      "\n",
      "Accuracy List Length : 1415\n",
      "FORTY   1628\n",
      "Accuracy: 0.6267870579382995\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77       838\n",
      "           1       0.42      0.03      0.05       491\n",
      "\n",
      "    accuracy                           0.63      1329\n",
      "   macro avg       0.53      0.50      0.41      1329\n",
      "weighted avg       0.55      0.63      0.50      1329\n",
      "\n",
      "Accuracy List Length : 1416\n",
      "FOSL   1629\n",
      "Accuracy: 0.5317511225144324\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.69       833\n",
      "           1       0.46      0.03      0.06       726\n",
      "\n",
      "    accuracy                           0.53      1559\n",
      "   macro avg       0.50      0.50      0.37      1559\n",
      "weighted avg       0.50      0.53      0.40      1559\n",
      "\n",
      "Accuracy List Length : 1417\n",
      "FOSLL   1630\n",
      "Accuracy: 0.5630252100840336\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.91      0.70        66\n",
      "           1       0.54      0.13      0.21        53\n",
      "\n",
      "    accuracy                           0.56       119\n",
      "   macro avg       0.55      0.52      0.45       119\n",
      "weighted avg       0.55      0.56      0.48       119\n",
      "\n",
      "Accuracy List Length : 1418\n",
      "FOX   1631\n",
      "Accuracy: 0.45849802371541504\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.29      0.35       129\n",
      "           1       0.46      0.64      0.54       124\n",
      "\n",
      "    accuracy                           0.46       253\n",
      "   macro avg       0.46      0.46      0.44       253\n",
      "weighted avg       0.46      0.46      0.44       253\n",
      "\n",
      "Accuracy List Length : 1419\n",
      "FOXA   1632\n",
      "Accuracy: 0.45454545454545453\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.19      0.26       125\n",
      "           1       0.47      0.71      0.57       128\n",
      "\n",
      "    accuracy                           0.45       253\n",
      "   macro avg       0.43      0.45      0.41       253\n",
      "weighted avg       0.43      0.45      0.42       253\n",
      "\n",
      "Accuracy List Length : 1420\n",
      "FOXF   1633\n",
      "Accuracy: 0.4681647940074906\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.92      0.62       248\n",
      "           1       0.52      0.08      0.13       286\n",
      "\n",
      "    accuracy                           0.47       534\n",
      "   macro avg       0.49      0.50      0.38       534\n",
      "weighted avg       0.50      0.47      0.36       534\n",
      "\n",
      "Accuracy List Length : 1421\n",
      "FOXX   1634\n",
      "Accuracy: 0.7407407407407407\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.97      0.84        59\n",
      "           1       0.60      0.14      0.22        22\n",
      "\n",
      "    accuracy                           0.74        81\n",
      "   macro avg       0.68      0.55      0.53        81\n",
      "weighted avg       0.71      0.74      0.68        81\n",
      "\n",
      "Accuracy List Length : 1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FOXXW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPA   1636\n",
      "Accuracy: 0.5584615384615385\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       367\n",
      "           1       0.45      0.06      0.11       283\n",
      "\n",
      "    accuracy                           0.56       650\n",
      "   macro avg       0.51      0.50      0.41       650\n",
      "weighted avg       0.52      0.56      0.45       650\n",
      "\n",
      "Accuracy List Length : 1423\n",
      "FPAY   1637\n",
      "Accuracy: 0.7183499288762447\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.99      0.83       505\n",
      "           1       0.50      0.03      0.05       198\n",
      "\n",
      "    accuracy                           0.72       703\n",
      "   macro avg       0.61      0.51      0.44       703\n",
      "weighted avg       0.66      0.72      0.61       703\n",
      "\n",
      "Accuracy List Length : 1424\n",
      "FPXE   1638\n",
      "Accuracy: 0.5384615384615384\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.68       153\n",
      "           1       0.39      0.09      0.15       120\n",
      "\n",
      "    accuracy                           0.54       273\n",
      "   macro avg       0.47      0.49      0.42       273\n",
      "weighted avg       0.48      0.54      0.45       273\n",
      "\n",
      "Accuracy List Length : 1425\n",
      "FPXI   1639\n",
      "Accuracy: 0.5668789808917197\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.10      0.16       206\n",
      "           1       0.57      0.93      0.71       265\n",
      "\n",
      "    accuracy                           0.57       471\n",
      "   macro avg       0.55      0.51      0.44       471\n",
      "weighted avg       0.55      0.57      0.47       471\n",
      "\n",
      "Accuracy List Length : 1426\n",
      "FRAF   1640\n",
      "Accuracy: 0.6790450928381963\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81      1021\n",
      "           1       0.62      0.02      0.03       487\n",
      "\n",
      "    accuracy                           0.68      1508\n",
      "   macro avg       0.65      0.51      0.42      1508\n",
      "weighted avg       0.66      0.68      0.56      1508\n",
      "\n",
      "Accuracy List Length : 1427\n",
      "FRBA   1641\n",
      "Accuracy: 0.5517751479289941\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.70       376\n",
      "           1       0.44      0.04      0.07       300\n",
      "\n",
      "    accuracy                           0.55       676\n",
      "   macro avg       0.50      0.50      0.39       676\n",
      "weighted avg       0.50      0.55      0.42       676\n",
      "\n",
      "Accuracy List Length : 1428\n",
      "FRES   1642\n",
      "Accuracy: 0.5432692307692307\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.69       114\n",
      "           1       0.45      0.05      0.10        94\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.50      0.50      0.39       208\n",
      "weighted avg       0.51      0.54      0.42       208\n",
      "\n",
      "Accuracy List Length : 1429\n",
      "FRGT   1643\n",
      "Accuracy: 0.5915915915915916\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.74       200\n",
      "           1       0.20      0.01      0.01       133\n",
      "\n",
      "    accuracy                           0.59       333\n",
      "   macro avg       0.40      0.49      0.38       333\n",
      "weighted avg       0.44      0.59      0.45       333\n",
      "\n",
      "Accuracy List Length : 1430\n",
      "FRHC   1644\n",
      "Accuracy: 0.4675324675324675\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.02      0.04       154\n",
      "           1       0.48      0.92      0.63       154\n",
      "\n",
      "    accuracy                           0.47       308\n",
      "   macro avg       0.34      0.47      0.33       308\n",
      "weighted avg       0.34      0.47      0.33       308\n",
      "\n",
      "Accuracy List Length : 1431\n",
      "FRME   1645\n",
      "Accuracy: 0.5545402627070246\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       973\n",
      "           1       0.47      0.02      0.04       778\n",
      "\n",
      "    accuracy                           0.55      1751\n",
      "   macro avg       0.51      0.50      0.37      1751\n",
      "weighted avg       0.52      0.55      0.41      1751\n",
      "\n",
      "Accuracy List Length : 1432\n",
      "FRMEP   1646\n",
      "Accuracy: 0.6353591160220995\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77       115\n",
      "           1       0.50      0.03      0.06        66\n",
      "\n",
      "    accuracy                           0.64       181\n",
      "   macro avg       0.57      0.51      0.42       181\n",
      "weighted avg       0.59      0.64      0.51       181\n",
      "\n",
      "Accuracy List Length : 1433\n",
      "FROG   1647\n",
      "Accuracy: 0.536723163841808\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.93      0.68        95\n",
      "           1       0.50      0.09      0.15        82\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.52      0.51      0.41       177\n",
      "weighted avg       0.52      0.54      0.43       177\n",
      "\n",
      "Accuracy List Length : 1434\n",
      "FRPH   1648\n",
      "Accuracy: 0.6549184639663335\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.94      0.78      1255\n",
      "           1       0.46      0.10      0.16       646\n",
      "\n",
      "    accuracy                           0.65      1901\n",
      "   macro avg       0.57      0.52      0.47      1901\n",
      "weighted avg       0.60      0.65      0.57      1901\n",
      "\n",
      "Accuracy List Length : 1435\n",
      "FRPT   1649\n",
      "Accuracy: 0.554140127388535\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.11      0.19       209\n",
      "           1       0.56      0.90      0.69       262\n",
      "\n",
      "    accuracy                           0.55       471\n",
      "   macro avg       0.53      0.51      0.44       471\n",
      "weighted avg       0.53      0.55      0.47       471\n",
      "\n",
      "Accuracy List Length : 1436\n",
      "FRSH   1650\n",
      "Accuracy: 0.488\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.77      0.57        56\n",
      "           1       0.58      0.26      0.36        69\n",
      "\n",
      "    accuracy                           0.49       125\n",
      "   macro avg       0.52      0.51      0.47       125\n",
      "weighted avg       0.53      0.49      0.46       125\n",
      "\n",
      "Accuracy List Length : 1437\n",
      "FRST   1651\n",
      "Accuracy: 0.5565714285714286\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71       488\n",
      "           1       0.48      0.03      0.06       387\n",
      "\n",
      "    accuracy                           0.56       875\n",
      "   macro avg       0.52      0.50      0.38       875\n",
      "weighted avg       0.52      0.56      0.42       875\n",
      "\n",
      "Accuracy List Length : 1438\n",
      "FRSX   1652\n",
      "Accuracy: 0.6029411764705882\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       207\n",
      "           1       0.33      0.02      0.03       133\n",
      "\n",
      "    accuracy                           0.60       340\n",
      "   macro avg       0.47      0.50      0.39       340\n",
      "weighted avg       0.50      0.60      0.47       340\n",
      "\n",
      "Accuracy List Length : 1439\n",
      "FSBC   1653\n",
      "Accuracy: 0.4896551724137931\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.42      0.47        78\n",
      "           1       0.46      0.57      0.51        67\n",
      "\n",
      "    accuracy                           0.49       145\n",
      "   macro avg       0.50      0.50      0.49       145\n",
      "weighted avg       0.50      0.49      0.49       145\n",
      "\n",
      "Accuracy List Length : 1440\n",
      "FSBW   1654\n",
      "Accuracy: 0.5365025466893039\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.93      0.68       306\n",
      "           1       0.60      0.11      0.19       283\n",
      "\n",
      "    accuracy                           0.54       589\n",
      "   macro avg       0.56      0.52      0.43       589\n",
      "weighted avg       0.56      0.54      0.44       589\n",
      "\n",
      "Accuracy List Length : 1441\n",
      "FSCS   1655\n",
      "Accuracy: 0.4896755162241888\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.03      0.05       166\n",
      "           1       0.50      0.93      0.65       173\n",
      "\n",
      "    accuracy                           0.49       339\n",
      "   macro avg       0.40      0.48      0.35       339\n",
      "weighted avg       0.40      0.49      0.36       339\n",
      "\n",
      "Accuracy List Length : 1442\n",
      "FSEA   1656\n",
      "Accuracy: 0.652542372881356\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.79       153\n",
      "           1       0.67      0.02      0.05        83\n",
      "\n",
      "    accuracy                           0.65       236\n",
      "   macro avg       0.66      0.51      0.42       236\n",
      "weighted avg       0.66      0.65      0.53       236\n",
      "\n",
      "Accuracy List Length : 1443\n",
      "FSFG   1657\n",
      "Accuracy: 0.6066838046272494\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.96      0.75       471\n",
      "           1       0.51      0.06      0.11       307\n",
      "\n",
      "    accuracy                           0.61       778\n",
      "   macro avg       0.56      0.51      0.43       778\n",
      "weighted avg       0.57      0.61      0.50       778\n",
      "\n",
      "Accuracy List Length : 1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FSHPR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSLR   1661\n",
      "Accuracy: 0.4610091743119266\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.07      0.13       477\n",
      "           1       0.45      0.93      0.61       395\n",
      "\n",
      "    accuracy                           0.46       872\n",
      "   macro avg       0.51      0.50      0.37       872\n",
      "weighted avg       0.51      0.46      0.35       872\n",
      "\n",
      "Accuracy List Length : 1445\n",
      "FSTR   1662\n",
      "Accuracy: 0.5989800649049606\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.95      0.74      1300\n",
      "           1       0.47      0.07      0.12       857\n",
      "\n",
      "    accuracy                           0.60      2157\n",
      "   macro avg       0.54      0.51      0.43      2157\n",
      "weighted avg       0.55      0.60      0.49      2157\n",
      "\n",
      "Accuracy List Length : 1446\n",
      "FSUN   1663\n",
      "Accuracy: 0.6585365853658537\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.79        56\n",
      "           1       0.33      0.08      0.12        26\n",
      "\n",
      "    accuracy                           0.66        82\n",
      "   macro avg       0.51      0.50      0.46        82\n",
      "weighted avg       0.57      0.66      0.58        82\n",
      "\n",
      "Accuracy List Length : 1447\n",
      "FSV   1664\n",
      "Accuracy: 0.5530474040632054\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.05      0.09       193\n",
      "           1       0.56      0.94      0.70       250\n",
      "\n",
      "    accuracy                           0.55       443\n",
      "   macro avg       0.48      0.50      0.40       443\n",
      "weighted avg       0.49      0.55      0.44       443\n",
      "\n",
      "Accuracy List Length : 1448\n",
      "FSZ   1665\n",
      "Accuracy: 0.48519736842105265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.03      0.06       303\n",
      "           1       0.49      0.93      0.65       305\n",
      "\n",
      "    accuracy                           0.49       608\n",
      "   macro avg       0.41      0.48      0.35       608\n",
      "weighted avg       0.41      0.49      0.35       608\n",
      "\n",
      "Accuracy List Length : 1449\n",
      "FTA   1666\n",
      "Accuracy: 0.5324675324675324\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.02      0.04       394\n",
      "           1       0.53      0.98      0.69       453\n",
      "\n",
      "    accuracy                           0.53       847\n",
      "   macro avg       0.49      0.50      0.37       847\n",
      "weighted avg       0.50      0.53      0.39       847\n",
      "\n",
      "Accuracy List Length : 1450\n",
      "FTAG   1667\n",
      "Accuracy: 0.5561877667140825\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71       394\n",
      "           1       0.44      0.04      0.07       309\n",
      "\n",
      "    accuracy                           0.56       703\n",
      "   macro avg       0.50      0.50      0.39       703\n",
      "weighted avg       0.51      0.56      0.43       703\n",
      "\n",
      "Accuracy List Length : 1451\n",
      "FTAI   1668\n",
      "Accuracy: 0.5246636771300448\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.03      0.05       214\n",
      "           1       0.52      0.98      0.68       232\n",
      "\n",
      "    accuracy                           0.52       446\n",
      "   macro avg       0.56      0.51      0.37       446\n",
      "weighted avg       0.56      0.52      0.38       446\n",
      "\n",
      "Accuracy List Length : 1452\n",
      "FTAIM   1669\n",
      "Accuracy: 0.5192307692307693\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.12      0.19        24\n",
      "           1       0.53      0.86      0.66        28\n",
      "\n",
      "    accuracy                           0.52        52\n",
      "   macro avg       0.48      0.49      0.43        52\n",
      "weighted avg       0.48      0.52      0.44        52\n",
      "\n",
      "Accuracy List Length : 1453\n",
      "FTAIN   1670\n",
      "Accuracy: 0.5099337748344371\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.17      0.26        75\n",
      "           1       0.51      0.84      0.63        76\n",
      "\n",
      "    accuracy                           0.51       151\n",
      "   macro avg       0.51      0.51      0.45       151\n",
      "weighted avg       0.51      0.51      0.45       151\n",
      "\n",
      "Accuracy List Length : 1454\n",
      "FTAIO   1671\n",
      "Accuracy: 0.5069124423963134\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.88      0.65       111\n",
      "           1       0.48      0.11      0.18       106\n",
      "\n",
      "    accuracy                           0.51       217\n",
      "   macro avg       0.50      0.50      0.42       217\n",
      "weighted avg       0.50      0.51      0.42       217\n",
      "\n",
      "Accuracy List Length : 1455\n",
      "FTC   1672\n",
      "Accuracy: 0.49705535924617195\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.01      0.02       429\n",
      "           1       0.50      0.99      0.66       420\n",
      "\n",
      "    accuracy                           0.50       849\n",
      "   macro avg       0.56      0.50      0.34       849\n",
      "weighted avg       0.56      0.50      0.34       849\n",
      "\n",
      "Accuracy List Length : 1456\n",
      "FTCI   1673\n",
      "Accuracy: 0.547945205479452\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.93      0.68        76\n",
      "           1       0.64      0.13      0.21        70\n",
      "\n",
      "    accuracy                           0.55       146\n",
      "   macro avg       0.59      0.53      0.45       146\n",
      "weighted avg       0.59      0.55      0.46       146\n",
      "\n",
      "Accuracy List Length : 1457\n",
      "FTCS   1674\n",
      "Accuracy: 0.5409652076318743\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.01      0.01       410\n",
      "           1       0.54      1.00      0.70       481\n",
      "\n",
      "    accuracy                           0.54       891\n",
      "   macro avg       0.57      0.50      0.36       891\n",
      "weighted avg       0.57      0.54      0.38       891\n",
      "\n",
      "Accuracy List Length : 1458\n",
      "FTDR   1675\n",
      "Accuracy: 0.5035971223021583\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.11      0.18       142\n",
      "           1       0.50      0.92      0.64       136\n",
      "\n",
      "    accuracy                           0.50       278\n",
      "   macro avg       0.54      0.51      0.41       278\n",
      "weighted avg       0.54      0.50      0.41       278\n",
      "\n",
      "Accuracy List Length : 1459\n",
      "FTDS   1676\n",
      "Accuracy: 0.5377969762419006\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69       253\n",
      "           1       0.44      0.08      0.13       210\n",
      "\n",
      "    accuracy                           0.54       463\n",
      "   macro avg       0.50      0.50      0.41       463\n",
      "weighted avg       0.50      0.54      0.43       463\n",
      "\n",
      "Accuracy List Length : 1460\n",
      "FTEK   1677\n",
      "Accuracy: 0.548114434330299\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       842\n",
      "           1       0.55      0.01      0.02       696\n",
      "\n",
      "    accuracy                           0.55      1538\n",
      "   macro avg       0.55      0.50      0.36      1538\n",
      "weighted avg       0.55      0.55      0.39      1538\n",
      "\n",
      "Accuracy List Length : 1461\n",
      "FTEL   1678\n",
      "Accuracy: 0.4666666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.19      0.27        16\n",
      "           1       0.46      0.79      0.58        14\n",
      "\n",
      "    accuracy                           0.47        30\n",
      "   macro avg       0.48      0.49      0.43        30\n",
      "weighted avg       0.48      0.47      0.42        30\n",
      "\n",
      "Accuracy List Length : 1462\n",
      "FTFT   1679\n",
      "Accuracy: 0.6007556675062973\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75       477\n",
      "           1       0.50      0.01      0.02       317\n",
      "\n",
      "    accuracy                           0.60       794\n",
      "   macro avg       0.55      0.50      0.39       794\n",
      "weighted avg       0.56      0.60      0.46       794\n",
      "\n",
      "Accuracy List Length : 1463\n",
      "FTGC   1680\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.10      0.17       267\n",
      "           1       0.49      0.91      0.64       257\n",
      "\n",
      "    accuracy                           0.50       524\n",
      "   macro avg       0.52      0.51      0.41       524\n",
      "weighted avg       0.52      0.50      0.40       524\n",
      "\n",
      "Accuracy List Length : 1464\n",
      "FTGS   1681\n",
      "Accuracy: 0.6571428571428571\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.26      0.37        27\n",
      "           1       0.66      0.91      0.76        43\n",
      "\n",
      "    accuracy                           0.66        70\n",
      "   macro avg       0.65      0.58      0.57        70\n",
      "weighted avg       0.65      0.66      0.61        70\n",
      "\n",
      "Accuracy List Length : 1465\n",
      "FTHI   1682\n",
      "Accuracy: 0.4961089494163424\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.91      0.62       235\n",
      "           1       0.67      0.14      0.24       279\n",
      "\n",
      "    accuracy                           0.50       514\n",
      "   macro avg       0.57      0.53      0.43       514\n",
      "weighted avg       0.58      0.50      0.41       514\n",
      "\n",
      "Accuracy List Length : 1466\n",
      "FTHM   1683\n",
      "Accuracy: 0.45901639344262296\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.89      0.61        87\n",
      "           1       0.41      0.07      0.12        96\n",
      "\n",
      "    accuracy                           0.46       183\n",
      "   macro avg       0.44      0.48      0.37       183\n",
      "weighted avg       0.44      0.46      0.35       183\n",
      "\n",
      "Accuracy List Length : 1467\n",
      "FTII   1684\n",
      "Accuracy: 0.7346938775510204\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.97      0.85        73\n",
      "           1       0.33      0.04      0.07        25\n",
      "\n",
      "    accuracy                           0.73        98\n",
      "   macro avg       0.54      0.51      0.46        98\n",
      "weighted avg       0.64      0.73      0.65        98\n",
      "\n",
      "Accuracy List Length : 1468\n",
      "FTIIU   1685\n",
      "Accuracy: 0.8666666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93        93\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.87       105\n",
      "   macro avg       0.44      0.49      0.46       105\n",
      "weighted avg       0.78      0.87      0.82       105\n",
      "\n",
      "Accuracy List Length : 1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FTIIW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTLF   1687\n",
      "Accuracy: 0.6783980582524272\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81       568\n",
      "           1       0.20      0.01      0.02       256\n",
      "\n",
      "    accuracy                           0.68       824\n",
      "   macro avg       0.44      0.50      0.41       824\n",
      "weighted avg       0.54      0.68      0.56       824\n",
      "\n",
      "Accuracy List Length : 1470\n",
      "FTNT   1688\n",
      "Accuracy: 0.5464632454923717\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.04       327\n",
      "           1       0.55      0.98      0.70       394\n",
      "\n",
      "    accuracy                           0.55       721\n",
      "   macro avg       0.52      0.50      0.37       721\n",
      "weighted avg       0.53      0.55      0.40       721\n",
      "\n",
      "Accuracy List Length : 1471\n",
      "FTQI   1689\n",
      "Accuracy: 0.5642023346303502\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.70       279\n",
      "           1       0.61      0.13      0.22       235\n",
      "\n",
      "    accuracy                           0.56       514\n",
      "   macro avg       0.58      0.53      0.46       514\n",
      "weighted avg       0.58      0.56      0.48       514\n",
      "\n",
      "Accuracy List Length : 1472\n",
      "FTRE   1690\n",
      "Accuracy: 0.39473684210526316\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.79      0.57        19\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.39        38\n",
      "   macro avg       0.22      0.39      0.28        38\n",
      "weighted avg       0.22      0.39      0.28        38\n",
      "\n",
      "Accuracy List Length : 1473\n",
      "FTRI   1691\n",
      "Accuracy: 0.5220483641536273\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.91      0.66       357\n",
      "           1       0.57      0.12      0.20       346\n",
      "\n",
      "    accuracy                           0.52       703\n",
      "   macro avg       0.54      0.52      0.43       703\n",
      "weighted avg       0.54      0.52      0.43       703\n",
      "\n",
      "Accuracy List Length : 1474\n",
      "FTSL   1692\n",
      "Accuracy: 0.5036496350364964\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.04      0.07       271\n",
      "           1       0.50      0.96      0.66       277\n",
      "\n",
      "    accuracy                           0.50       548\n",
      "   macro avg       0.49      0.50      0.37       548\n",
      "weighted avg       0.49      0.50      0.37       548\n",
      "\n",
      "Accuracy List Length : 1475\n",
      "FTSM   1693\n",
      "Accuracy: 0.518595041322314\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.78      0.61       232\n",
      "           1       0.58      0.27      0.37       252\n",
      "\n",
      "    accuracy                           0.52       484\n",
      "   macro avg       0.54      0.53      0.49       484\n",
      "weighted avg       0.54      0.52      0.49       484\n",
      "\n",
      "Accuracy List Length : 1476\n",
      "FTXG   1694\n",
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.68       201\n",
      "           1       0.48      0.06      0.10       174\n",
      "\n",
      "    accuracy                           0.53       375\n",
      "   macro avg       0.51      0.50      0.39       375\n",
      "weighted avg       0.51      0.53      0.41       375\n",
      "\n",
      "Accuracy List Length : 1477\n",
      "FTXH   1695\n",
      "Accuracy: 0.5384615384615384\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.82      0.66       211\n",
      "           1       0.44      0.19      0.26       166\n",
      "\n",
      "    accuracy                           0.54       377\n",
      "   macro avg       0.50      0.50      0.46       377\n",
      "weighted avg       0.51      0.54      0.49       377\n",
      "\n",
      "Accuracy List Length : 1478\n",
      "FTXL   1696\n",
      "Accuracy: 0.5490716180371353\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.04      0.08       162\n",
      "           1       0.56      0.93      0.70       215\n",
      "\n",
      "    accuracy                           0.55       377\n",
      "   macro avg       0.44      0.49      0.39       377\n",
      "weighted avg       0.46      0.55      0.43       377\n",
      "\n",
      "Accuracy List Length : 1479\n",
      "FTXN   1697\n",
      "Accuracy: 0.5145888594164456\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.82      0.62       184\n",
      "           1       0.57      0.22      0.32       193\n",
      "\n",
      "    accuracy                           0.51       377\n",
      "   macro avg       0.53      0.52      0.47       377\n",
      "weighted avg       0.53      0.51      0.47       377\n",
      "\n",
      "Accuracy List Length : 1480\n",
      "FTXO   1698\n",
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.22      0.31       181\n",
      "           1       0.53      0.83      0.65       194\n",
      "\n",
      "    accuracy                           0.53       375\n",
      "   macro avg       0.54      0.52      0.48       375\n",
      "weighted avg       0.54      0.53      0.48       375\n",
      "\n",
      "Accuracy List Length : 1481\n",
      "FTXR   1699\n",
      "Accuracy: 0.5411140583554377\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.69       203\n",
      "           1       0.53      0.05      0.08       174\n",
      "\n",
      "    accuracy                           0.54       377\n",
      "   macro avg       0.54      0.51      0.39       377\n",
      "weighted avg       0.54      0.54      0.41       377\n",
      "\n",
      "Accuracy List Length : 1482\n",
      "FUFU   1700\n",
      "Accuracy: 0.6228070175438597\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.77        73\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.62       114\n",
      "   macro avg       0.32      0.49      0.38       114\n",
      "weighted avg       0.41      0.62      0.49       114\n",
      "\n",
      "Accuracy List Length : 1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FUFUW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULC   1702\n",
      "Accuracy: 0.5234042553191489\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.91      0.66       121\n",
      "           1       0.54      0.11      0.19       114\n",
      "\n",
      "    accuracy                           0.52       235\n",
      "   macro avg       0.53      0.51      0.43       235\n",
      "weighted avg       0.53      0.52      0.43       235\n",
      "\n",
      "Accuracy List Length : 1484\n",
      "FULT   1703\n",
      "Accuracy: 0.56201749871333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71      1083\n",
      "           1       0.55      0.06      0.11       860\n",
      "\n",
      "    accuracy                           0.56      1943\n",
      "   macro avg       0.55      0.51      0.41      1943\n",
      "weighted avg       0.56      0.56      0.44      1943\n",
      "\n",
      "Accuracy List Length : 1485\n",
      "FULTP   1704\n",
      "Accuracy: 0.5321637426900585\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60        97\n",
      "           1       0.46      0.42      0.44        74\n",
      "\n",
      "    accuracy                           0.53       171\n",
      "   macro avg       0.52      0.52      0.52       171\n",
      "weighted avg       0.53      0.53      0.53       171\n",
      "\n",
      "Accuracy List Length : 1486\n",
      "FUNC   1705\n",
      "Accuracy: 0.6085588420390182\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       958\n",
      "           1       0.60      0.04      0.08       631\n",
      "\n",
      "    accuracy                           0.61      1589\n",
      "   macro avg       0.60      0.51      0.42      1589\n",
      "weighted avg       0.60      0.61      0.49      1589\n",
      "\n",
      "Accuracy List Length : 1487\n",
      "FUND   1706\n",
      "Accuracy: 0.5540765391014975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69       989\n",
      "           1       0.53      0.13      0.21       814\n",
      "\n",
      "    accuracy                           0.55      1803\n",
      "   macro avg       0.54      0.52      0.45      1803\n",
      "weighted avg       0.54      0.55      0.47      1803\n",
      "\n",
      "Accuracy List Length : 1488\n",
      "FUSB   1707\n",
      "Accuracy: 0.5962145110410094\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.74       762\n",
      "           1       0.39      0.02      0.04       506\n",
      "\n",
      "    accuracy                           0.60      1268\n",
      "   macro avg       0.50      0.50      0.39      1268\n",
      "weighted avg       0.52      0.60      0.46      1268\n",
      "\n",
      "Accuracy List Length : 1489\n",
      "FUTU   1708\n",
      "Accuracy: 0.47244094488188976\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.19      0.29       143\n",
      "           1       0.44      0.84      0.58       111\n",
      "\n",
      "    accuracy                           0.47       254\n",
      "   macro avg       0.52      0.51      0.43       254\n",
      "weighted avg       0.53      0.47      0.42       254\n",
      "\n",
      "Accuracy List Length : 1490\n",
      "FV   1709\n",
      "Accuracy: 0.5296442687747036\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.01       238\n",
      "           1       0.53      1.00      0.69       268\n",
      "\n",
      "    accuracy                           0.53       506\n",
      "   macro avg       0.51      0.50      0.35       506\n",
      "weighted avg       0.52      0.53      0.37       506\n",
      "\n",
      "Accuracy List Length : 1491\n",
      "FVC   1710\n",
      "Accuracy: 0.5062034739454094\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.01      0.03       201\n",
      "           1       0.50      1.00      0.67       202\n",
      "\n",
      "    accuracy                           0.51       403\n",
      "   macro avg       0.63      0.50      0.35       403\n",
      "weighted avg       0.63      0.51      0.35       403\n",
      "\n",
      "Accuracy List Length : 1492\n",
      "FVCB   1711\n",
      "Accuracy: 0.5659955257270693\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71       249\n",
      "           1       0.60      0.06      0.11       198\n",
      "\n",
      "    accuracy                           0.57       447\n",
      "   macro avg       0.58      0.51      0.41       447\n",
      "weighted avg       0.58      0.57      0.45       447\n",
      "\n",
      "Accuracy List Length : 1493\n",
      "FWONA   1715\n",
      "Accuracy: 0.4937833037300178\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.04       273\n",
      "           1       0.50      0.94      0.66       290\n",
      "\n",
      "    accuracy                           0.49       563\n",
      "   macro avg       0.38      0.48      0.35       563\n",
      "weighted avg       0.38      0.49      0.36       563\n",
      "\n",
      "Accuracy List Length : 1494\n",
      "FWONK   1716\n",
      "Accuracy: 0.5153374233128835\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.03      0.05       234\n",
      "           1       0.52      0.96      0.67       255\n",
      "\n",
      "    accuracy                           0.52       489\n",
      "   macro avg       0.46      0.50      0.36       489\n",
      "weighted avg       0.46      0.52      0.38       489\n",
      "\n",
      "Accuracy List Length : 1495\n",
      "FWRD   1717\n",
      "Accuracy: 0.5202879581151832\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.89      0.66       800\n",
      "           1       0.48      0.11      0.18       728\n",
      "\n",
      "    accuracy                           0.52      1528\n",
      "   macro avg       0.50      0.50      0.42      1528\n",
      "weighted avg       0.51      0.52      0.43      1528\n",
      "\n",
      "Accuracy List Length : 1496\n",
      "FWRG   1718\n",
      "Accuracy: 0.5241935483870968\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.17      0.27        65\n",
      "           1       0.50      0.92      0.65        59\n",
      "\n",
      "    accuracy                           0.52       124\n",
      "   macro avg       0.59      0.54      0.46       124\n",
      "weighted avg       0.60      0.52      0.45       124\n",
      "\n",
      "Accuracy List Length : 1497\n",
      "FXNC   1719\n",
      "Accuracy: 0.7371744277821626\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85       938\n",
      "           1       0.17      0.00      0.01       329\n",
      "\n",
      "    accuracy                           0.74      1267\n",
      "   macro avg       0.45      0.50      0.43      1267\n",
      "weighted avg       0.59      0.74      0.63      1267\n",
      "\n",
      "Accuracy List Length : 1498\n",
      "FYBR   1720\n",
      "Accuracy: 0.5655172413793104\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.77      0.65        77\n",
      "           1       0.56      0.34      0.42        68\n",
      "\n",
      "    accuracy                           0.57       145\n",
      "   macro avg       0.56      0.55      0.54       145\n",
      "weighted avg       0.56      0.57      0.54       145\n",
      "\n",
      "Accuracy List Length : 1499\n",
      "FYC   1721\n",
      "Accuracy: 0.49538461538461537\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.06      0.10       321\n",
      "           1       0.50      0.92      0.65       329\n",
      "\n",
      "    accuracy                           0.50       650\n",
      "   macro avg       0.46      0.49      0.38       650\n",
      "weighted avg       0.46      0.50      0.38       650\n",
      "\n",
      "Accuracy List Length : 1500\n",
      "FYT   1722\n",
      "Accuracy: 0.47692307692307695\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.07      0.11       335\n",
      "           1       0.48      0.91      0.63       315\n",
      "\n",
      "    accuracy                           0.48       650\n",
      "   macro avg       0.46      0.49      0.37       650\n",
      "weighted avg       0.46      0.48      0.36       650\n",
      "\n",
      "Accuracy List Length : 1501\n",
      "FYX   1723\n",
      "Accuracy: 0.5300353356890459\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.05      0.08       391\n",
      "           1       0.54      0.94      0.68       458\n",
      "\n",
      "    accuracy                           0.53       849\n",
      "   macro avg       0.47      0.49      0.38       849\n",
      "weighted avg       0.48      0.53      0.41       849\n",
      "\n",
      "Accuracy List Length : 1502\n",
      "GABC   1724\n",
      "Accuracy: 0.5653573728267869\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.71       869\n",
      "           1       0.56      0.06      0.11       684\n",
      "\n",
      "    accuracy                           0.57      1553\n",
      "   macro avg       0.56      0.51      0.41      1553\n",
      "weighted avg       0.56      0.57      0.45      1553\n",
      "\n",
      "Accuracy List Length : 1503\n",
      "GAIA   1725\n",
      "Accuracy: 0.5175224123879381\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.96      0.67       640\n",
      "           1       0.45      0.04      0.07       587\n",
      "\n",
      "    accuracy                           0.52      1227\n",
      "   macro avg       0.48      0.50      0.37      1227\n",
      "weighted avg       0.49      0.52      0.38      1227\n",
      "\n",
      "Accuracy List Length : 1504\n",
      "GAIN   1726\n",
      "Accuracy: 0.5185577942735949\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.06      0.11       447\n",
      "           1       0.52      0.93      0.67       496\n",
      "\n",
      "    accuracy                           0.52       943\n",
      "   macro avg       0.48      0.50      0.39       943\n",
      "weighted avg       0.49      0.52      0.40       943\n",
      "\n",
      "Accuracy List Length : 1505\n",
      "GAINL   1727\n",
      "Accuracy: 0.525\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.74      0.60        19\n",
      "           1       0.58      0.33      0.42        21\n",
      "\n",
      "    accuracy                           0.53        40\n",
      "   macro avg       0.54      0.54      0.51        40\n",
      "weighted avg       0.54      0.53      0.51        40\n",
      "\n",
      "Accuracy List Length : 1506\n",
      "GAINN   1728\n",
      "Accuracy: 0.5816993464052288\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71        91\n",
      "           1       0.45      0.16      0.24        62\n",
      "\n",
      "    accuracy                           0.58       153\n",
      "   macro avg       0.53      0.51      0.47       153\n",
      "weighted avg       0.54      0.58      0.52       153\n",
      "\n",
      "Accuracy List Length : 1507\n",
      "GAINZ   1729\n",
      "Accuracy: 0.6153846153846154\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75        77\n",
      "           1       0.80      0.08      0.14        53\n",
      "\n",
      "    accuracy                           0.62       130\n",
      "   macro avg       0.70      0.53      0.45       130\n",
      "weighted avg       0.69      0.62      0.50       130\n",
      "\n",
      "Accuracy List Length : 1508\n",
      "GALT   1730\n",
      "Accuracy: 0.5695852534562212\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       619\n",
      "           1       0.44      0.01      0.02       466\n",
      "\n",
      "    accuracy                           0.57      1085\n",
      "   macro avg       0.51      0.50      0.37      1085\n",
      "weighted avg       0.52      0.57      0.42      1085\n",
      "\n",
      "Accuracy List Length : 1509\n",
      "GAMB   1731\n",
      "Accuracy: 0.5373134328358209\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.23      0.34        70\n",
      "           1       0.51      0.88      0.64        64\n",
      "\n",
      "    accuracy                           0.54       134\n",
      "   macro avg       0.59      0.55      0.49       134\n",
      "weighted avg       0.59      0.54      0.49       134\n",
      "\n",
      "Accuracy List Length : 1510\n",
      "GAME   1732\n",
      "Accuracy: 0.6116504854368932\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.94      0.75       193\n",
      "           1       0.39      0.06      0.10       116\n",
      "\n",
      "    accuracy                           0.61       309\n",
      "   macro avg       0.51      0.50      0.43       309\n",
      "weighted avg       0.54      0.61      0.51       309\n",
      "\n",
      "Accuracy List Length : 1511\n",
      "GAN   1733\n",
      "Accuracy: 0.5948717948717949\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       115\n",
      "           1       0.67      0.03      0.05        80\n",
      "\n",
      "    accuracy                           0.59       195\n",
      "   macro avg       0.63      0.51      0.40       195\n",
      "weighted avg       0.62      0.59      0.46       195\n",
      "\n",
      "Accuracy List Length : 1512\n",
      "GANX   1734\n",
      "Accuracy: 0.5231788079470199\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.95      0.67        76\n",
      "           1       0.64      0.09      0.16        75\n",
      "\n",
      "    accuracy                           0.52       151\n",
      "   macro avg       0.58      0.52      0.41       151\n",
      "weighted avg       0.57      0.52      0.42       151\n",
      "\n",
      "Accuracy List Length : 1513\n",
      "GASS   1735\n",
      "Accuracy: 0.5296017222820237\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.69       491\n",
      "           1       0.52      0.03      0.06       438\n",
      "\n",
      "    accuracy                           0.53       929\n",
      "   macro avg       0.52      0.50      0.37       929\n",
      "weighted avg       0.52      0.53      0.39       929\n",
      "\n",
      "Accuracy List Length : 1514\n",
      "GATE   1736\n",
      "Accuracy: 0.7521367521367521\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        88\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.75       117\n",
      "   macro avg       0.38      0.50      0.43       117\n",
      "weighted avg       0.57      0.75      0.65       117\n",
      "\n",
      "Accuracy List Length : 1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATEU   1737\n",
      "Accuracy: 0.8870967741935484\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       110\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.89       124\n",
      "   macro avg       0.44      0.50      0.47       124\n",
      "weighted avg       0.79      0.89      0.83       124\n",
      "\n",
      "Accuracy List Length : 1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATEW   1738\n",
      "Accuracy: 0.8205128205128205\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        96\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.82       117\n",
      "   macro avg       0.41      0.50      0.45       117\n",
      "weighted avg       0.67      0.82      0.74       117\n",
      "\n",
      "Accuracy List Length : 1517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBBK   1740\n",
      "Accuracy: 0.7386363636363636\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        64\n",
      "           1       1.00      0.04      0.08        24\n",
      "\n",
      "    accuracy                           0.74        88\n",
      "   macro avg       0.87      0.52      0.46        88\n",
      "weighted avg       0.81      0.74      0.64        88\n",
      "\n",
      "Accuracy List Length : 1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GBBKR: Period 'max' is invalid, must be one of ['1d', '5d']\n",
      "GBBKW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDC   1743\n",
      "Accuracy: 0.514978601997147\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.04      0.07       342\n",
      "           1       0.51      0.97      0.67       359\n",
      "\n",
      "    accuracy                           0.51       701\n",
      "   macro avg       0.53      0.50      0.37       701\n",
      "weighted avg       0.53      0.51      0.38       701\n",
      "\n",
      "Accuracy List Length : 1519\n",
      "GBIO   1744\n",
      "Accuracy: 0.531578947368421\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       101\n",
      "           1       0.50      0.06      0.10        89\n",
      "\n",
      "    accuracy                           0.53       190\n",
      "   macro avg       0.52      0.50      0.39       190\n",
      "weighted avg       0.52      0.53      0.41       190\n",
      "\n",
      "Accuracy List Length : 1520\n",
      "GCBC   1745\n",
      "Accuracy: 0.6366559485530546\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.94      0.77       805\n",
      "           1       0.42      0.07      0.12       439\n",
      "\n",
      "    accuracy                           0.64      1244\n",
      "   macro avg       0.53      0.51      0.45      1244\n",
      "weighted avg       0.57      0.64      0.54      1244\n",
      "\n",
      "Accuracy List Length : 1521\n",
      "GCMG   1746\n",
      "Accuracy: 0.5426356589147286\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.93      0.69       142\n",
      "           1       0.44      0.07      0.12       116\n",
      "\n",
      "    accuracy                           0.54       258\n",
      "   macro avg       0.50      0.50      0.41       258\n",
      "weighted avg       0.50      0.54      0.43       258\n",
      "\n",
      "Accuracy List Length : 1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCMGW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCT   1748\n",
      "Accuracy: 0.3875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.43      0.40        37\n",
      "           1       0.42      0.35      0.38        43\n",
      "\n",
      "    accuracy                           0.39        80\n",
      "   macro avg       0.39      0.39      0.39        80\n",
      "weighted avg       0.39      0.39      0.39        80\n",
      "\n",
      "Accuracy List Length : 1523\n",
      "GCTK   1749\n",
      "Accuracy: 0.8142076502732241\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90       447\n",
      "           1       0.00      0.00      0.00       102\n",
      "\n",
      "    accuracy                           0.81       549\n",
      "   macro avg       0.41      0.50      0.45       549\n",
      "weighted avg       0.66      0.81      0.73       549\n",
      "\n",
      "Accuracy List Length : 1524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDC   1750\n",
      "Accuracy: 0.6521739130434783\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       268\n",
      "           1       0.75      0.02      0.04       146\n",
      "\n",
      "    accuracy                           0.65       414\n",
      "   macro avg       0.70      0.51      0.41       414\n",
      "weighted avg       0.69      0.65      0.52       414\n",
      "\n",
      "Accuracy List Length : 1525\n",
      "GDEN   1751\n",
      "Accuracy: 0.5390070921985816\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69       685\n",
      "           1       0.49      0.04      0.08       584\n",
      "\n",
      "    accuracy                           0.54      1269\n",
      "   macro avg       0.52      0.50      0.39      1269\n",
      "weighted avg       0.52      0.54      0.41      1269\n",
      "\n",
      "Accuracy List Length : 1526\n",
      "GDEV   1752\n",
      "Accuracy: 0.6494252873563219\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78       114\n",
      "           1       0.44      0.07      0.12        60\n",
      "\n",
      "    accuracy                           0.65       174\n",
      "   macro avg       0.55      0.51      0.45       174\n",
      "weighted avg       0.59      0.65      0.55       174\n",
      "\n",
      "Accuracy List Length : 1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GDEVW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDHG   1754\n",
      "Accuracy: 0.5531914893617021\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71        28\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.29      0.46      0.36        47\n",
      "weighted avg       0.34      0.55      0.42        47\n",
      "\n",
      "Accuracy List Length : 1528\n",
      "GDRX   1755\n",
      "Accuracy: 0.5340909090909091\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69        99\n",
      "           1       0.27      0.04      0.07        77\n",
      "\n",
      "    accuracy                           0.53       176\n",
      "   macro avg       0.41      0.48      0.38       176\n",
      "weighted avg       0.43      0.53      0.42       176\n",
      "\n",
      "Accuracy List Length : 1529\n",
      "GDS   1756\n",
      "Accuracy: 0.5040431266846361\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.07      0.12       183\n",
      "           1       0.51      0.93      0.66       188\n",
      "\n",
      "    accuracy                           0.50       371\n",
      "   macro avg       0.49      0.50      0.39       371\n",
      "weighted avg       0.49      0.50      0.39       371\n",
      "\n",
      "Accuracy List Length : 1530\n",
      "GDST   1757\n",
      "Accuracy: 0.8247422680412371\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90        81\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.82        97\n",
      "   macro avg       0.42      0.49      0.45        97\n",
      "weighted avg       0.70      0.82      0.75        97\n",
      "\n",
      "Accuracy List Length : 1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GDSTR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDSTU   1759\n",
      "Accuracy: 0.9702970297029703\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        98\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       101\n",
      "   macro avg       0.49      0.50      0.49       101\n",
      "weighted avg       0.94      0.97      0.96       101\n",
      "\n",
      "Accuracy List Length : 1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "GDSTW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDTC   1761\n",
      "Accuracy: 0.6382978723404256\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76        32\n",
      "           1       0.38      0.20      0.26        15\n",
      "\n",
      "    accuracy                           0.64        47\n",
      "   macro avg       0.53      0.52      0.51        47\n",
      "weighted avg       0.59      0.64      0.60        47\n",
      "\n",
      "Accuracy List Length : 1533\n",
      "GDYN   1762\n",
      "Accuracy: 0.4907749077490775\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.85      0.62       135\n",
      "           1       0.47      0.13      0.21       136\n",
      "\n",
      "    accuracy                           0.49       271\n",
      "   macro avg       0.48      0.49      0.42       271\n",
      "weighted avg       0.48      0.49      0.42       271\n",
      "\n",
      "Accuracy List Length : 1534\n",
      "GECC   1763\n",
      "Accuracy: 0.5175202156334232\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.95      0.68       196\n",
      "           1       0.38      0.03      0.06       175\n",
      "\n",
      "    accuracy                           0.52       371\n",
      "   macro avg       0.45      0.49      0.37       371\n",
      "weighted avg       0.45      0.52      0.39       371\n",
      "\n",
      "Accuracy List Length : 1535\n",
      "GECCO   1766\n",
      "Accuracy: 0.7318840579710145\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.99      0.84       100\n",
      "           1       0.67      0.05      0.10        38\n",
      "\n",
      "    accuracy                           0.73       138\n",
      "   macro avg       0.70      0.52      0.47       138\n",
      "weighted avg       0.71      0.73      0.64       138\n",
      "\n",
      "Accuracy List Length : 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GECCZ: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEG   1768\n",
      "Accuracy: 0.5637530072173216\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       713\n",
      "           1       0.36      0.02      0.05       534\n",
      "\n",
      "    accuracy                           0.56      1247\n",
      "   macro avg       0.47      0.50      0.38      1247\n",
      "weighted avg       0.48      0.56      0.43      1247\n",
      "\n",
      "Accuracy List Length : 1537\n",
      "GEGGL   1769\n",
      "Accuracy: 0.6363636363636364\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75        54\n",
      "           1       0.58      0.21      0.30        34\n",
      "\n",
      "    accuracy                           0.64        88\n",
      "   macro avg       0.61      0.56      0.53        88\n",
      "weighted avg       0.62      0.64      0.58        88\n",
      "\n",
      "Accuracy List Length : 1538\n",
      "GEHC   1770\n",
      "Accuracy: 0.47619047619047616\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.21      0.30        34\n",
      "           1       0.46      0.79      0.58        29\n",
      "\n",
      "    accuracy                           0.48        63\n",
      "   macro avg       0.50      0.50      0.44        63\n",
      "weighted avg       0.50      0.48      0.43        63\n",
      "\n",
      "Accuracy List Length : 1539\n",
      "GEN   1772\n",
      "Accuracy: 0.5131428571428571\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66       883\n",
      "           1       0.55      0.09      0.16       867\n",
      "\n",
      "    accuracy                           0.51      1750\n",
      "   macro avg       0.53      0.51      0.41      1750\n",
      "weighted avg       0.53      0.51      0.41      1750\n",
      "\n",
      "Accuracy List Length : 1540\n",
      "GENE   1773\n",
      "Accuracy: 0.632368703108253\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.99      0.77       591\n",
      "           1       0.40      0.01      0.01       342\n",
      "\n",
      "    accuracy                           0.63       933\n",
      "   macro avg       0.52      0.50      0.39       933\n",
      "weighted avg       0.55      0.63      0.49       933\n",
      "\n",
      "Accuracy List Length : 1541\n",
      "GENK   1774\n",
      "Accuracy: 0.43243243243243246\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.17      0.28        23\n",
      "           1       0.39      0.86      0.53        14\n",
      "\n",
      "    accuracy                           0.43        37\n",
      "   macro avg       0.53      0.52      0.40        37\n",
      "weighted avg       0.56      0.43      0.37        37\n",
      "\n",
      "Accuracy List Length : 1542\n",
      "GEOS   1775\n",
      "Accuracy: 0.5350943396226415\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.91      0.68       717\n",
      "           1       0.47      0.09      0.15       608\n",
      "\n",
      "    accuracy                           0.54      1325\n",
      "   macro avg       0.50      0.50      0.42      1325\n",
      "weighted avg       0.51      0.54      0.44      1325\n",
      "\n",
      "Accuracy List Length : 1543\n",
      "GERN   1776\n",
      "Accuracy: 0.5298346513299784\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.93      0.68       752\n",
      "           1       0.41      0.05      0.10       639\n",
      "\n",
      "    accuracy                           0.53      1391\n",
      "   macro avg       0.47      0.49      0.39      1391\n",
      "weighted avg       0.48      0.53      0.41      1391\n",
      "\n",
      "Accuracy List Length : 1544\n",
      "GEVO   1777\n",
      "Accuracy: 0.6196969696969697\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.96      0.76       414\n",
      "           1       0.41      0.04      0.08       246\n",
      "\n",
      "    accuracy                           0.62       660\n",
      "   macro avg       0.52      0.50      0.42       660\n",
      "weighted avg       0.55      0.62      0.51       660\n",
      "\n",
      "Accuracy List Length : 1545\n",
      "GFAI   1778\n",
      "Accuracy: 0.5645161290322581\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72        70\n",
      "           1       0.50      0.04      0.07        54\n",
      "\n",
      "    accuracy                           0.56       124\n",
      "   macro avg       0.53      0.50      0.39       124\n",
      "weighted avg       0.54      0.56      0.43       124\n",
      "\n",
      "Accuracy List Length : 1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GFAIW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFGF   1780\n",
      "Accuracy: 0.5663716814159292\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.04        49\n",
      "           1       0.57      0.98      0.72        64\n",
      "\n",
      "    accuracy                           0.57       113\n",
      "   macro avg       0.53      0.50      0.38       113\n",
      "weighted avg       0.54      0.57      0.42       113\n",
      "\n",
      "Accuracy List Length : 1547\n",
      "GFS   1781\n",
      "Accuracy: 0.49166666666666664\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.80      0.61        60\n",
      "           1       0.48      0.18      0.27        60\n",
      "\n",
      "    accuracy                           0.49       120\n",
      "   macro avg       0.49      0.49      0.44       120\n",
      "weighted avg       0.49      0.49      0.44       120\n",
      "\n",
      "Accuracy List Length : 1548\n",
      "GGAL   1782\n",
      "Accuracy: 0.515126050420168\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.91      0.66       605\n",
      "           1       0.54      0.10      0.17       585\n",
      "\n",
      "    accuracy                           0.52      1190\n",
      "   macro avg       0.52      0.51      0.42      1190\n",
      "weighted avg       0.52      0.52      0.42      1190\n",
      "\n",
      "Accuracy List Length : 1549\n",
      "GGLL   1783\n",
      "Accuracy: 0.5844155844155844\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.06      0.11        33\n",
      "           1       0.58      0.98      0.73        44\n",
      "\n",
      "    accuracy                           0.58        77\n",
      "   macro avg       0.62      0.52      0.42        77\n",
      "weighted avg       0.62      0.58      0.46        77\n",
      "\n",
      "Accuracy List Length : 1550\n",
      "GGLS   1784\n",
      "Accuracy: 0.7236842105263158\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82        50\n",
      "           1       0.78      0.27      0.40        26\n",
      "\n",
      "    accuracy                           0.72        76\n",
      "   macro avg       0.75      0.61      0.61        76\n",
      "weighted avg       0.74      0.72      0.68        76\n",
      "\n",
      "Accuracy List Length : 1551\n",
      "GGR   1785\n",
      "Accuracy: 0.5584415584415584\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71        83\n",
      "           1       1.00      0.04      0.08        71\n",
      "\n",
      "    accuracy                           0.56       154\n",
      "   macro avg       0.77      0.52      0.40       154\n",
      "weighted avg       0.76      0.56      0.42       154\n",
      "\n",
      "Accuracy List Length : 1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GGROW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GH   1787\n",
      "Accuracy: 0.5018181818181818\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.89      0.65       145\n",
      "           1       0.36      0.07      0.12       130\n",
      "\n",
      "    accuracy                           0.50       275\n",
      "   macro avg       0.44      0.48      0.38       275\n",
      "weighted avg       0.44      0.50      0.40       275\n",
      "\n",
      "Accuracy List Length : 1553\n",
      "GHIX   1788\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83        73\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.71        98\n",
      "   macro avg       0.37      0.48      0.42        98\n",
      "weighted avg       0.55      0.71      0.62        98\n",
      "\n",
      "Accuracy List Length : 1554\n",
      "GHIXU   1789\n",
      "Accuracy: 0.8240740740740741\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90        91\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.82       108\n",
      "   macro avg       0.42      0.49      0.45       108\n",
      "weighted avg       0.71      0.82      0.76       108\n",
      "\n",
      "Accuracy List Length : 1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GHIXW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GHRS   1791\n",
      "Accuracy: 0.6159420289855072\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73        88\n",
      "           1       0.45      0.28      0.35        50\n",
      "\n",
      "    accuracy                           0.62       138\n",
      "   macro avg       0.56      0.54      0.54       138\n",
      "weighted avg       0.59      0.62      0.59       138\n",
      "\n",
      "Accuracy List Length : 1556\n",
      "GIFI   1792\n",
      "Accuracy: 0.5416359616801769\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.69       729\n",
      "           1       0.53      0.08      0.14       628\n",
      "\n",
      "    accuracy                           0.54      1357\n",
      "   macro avg       0.54      0.51      0.41      1357\n",
      "weighted avg       0.54      0.54      0.43      1357\n",
      "\n",
      "Accuracy List Length : 1557\n",
      "GIFT   1793\n",
      "Accuracy: 0.6832298136645962\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       113\n",
      "           1       0.33      0.06      0.11        48\n",
      "\n",
      "    accuracy                           0.68       161\n",
      "   macro avg       0.52      0.50      0.46       161\n",
      "weighted avg       0.59      0.68      0.60       161\n",
      "\n",
      "Accuracy List Length : 1558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GIGGW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIGM   1797\n",
      "Accuracy: 0.5998349834983498\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.75       725\n",
      "           1       0.54      0.03      0.05       487\n",
      "\n",
      "    accuracy                           0.60      1212\n",
      "   macro avg       0.57      0.51      0.40      1212\n",
      "weighted avg       0.58      0.60      0.47      1212\n",
      "\n",
      "Accuracy List Length : 1559\n",
      "GIII   1798\n",
      "Accuracy: 0.5718424101969872\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       984\n",
      "           1       0.52      0.05      0.09       742\n",
      "\n",
      "    accuracy                           0.57      1726\n",
      "   macro avg       0.55      0.51      0.41      1726\n",
      "weighted avg       0.55      0.57      0.45      1726\n",
      "\n",
      "Accuracy List Length : 1560\n",
      "GILD   1799\n",
      "Accuracy: 0.5166666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.83      0.63       806\n",
      "           1       0.55      0.20      0.30       814\n",
      "\n",
      "    accuracy                           0.52      1620\n",
      "   macro avg       0.53      0.52      0.46      1620\n",
      "weighted avg       0.53      0.52      0.46      1620\n",
      "\n",
      "Accuracy List Length : 1561\n",
      "GILT   1800\n",
      "Accuracy: 0.541025641025641\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.70       840\n",
      "           1       0.59      0.02      0.04       720\n",
      "\n",
      "    accuracy                           0.54      1560\n",
      "   macro avg       0.57      0.50      0.37      1560\n",
      "weighted avg       0.56      0.54      0.39      1560\n",
      "\n",
      "Accuracy List Length : 1562\n",
      "GINX   1801\n",
      "Accuracy: 0.3333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n",
      "Accuracy List Length : 1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIPR   1802\n",
      "Accuracy: 0.5403225806451613\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.94      0.70        69\n",
      "           1       0.33      0.04      0.07        55\n",
      "\n",
      "    accuracy                           0.54       124\n",
      "   macro avg       0.44      0.49      0.38       124\n",
      "weighted avg       0.45      0.54      0.42       124\n",
      "\n",
      "Accuracy List Length : 1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GIPRW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLAC   1804\n",
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         7\n",
      "           1       1.00      0.12      0.22         8\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.75      0.56      0.44        15\n",
      "weighted avg       0.77      0.53      0.43        15\n",
      "\n",
      "Accuracy List Length : 1565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GLACR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLACU   1806\n",
      "Accuracy: 0.8235294117647058\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.41      0.50      0.45        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n",
      "Accuracy List Length : 1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLAD   1807\n",
      "Accuracy: 0.5206611570247934\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.05      0.10       530\n",
      "           1       0.52      0.96      0.67       559\n",
      "\n",
      "    accuracy                           0.52      1089\n",
      "   macro avg       0.55      0.51      0.39      1089\n",
      "weighted avg       0.55      0.52      0.39      1089\n",
      "\n",
      "Accuracy List Length : 1567\n",
      "GLADZ   1808\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.69      0.59        16\n",
      "           1       0.44      0.29      0.35        14\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.48      0.49      0.47        30\n",
      "weighted avg       0.49      0.50      0.48        30\n",
      "\n",
      "Accuracy List Length : 1568\n",
      "GLBE   1809\n",
      "Accuracy: 0.5625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.79      0.64        71\n",
      "           1       0.62      0.34      0.44        73\n",
      "\n",
      "    accuracy                           0.56       144\n",
      "   macro avg       0.58      0.57      0.54       144\n",
      "weighted avg       0.58      0.56      0.54       144\n",
      "\n",
      "Accuracy List Length : 1569\n",
      "GLBS   1810\n",
      "Accuracy: 0.654275092936803\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       526\n",
      "           1       1.00      0.01      0.01       281\n",
      "\n",
      "    accuracy                           0.65       807\n",
      "   macro avg       0.83      0.50      0.40       807\n",
      "weighted avg       0.77      0.65      0.52       807\n",
      "\n",
      "Accuracy List Length : 1570\n",
      "GLBZ   1811\n",
      "Accuracy: 0.7251223491027733\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84       889\n",
      "           1       0.50      0.00      0.01       337\n",
      "\n",
      "    accuracy                           0.73      1226\n",
      "   macro avg       0.61      0.50      0.42      1226\n",
      "weighted avg       0.66      0.73      0.61      1226\n",
      "\n",
      "Accuracy List Length : 1571\n",
      "GLDD   1812\n",
      "Accuracy: 0.538638985005767\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.69       472\n",
      "           1       0.45      0.06      0.10       395\n",
      "\n",
      "    accuracy                           0.54       867\n",
      "   macro avg       0.50      0.50      0.40       867\n",
      "weighted avg       0.50      0.54      0.42       867\n",
      "\n",
      "Accuracy List Length : 1572\n",
      "GLDI   1813\n",
      "Accuracy: 0.5098039215686274\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.10      0.17       269\n",
      "           1       0.52      0.88      0.65       292\n",
      "\n",
      "    accuracy                           0.51       561\n",
      "   macro avg       0.48      0.49      0.41       561\n",
      "weighted avg       0.49      0.51      0.42       561\n",
      "\n",
      "Accuracy List Length : 1573\n",
      "GLLI   1815\n",
      "Accuracy: 0.7589285714285714\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86        91\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.76       112\n",
      "   macro avg       0.40      0.47      0.43       112\n",
      "weighted avg       0.65      0.76      0.70       112\n",
      "\n",
      "Accuracy List Length : 1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GLLIR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLLIU   1817\n",
      "Accuracy: 0.8695652173913043\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       103\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.87       115\n",
      "   macro avg       0.45      0.49      0.47       115\n",
      "weighted avg       0.80      0.87      0.83       115\n",
      "\n",
      "Accuracy List Length : 1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GLLIW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMD   1819\n",
      "Accuracy: 0.5782178217821782\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       291\n",
      "           1       0.60      0.01      0.03       214\n",
      "\n",
      "    accuracy                           0.58       505\n",
      "   macro avg       0.59      0.50      0.38       505\n",
      "weighted avg       0.59      0.58      0.43       505\n",
      "\n",
      "Accuracy List Length : 1576\n",
      "GLNG   1820\n",
      "Accuracy: 0.5072046109510087\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.92      0.65       520\n",
      "           1       0.54      0.09      0.16       521\n",
      "\n",
      "    accuracy                           0.51      1041\n",
      "   macro avg       0.52      0.51      0.41      1041\n",
      "weighted avg       0.52      0.51      0.41      1041\n",
      "\n",
      "Accuracy List Length : 1577\n",
      "GLPG   1822\n",
      "Accuracy: 0.5255354200988468\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.87      0.66       321\n",
      "           1       0.49      0.14      0.21       286\n",
      "\n",
      "    accuracy                           0.53       607\n",
      "   macro avg       0.51      0.50      0.44       607\n",
      "weighted avg       0.51      0.53      0.45       607\n",
      "\n",
      "Accuracy List Length : 1578\n",
      "GLPI   1823\n",
      "Accuracy: 0.49523809523809526\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.04      0.08       258\n",
      "           1       0.50      0.93      0.65       267\n",
      "\n",
      "    accuracy                           0.50       525\n",
      "   macro avg       0.44      0.49      0.36       525\n",
      "weighted avg       0.44      0.50      0.37       525\n",
      "\n",
      "Accuracy List Length : 1579\n",
      "GLRE   1824\n",
      "Accuracy: 0.5053128689492326\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.92      0.65       421\n",
      "           1       0.55      0.10      0.17       426\n",
      "\n",
      "    accuracy                           0.51       847\n",
      "   macro avg       0.52      0.51      0.41       847\n",
      "weighted avg       0.52      0.51      0.41       847\n",
      "\n",
      "Accuracy List Length : 1580\n",
      "GLSI   1825\n",
      "Accuracy: 0.5657142857142857\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       100\n",
      "           1       0.45      0.07      0.12        75\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.51      0.50      0.41       175\n",
      "weighted avg       0.52      0.57      0.46       175\n",
      "\n",
      "Accuracy List Length : 1581\n",
      "GLST   1826\n",
      "Accuracy: 0.7352941176470589\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85        52\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.74        68\n",
      "   macro avg       0.38      0.48      0.42        68\n",
      "weighted avg       0.58      0.74      0.65        68\n",
      "\n",
      "Accuracy List Length : 1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GLSTR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLSTU   1828\n",
      "Accuracy: 0.9333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        70\n",
      "           1       0.50      0.20      0.29         5\n",
      "\n",
      "    accuracy                           0.93        75\n",
      "   macro avg       0.72      0.59      0.63        75\n",
      "weighted avg       0.92      0.93      0.92        75\n",
      "\n",
      "Accuracy List Length : 1583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GLSTW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLTO   1830\n",
      "Accuracy: 0.5588235294117647\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71        92\n",
      "           1       1.00      0.04      0.07        78\n",
      "\n",
      "    accuracy                           0.56       170\n",
      "   macro avg       0.78      0.52      0.39       170\n",
      "weighted avg       0.76      0.56      0.42       170\n",
      "\n",
      "Accuracy List Length : 1584\n",
      "GLUE   1831\n",
      "Accuracy: 0.5217391304347826\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.88      0.66        73\n",
      "           1       0.47      0.12      0.20        65\n",
      "\n",
      "    accuracy                           0.52       138\n",
      "   macro avg       0.50      0.50      0.43       138\n",
      "weighted avg       0.50      0.52      0.44       138\n",
      "\n",
      "Accuracy List Length : 1585\n",
      "GLYC   1833\n",
      "Accuracy: 0.5692007797270955\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72       290\n",
      "           1       0.57      0.04      0.07       223\n",
      "\n",
      "    accuracy                           0.57       513\n",
      "   macro avg       0.57      0.51      0.39       513\n",
      "weighted avg       0.57      0.57      0.44       513\n",
      "\n",
      "Accuracy List Length : 1586\n",
      "GMAB   1834\n",
      "Accuracy: 0.6026845637583893\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.89      0.74       472\n",
      "           1       0.36      0.11      0.17       273\n",
      "\n",
      "    accuracy                           0.60       745\n",
      "   macro avg       0.50      0.50      0.46       745\n",
      "weighted avg       0.53      0.60      0.53       745\n",
      "\n",
      "Accuracy List Length : 1587\n",
      "GMGI   1835\n",
      "Accuracy: 0.7582872928176796\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86       553\n",
      "           1       0.17      0.01      0.01       171\n",
      "\n",
      "    accuracy                           0.76       724\n",
      "   macro avg       0.46      0.50      0.44       724\n",
      "weighted avg       0.62      0.76      0.66       724\n",
      "\n",
      "Accuracy List Length : 1588\n",
      "GMM   1836\n",
      "Accuracy: 0.6521739130434783\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79        18\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.38      0.42      0.39        23\n",
      "weighted avg       0.59      0.65      0.62        23\n",
      "\n",
      "Accuracy List Length : 1589\n",
      "GNFT   1837\n",
      "Accuracy: 0.5338645418326693\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       132\n",
      "           1       0.57      0.07      0.12       119\n",
      "\n",
      "    accuracy                           0.53       251\n",
      "   macro avg       0.55      0.51      0.40       251\n",
      "weighted avg       0.55      0.53      0.42       251\n",
      "\n",
      "Accuracy List Length : 1590\n",
      "GNLN   1838\n",
      "Accuracy: 0.6048387096774194\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75       149\n",
      "           1       0.67      0.02      0.04        99\n",
      "\n",
      "    accuracy                           0.60       248\n",
      "   macro avg       0.64      0.51      0.40       248\n",
      "weighted avg       0.63      0.60      0.47       248\n",
      "\n",
      "Accuracy List Length : 1591\n",
      "GNLX   1839\n",
      "Accuracy: 0.6206896551724138\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        36\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.62        58\n",
      "   macro avg       0.31      0.50      0.38        58\n",
      "weighted avg       0.39      0.62      0.48        58\n",
      "\n",
      "Accuracy List Length : 1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNMA   1840\n",
      "Accuracy: 0.524671052631579\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.64       317\n",
      "           1       0.51      0.20      0.28       291\n",
      "\n",
      "    accuracy                           0.52       608\n",
      "   macro avg       0.52      0.51      0.46       608\n",
      "weighted avg       0.52      0.52      0.47       608\n",
      "\n",
      "Accuracy List Length : 1593\n",
      "GNOM   1841\n",
      "Accuracy: 0.4819277108433735\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.26      0.34       127\n",
      "           1       0.48      0.71      0.57       122\n",
      "\n",
      "    accuracy                           0.48       249\n",
      "   macro avg       0.48      0.49      0.46       249\n",
      "weighted avg       0.48      0.48      0.45       249\n",
      "\n",
      "Accuracy List Length : 1594\n",
      "GNPX   1842\n",
      "Accuracy: 0.5913621262458472\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.94      0.74       183\n",
      "           1       0.35      0.05      0.09       118\n",
      "\n",
      "    accuracy                           0.59       301\n",
      "   macro avg       0.48      0.50      0.41       301\n",
      "weighted avg       0.51      0.59      0.48       301\n",
      "\n",
      "Accuracy List Length : 1595\n",
      "GNSS   1843\n",
      "Accuracy: 0.5765407554671969\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73       869\n",
      "           1       0.60      0.00      0.01       640\n",
      "\n",
      "    accuracy                           0.58      1509\n",
      "   macro avg       0.59      0.50      0.37      1509\n",
      "weighted avg       0.59      0.58      0.42      1509\n",
      "\n",
      "Accuracy List Length : 1596\n",
      "GNTA   1844\n",
      "Accuracy: 0.6140350877192983\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        69\n",
      "           1       1.00      0.02      0.04        45\n",
      "\n",
      "    accuracy                           0.61       114\n",
      "   macro avg       0.81      0.51      0.40       114\n",
      "weighted avg       0.76      0.61      0.48       114\n",
      "\n",
      "Accuracy List Length : 1597\n",
      "GNTX   1845\n",
      "Accuracy: 0.5615023474178403\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.91      0.70      1191\n",
      "           1       0.51      0.12      0.20       939\n",
      "\n",
      "    accuracy                           0.56      2130\n",
      "   macro avg       0.54      0.52      0.45      2130\n",
      "weighted avg       0.54      0.56      0.48      2130\n",
      "\n",
      "Accuracy List Length : 1598\n",
      "GO   1846\n",
      "Accuracy: 0.497907949790795\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.15      0.24       124\n",
      "           1       0.49      0.87      0.62       115\n",
      "\n",
      "    accuracy                           0.50       239\n",
      "   macro avg       0.52      0.51      0.43       239\n",
      "weighted avg       0.52      0.50      0.43       239\n",
      "\n",
      "Accuracy List Length : 1599\n",
      "GOCO   1847\n",
      "Accuracy: 0.5621621621621622\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.91      0.70       103\n",
      "           1       0.53      0.12      0.20        82\n",
      "\n",
      "    accuracy                           0.56       185\n",
      "   macro avg       0.55      0.52      0.45       185\n",
      "weighted avg       0.55      0.56      0.48       185\n",
      "\n",
      "Accuracy List Length : 1600\n",
      "GODN   1848\n",
      "Accuracy: 0.8378378378378378\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        29\n",
      "           1       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.84        37\n",
      "   macro avg       0.91      0.62      0.65        37\n",
      "weighted avg       0.87      0.84      0.80        37\n",
      "\n",
      "Accuracy List Length : 1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GODNR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GODNU   1850\n",
      "Accuracy: 0.9523809523809523\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        40\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.48      0.50      0.49        42\n",
      "weighted avg       0.91      0.95      0.93        42\n",
      "\n",
      "Accuracy List Length : 1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOEV   1851\n",
      "Accuracy: 0.5725806451612904\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       143\n",
      "           1       0.46      0.06      0.10       105\n",
      "\n",
      "    accuracy                           0.57       248\n",
      "   macro avg       0.52      0.50      0.41       248\n",
      "weighted avg       0.53      0.57      0.46       248\n",
      "\n",
      "Accuracy List Length : 1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GOEVW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOGL   1853\n",
      "Accuracy: 0.4937728937728938\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.95      0.65       660\n",
      "           1       0.59      0.07      0.12       705\n",
      "\n",
      "    accuracy                           0.49      1365\n",
      "   macro avg       0.54      0.51      0.38      1365\n",
      "weighted avg       0.54      0.49      0.37      1365\n",
      "\n",
      "Accuracy List Length : 1604\n",
      "GOGO   1854\n",
      "Accuracy: 0.5268022181146026\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.92      0.68       294\n",
      "           1       0.38      0.06      0.10       247\n",
      "\n",
      "    accuracy                           0.53       541\n",
      "   macro avg       0.46      0.49      0.39       541\n",
      "weighted avg       0.46      0.53      0.41       541\n",
      "\n",
      "Accuracy List Length : 1605\n",
      "GOOD   1855\n",
      "Accuracy: 0.502410800385728\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.05      0.09       518\n",
      "           1       0.50      0.96      0.66       519\n",
      "\n",
      "    accuracy                           0.50      1037\n",
      "   macro avg       0.51      0.50      0.37      1037\n",
      "weighted avg       0.51      0.50      0.37      1037\n",
      "\n",
      "Accuracy List Length : 1606\n",
      "GOODN   1856\n",
      "Accuracy: 0.5265486725663717\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.89      0.66       119\n",
      "           1       0.50      0.12      0.20       107\n",
      "\n",
      "    accuracy                           0.53       226\n",
      "   macro avg       0.52      0.51      0.43       226\n",
      "weighted avg       0.52      0.53      0.44       226\n",
      "\n",
      "Accuracy List Length : 1607\n",
      "GOODO   1857\n",
      "Accuracy: 0.5362318840579711\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.48      0.54        77\n",
      "           1       0.48      0.61      0.54        61\n",
      "\n",
      "    accuracy                           0.54       138\n",
      "   macro avg       0.54      0.54      0.54       138\n",
      "weighted avg       0.55      0.54      0.54       138\n",
      "\n",
      "Accuracy List Length : 1608\n",
      "GOOG   1858\n",
      "Accuracy: 0.5243407707910751\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.11       469\n",
      "           1       0.53      0.94      0.68       517\n",
      "\n",
      "    accuracy                           0.52       986\n",
      "   macro avg       0.51      0.50      0.39       986\n",
      "weighted avg       0.51      0.52      0.41       986\n",
      "\n",
      "Accuracy List Length : 1609\n",
      "GOOGL   1859\n",
      "Accuracy: 0.5273833671399595\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.06      0.11       472\n",
      "           1       0.53      0.96      0.68       514\n",
      "\n",
      "    accuracy                           0.53       986\n",
      "   macro avg       0.54      0.51      0.39       986\n",
      "weighted avg       0.54      0.53      0.41       986\n",
      "\n",
      "Accuracy List Length : 1610\n",
      "GORV   1860\n",
      "Accuracy: 0.5529801324503312\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       165\n",
      "           1       0.58      0.05      0.09       137\n",
      "\n",
      "    accuracy                           0.55       302\n",
      "   macro avg       0.57      0.51      0.40       302\n",
      "weighted avg       0.57      0.55      0.43       302\n",
      "\n",
      "Accuracy List Length : 1611\n",
      "GOSS   1861\n",
      "Accuracy: 0.5836575875486382\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.71       142\n",
      "           1       0.67      0.14      0.23       115\n",
      "\n",
      "    accuracy                           0.58       257\n",
      "   macro avg       0.62      0.54      0.47       257\n",
      "weighted avg       0.62      0.58      0.50       257\n",
      "\n",
      "Accuracy List Length : 1612\n",
      "GOVI   1862\n",
      "Accuracy: 0.5362318840579711\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.06      0.11       387\n",
      "           1       0.54      0.95      0.69       441\n",
      "\n",
      "    accuracy                           0.54       828\n",
      "   macro avg       0.54      0.51      0.40       828\n",
      "weighted avg       0.54      0.54      0.42       828\n",
      "\n",
      "Accuracy List Length : 1613\n",
      "GOVX   1863\n",
      "Accuracy: 0.56\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.72        99\n",
      "           1       0.33      0.01      0.03        76\n",
      "\n",
      "    accuracy                           0.56       175\n",
      "   macro avg       0.45      0.50      0.37       175\n",
      "weighted avg       0.46      0.56      0.42       175\n",
      "\n",
      "Accuracy List Length : 1614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GOVXW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP   1865\n",
      "Accuracy: 0.547486033519553\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.91      0.70       103\n",
      "           1       0.31      0.05      0.09        76\n",
      "\n",
      "    accuracy                           0.55       179\n",
      "   macro avg       0.44      0.48      0.39       179\n",
      "weighted avg       0.46      0.55      0.44       179\n",
      "\n",
      "Accuracy List Length : 1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPATW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPCR   1869\n",
      "Accuracy: 0.5964912280701754\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72        34\n",
      "           1       0.50      0.17      0.26        23\n",
      "\n",
      "    accuracy                           0.60        57\n",
      "   macro avg       0.56      0.53      0.49        57\n",
      "weighted avg       0.57      0.60      0.54        57\n",
      "\n",
      "Accuracy List Length : 1616\n",
      "GPIQ   1870\n",
      "Accuracy: 0.55\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.55      1.00      0.71        11\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.28      0.50      0.35        20\n",
      "weighted avg       0.30      0.55      0.39        20\n",
      "\n",
      "Accuracy List Length : 1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPIX   1871\n",
      "Accuracy: 0.55\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.58      0.92      0.71        12\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.29      0.46      0.35        20\n",
      "weighted avg       0.35      0.55      0.43        20\n",
      "\n",
      "Accuracy List Length : 1618\n",
      "GPRE   1872\n",
      "Accuracy: 0.5170893054024256\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.94      0.66       463\n",
      "           1       0.55      0.08      0.14       444\n",
      "\n",
      "    accuracy                           0.52       907\n",
      "   macro avg       0.53      0.51      0.40       907\n",
      "weighted avg       0.53      0.52      0.41       907\n",
      "\n",
      "Accuracy List Length : 1619\n",
      "GPRO   1874\n",
      "Accuracy: 0.49387755102040815\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.98      0.66       242\n",
      "           1       0.50      0.02      0.05       248\n",
      "\n",
      "    accuracy                           0.49       490\n",
      "   macro avg       0.50      0.50      0.35       490\n",
      "weighted avg       0.50      0.49      0.35       490\n",
      "\n",
      "Accuracy List Length : 1620\n",
      "GRAB   1876\n",
      "Accuracy: 0.5060240963855421\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.90      0.66        88\n",
      "           1       0.36      0.06      0.11        78\n",
      "\n",
      "    accuracy                           0.51       166\n",
      "   macro avg       0.44      0.48      0.38       166\n",
      "weighted avg       0.44      0.51      0.40       166\n",
      "\n",
      "Accuracy List Length : 1621\n",
      "GRABW   1877\n",
      "Accuracy: 0.5757575757575758\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.89      0.71        94\n",
      "           1       0.52      0.15      0.24        71\n",
      "\n",
      "    accuracy                           0.58       165\n",
      "   macro avg       0.55      0.52      0.47       165\n",
      "weighted avg       0.56      0.58      0.51       165\n",
      "\n",
      "Accuracy List Length : 1622\n",
      "GRCE   1879\n",
      "Accuracy: 0.5934426229508196\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       358\n",
      "           1       0.70      0.03      0.05       252\n",
      "\n",
      "    accuracy                           0.59       610\n",
      "   macro avg       0.65      0.51      0.40       610\n",
      "weighted avg       0.64      0.59      0.46       610\n",
      "\n",
      "Accuracy List Length : 1623\n",
      "GREE   1880\n",
      "Accuracy: 0.5650713685978169\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72       675\n",
      "           1       0.46      0.03      0.05       516\n",
      "\n",
      "    accuracy                           0.57      1191\n",
      "   macro avg       0.52      0.50      0.38      1191\n",
      "weighted avg       0.52      0.57      0.43      1191\n",
      "\n",
      "Accuracy List Length : 1624\n",
      "GREEL   1881\n",
      "Accuracy: 0.4426229508196721\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.38      0.41        63\n",
      "           1       0.43      0.51      0.47        59\n",
      "\n",
      "    accuracy                           0.44       122\n",
      "   macro avg       0.44      0.44      0.44       122\n",
      "weighted avg       0.44      0.44      0.44       122\n",
      "\n",
      "Accuracy List Length : 1625\n",
      "GRFS   1882\n",
      "Accuracy: 0.5186335403726708\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.88      0.64       314\n",
      "           1       0.61      0.17      0.27       330\n",
      "\n",
      "    accuracy                           0.52       644\n",
      "   macro avg       0.56      0.53      0.46       644\n",
      "weighted avg       0.56      0.52      0.45       644\n",
      "\n",
      "Accuracy List Length : 1626\n",
      "GRI   1883\n",
      "Accuracy: 0.6153846153846154\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.96      0.76        98\n",
      "           1       0.33      0.03      0.06        58\n",
      "\n",
      "    accuracy                           0.62       156\n",
      "   macro avg       0.48      0.50      0.41       156\n",
      "weighted avg       0.52      0.62      0.50       156\n",
      "\n",
      "Accuracy List Length : 1627\n",
      "GRID   1884\n",
      "Accuracy: 0.4986149584487535\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.88      0.63       356\n",
      "           1       0.52      0.13      0.21       366\n",
      "\n",
      "    accuracy                           0.50       722\n",
      "   macro avg       0.51      0.50      0.42       722\n",
      "weighted avg       0.51      0.50      0.42       722\n",
      "\n",
      "Accuracy List Length : 1628\n",
      "GRNQ   1885\n",
      "Accuracy: 0.5344827586206896\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.94      0.69       160\n",
      "           1       0.31      0.03      0.06       130\n",
      "\n",
      "    accuracy                           0.53       290\n",
      "   macro avg       0.43      0.49      0.37       290\n",
      "weighted avg       0.44      0.53      0.41       290\n",
      "\n",
      "Accuracy List Length : 1629\n",
      "GROW   1886\n",
      "Accuracy: 0.6568077511473738\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79      1291\n",
      "           1       0.41      0.01      0.02       670\n",
      "\n",
      "    accuracy                           0.66      1961\n",
      "   macro avg       0.54      0.50      0.41      1961\n",
      "weighted avg       0.57      0.66      0.53      1961\n",
      "\n",
      "Accuracy List Length : 1630\n",
      "GRPN   1887\n",
      "Accuracy: 0.5771704180064309\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73       359\n",
      "           1       0.50      0.05      0.08       263\n",
      "\n",
      "    accuracy                           0.58       622\n",
      "   macro avg       0.54      0.51      0.40       622\n",
      "weighted avg       0.55      0.58      0.45       622\n",
      "\n",
      "Accuracy List Length : 1631\n",
      "GRRR   1888\n",
      "Accuracy: 0.625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        90\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.62       144\n",
      "   macro avg       0.31      0.50      0.38       144\n",
      "weighted avg       0.39      0.62      0.48       144\n",
      "\n",
      "Accuracy List Length : 1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "GRRRW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRVY   1890\n",
      "Accuracy: 0.58004158004158\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.97      0.73       568\n",
      "           1       0.27      0.02      0.03       394\n",
      "\n",
      "    accuracy                           0.58       962\n",
      "   macro avg       0.43      0.49      0.38       962\n",
      "weighted avg       0.46      0.58      0.44       962\n",
      "\n",
      "Accuracy List Length : 1633\n",
      "GRWG   1891\n",
      "Accuracy: 0.5227272727272727\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.93      0.68       167\n",
      "           1       0.31      0.04      0.06       141\n",
      "\n",
      "    accuracy                           0.52       308\n",
      "   macro avg       0.42      0.48      0.37       308\n",
      "weighted avg       0.43      0.52      0.40       308\n",
      "\n",
      "Accuracy List Length : 1634\n",
      "GRYP   1892\n",
      "Accuracy: 0.580327868852459\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73       177\n",
      "           1       0.00      0.00      0.00       128\n",
      "\n",
      "    accuracy                           0.58       305\n",
      "   macro avg       0.29      0.50      0.37       305\n",
      "weighted avg       0.34      0.58      0.43       305\n",
      "\n",
      "Accuracy List Length : 1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSBC   1893\n",
      "Accuracy: 0.5341830822711472\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.93      0.68       903\n",
      "           1       0.57      0.10      0.17       823\n",
      "\n",
      "    accuracy                           0.53      1726\n",
      "   macro avg       0.55      0.51      0.42      1726\n",
      "weighted avg       0.55      0.53      0.43      1726\n",
      "\n",
      "Accuracy List Length : 1636\n",
      "GSHD   1894\n",
      "Accuracy: 0.5016835016835017\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.05      0.10       146\n",
      "           1       0.51      0.93      0.66       151\n",
      "\n",
      "    accuracy                           0.50       297\n",
      "   macro avg       0.47      0.49      0.38       297\n",
      "weighted avg       0.48      0.50      0.38       297\n",
      "\n",
      "Accuracy List Length : 1637\n",
      "GSIB   1895\n",
      "Accuracy: 0.3076923076923077\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           1       0.33      0.50      0.40         6\n",
      "\n",
      "    accuracy                           0.31        13\n",
      "   macro avg       0.29      0.32      0.29        13\n",
      "weighted avg       0.29      0.31      0.28        13\n",
      "\n",
      "Accuracy List Length : 1638\n",
      "GSIT   1896\n",
      "Accuracy: 0.5391812865497077\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.69       457\n",
      "           1       0.59      0.03      0.06       398\n",
      "\n",
      "    accuracy                           0.54       855\n",
      "   macro avg       0.56      0.51      0.38       855\n",
      "weighted avg       0.56      0.54      0.40       855\n",
      "\n",
      "Accuracy List Length : 1639\n",
      "GSIW   1897\n",
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.67         9\n",
      "           1       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.46      0.47      0.44        15\n",
      "weighted avg       0.48      0.53      0.49        15\n",
      "\n",
      "Accuracy List Length : 1640\n",
      "GSM   1898\n",
      "Accuracy: 0.508819538670285\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.91      0.66       379\n",
      "           1       0.47      0.08      0.14       358\n",
      "\n",
      "    accuracy                           0.51       737\n",
      "   macro avg       0.49      0.50      0.40       737\n",
      "weighted avg       0.49      0.51      0.41       737\n",
      "\n",
      "Accuracy List Length : 1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GSMGW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSUN   1901\n",
      "Accuracy: 0.5568181818181818\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70        49\n",
      "           1       0.50      0.08      0.13        39\n",
      "\n",
      "    accuracy                           0.56        88\n",
      "   macro avg       0.53      0.51      0.42        88\n",
      "weighted avg       0.53      0.56      0.45        88\n",
      "\n",
      "Accuracy List Length : 1642\n",
      "GT   1902\n",
      "Accuracy: 0.5616219667943806\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71      1758\n",
      "           1       0.51      0.03      0.05      1374\n",
      "\n",
      "    accuracy                           0.56      3132\n",
      "   macro avg       0.53      0.50      0.38      3132\n",
      "weighted avg       0.54      0.56      0.42      3132\n",
      "\n",
      "Accuracy List Length : 1643\n",
      "GTBP   1903\n",
      "Accuracy: 0.5647840531561462\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72       171\n",
      "           1       0.43      0.02      0.04       130\n",
      "\n",
      "    accuracy                           0.56       301\n",
      "   macro avg       0.50      0.50      0.38       301\n",
      "weighted avg       0.51      0.56      0.43       301\n",
      "\n",
      "Accuracy List Length : 1644\n",
      "GTEC   1904\n",
      "Accuracy: 0.5759717314487632\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.96      0.73       166\n",
      "           1       0.33      0.03      0.05       117\n",
      "\n",
      "    accuracy                           0.58       283\n",
      "   macro avg       0.46      0.49      0.39       283\n",
      "weighted avg       0.48      0.58      0.45       283\n",
      "\n",
      "Accuracy List Length : 1645\n",
      "GTI   1905\n",
      "Accuracy: 0.7\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.99      0.82        78\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.70       110\n",
      "   macro avg       0.35      0.49      0.41       110\n",
      "weighted avg       0.50      0.70      0.58       110\n",
      "\n",
      "Accuracy List Length : 1646\n",
      "GTIM   1906\n",
      "Accuracy: 0.63055729492799\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.99      0.77      1001\n",
      "           1       0.64      0.02      0.05       596\n",
      "\n",
      "    accuracy                           0.63      1597\n",
      "   macro avg       0.63      0.51      0.41      1597\n",
      "weighted avg       0.63      0.63      0.50      1597\n",
      "\n",
      "Accuracy List Length : 1647\n",
      "GTLB   1907\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.12      0.21        65\n",
      "           1       0.48      0.93      0.63        57\n",
      "\n",
      "    accuracy                           0.50       122\n",
      "   macro avg       0.57      0.53      0.42       122\n",
      "weighted avg       0.58      0.50      0.41       122\n",
      "\n",
      "Accuracy List Length : 1648\n",
      "GTR   1908\n",
      "Accuracy: 0.5121951219512195\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.17      0.23        54\n",
      "           1       0.55      0.78      0.64        69\n",
      "\n",
      "    accuracy                           0.51       123\n",
      "   macro avg       0.46      0.47      0.44       123\n",
      "weighted avg       0.47      0.51      0.46       123\n",
      "\n",
      "Accuracy List Length : 1649\n",
      "GTX   1909\n",
      "Accuracy: 0.48736462093862815\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.88      0.64       145\n",
      "           1       0.29      0.05      0.09       132\n",
      "\n",
      "    accuracy                           0.49       277\n",
      "   macro avg       0.40      0.47      0.37       277\n",
      "weighted avg       0.40      0.49      0.38       277\n",
      "\n",
      "Accuracy List Length : 1650\n",
      "GURE   1910\n",
      "Accuracy: 0.5570776255707762\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       494\n",
      "           1       0.25      0.01      0.02       382\n",
      "\n",
      "    accuracy                           0.56       876\n",
      "   macro avg       0.41      0.49      0.36       876\n",
      "weighted avg       0.43      0.56      0.41       876\n",
      "\n",
      "Accuracy List Length : 1651\n",
      "GUTS   1911\n",
      "Accuracy: 0.42857142857142855\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         3\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.43         7\n",
      "   macro avg       0.21      0.50      0.30         7\n",
      "weighted avg       0.18      0.43      0.26         7\n",
      "\n",
      "Accuracy List Length : 1652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GV   1912\n",
      "Accuracy: 0.5698924731182796\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72        56\n",
      "           1       0.20      0.03      0.05        37\n",
      "\n",
      "    accuracy                           0.57        93\n",
      "   macro avg       0.40      0.48      0.38        93\n",
      "weighted avg       0.44      0.57      0.45        93\n",
      "\n",
      "Accuracy List Length : 1653\n",
      "GVH   1913\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.80      0.64        10\n",
      "           1       0.33      0.12      0.18         8\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.43      0.46      0.41        18\n",
      "weighted avg       0.44      0.50      0.44        18\n",
      "\n",
      "Accuracy List Length : 1654\n",
      "GWAV   1914\n",
      "Accuracy: 0.5809312638580931\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.73       266\n",
      "           1       0.17      0.01      0.01       185\n",
      "\n",
      "    accuracy                           0.58       451\n",
      "   macro avg       0.38      0.49      0.37       451\n",
      "weighted avg       0.41      0.58      0.44       451\n",
      "\n",
      "Accuracy List Length : 1655\n",
      "GWRS   1915\n",
      "Accuracy: 0.5188916876574308\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.89      0.66       209\n",
      "           1       0.47      0.11      0.18       188\n",
      "\n",
      "    accuracy                           0.52       397\n",
      "   macro avg       0.50      0.50      0.42       397\n",
      "weighted avg       0.50      0.52      0.43       397\n",
      "\n",
      "Accuracy List Length : 1656\n",
      "GXAI   1916\n",
      "Accuracy: 0.6363636363636364\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77        34\n",
      "           1       1.00      0.05      0.09        21\n",
      "\n",
      "    accuracy                           0.64        55\n",
      "   macro avg       0.81      0.52      0.43        55\n",
      "weighted avg       0.77      0.64      0.51        55\n",
      "\n",
      "Accuracy List Length : 1657\n",
      "GXTG   1917\n",
      "Accuracy: 0.5227272727272727\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.86      0.66       118\n",
      "           1       0.45      0.13      0.20       102\n",
      "\n",
      "    accuracy                           0.52       220\n",
      "   macro avg       0.49      0.50      0.43       220\n",
      "weighted avg       0.49      0.52      0.45       220\n",
      "\n",
      "Accuracy List Length : 1658\n",
      "GYRE   1918\n",
      "Accuracy: 0.5293466223698782\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.69       486\n",
      "           1       0.35      0.02      0.04       417\n",
      "\n",
      "    accuracy                           0.53       903\n",
      "   macro avg       0.44      0.49      0.36       903\n",
      "weighted avg       0.45      0.53      0.39       903\n",
      "\n",
      "Accuracy List Length : 1659\n",
      "GYRO   1919\n",
      "Accuracy: 0.7317581653926337\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.99      0.84      1052\n",
      "           1       0.53      0.02      0.04       387\n",
      "\n",
      "    accuracy                           0.73      1439\n",
      "   macro avg       0.63      0.51      0.44      1439\n",
      "weighted avg       0.68      0.73      0.63      1439\n",
      "\n",
      "Accuracy List Length : 1660\n",
      "HAFC   1920\n",
      "Accuracy: 0.5590185676392573\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       853\n",
      "           1       0.44      0.05      0.10       655\n",
      "\n",
      "    accuracy                           0.56      1508\n",
      "   macro avg       0.50      0.50      0.40      1508\n",
      "weighted avg       0.51      0.56      0.44      1508\n",
      "\n",
      "Accuracy List Length : 1661\n",
      "HAIA   1921\n",
      "Accuracy: 0.7289719626168224\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        77\n",
      "           1       1.00      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.73       107\n",
      "   macro avg       0.86      0.52      0.45       107\n",
      "weighted avg       0.80      0.73      0.62       107\n",
      "\n",
      "Accuracy List Length : 1662\n",
      "HAIAU   1922\n",
      "Accuracy: 0.8771929824561403\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       101\n",
      "           1       0.33      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.61      0.53      0.53       114\n",
      "weighted avg       0.83      0.88      0.84       114\n",
      "\n",
      "Accuracy List Length : 1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HAIAW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAIN   1924\n",
      "Accuracy: 0.5187623436471362\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.92      0.67       801\n",
      "           1       0.44      0.07      0.12       718\n",
      "\n",
      "    accuracy                           0.52      1519\n",
      "   macro avg       0.48      0.50      0.40      1519\n",
      "weighted avg       0.49      0.52      0.41      1519\n",
      "\n",
      "Accuracy List Length : 1664\n",
      "HALO   1925\n",
      "Accuracy: 0.5029761904761905\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.91      0.65       517\n",
      "           1       0.44      0.08      0.13       491\n",
      "\n",
      "    accuracy                           0.50      1008\n",
      "   macro avg       0.48      0.49      0.39      1008\n",
      "weighted avg       0.48      0.50      0.40      1008\n",
      "\n",
      "Accuracy List Length : 1665\n",
      "HAO   1926\n",
      "Accuracy: 0.625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73         4\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.79      0.62      0.56         8\n",
      "weighted avg       0.79      0.62      0.56         8\n",
      "\n",
      "Accuracy List Length : 1666\n",
      "HAS   1927\n",
      "Accuracy: 0.5168995042812078\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.95      0.67      1141\n",
      "           1       0.53      0.06      0.10      1078\n",
      "\n",
      "    accuracy                           0.52      2219\n",
      "   macro avg       0.52      0.50      0.39      2219\n",
      "weighted avg       0.52      0.52      0.39      2219\n",
      "\n",
      "Accuracy List Length : 1667\n",
      "HBAN   1928\n",
      "Accuracy: 0.5543037404236142\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71      1230\n",
      "           1       0.50      0.05      0.09       989\n",
      "\n",
      "    accuracy                           0.55      2219\n",
      "   macro avg       0.53      0.50      0.40      2219\n",
      "weighted avg       0.53      0.55      0.43      2219\n",
      "\n",
      "Accuracy List Length : 1668\n",
      "HBANL   1929\n",
      "Accuracy: 0.5283018867924528\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.88      0.65        26\n",
      "           1       0.62      0.19      0.29        27\n",
      "\n",
      "    accuracy                           0.53        53\n",
      "   macro avg       0.57      0.53      0.47        53\n",
      "weighted avg       0.57      0.53      0.46        53\n",
      "\n",
      "Accuracy List Length : 1669\n",
      "HBANM   1930\n",
      "Accuracy: 0.5142857142857142\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.10      0.17        67\n",
      "           1       0.52      0.89      0.66        73\n",
      "\n",
      "    accuracy                           0.51       140\n",
      "   macro avg       0.49      0.50      0.41       140\n",
      "weighted avg       0.49      0.51      0.42       140\n",
      "\n",
      "Accuracy List Length : 1670\n",
      "HBANP   1931\n",
      "Accuracy: 0.5759493670886076\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.89      0.70        90\n",
      "           1       0.52      0.16      0.25        68\n",
      "\n",
      "    accuracy                           0.58       158\n",
      "   macro avg       0.55      0.53      0.48       158\n",
      "weighted avg       0.56      0.58      0.51       158\n",
      "\n",
      "Accuracy List Length : 1671\n",
      "HBCP   1932\n",
      "Accuracy: 0.5102827763496144\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.87      0.64       389\n",
      "           1       0.54      0.15      0.24       389\n",
      "\n",
      "    accuracy                           0.51       778\n",
      "   macro avg       0.52      0.51      0.44       778\n",
      "weighted avg       0.52      0.51      0.44       778\n",
      "\n",
      "Accuracy List Length : 1672\n",
      "HBIO   1933\n",
      "Accuracy: 0.5224525043177893\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.99      0.68       606\n",
      "           1       0.47      0.01      0.02       552\n",
      "\n",
      "    accuracy                           0.52      1158\n",
      "   macro avg       0.49      0.50      0.35      1158\n",
      "weighted avg       0.50      0.52      0.37      1158\n",
      "\n",
      "Accuracy List Length : 1673\n",
      "HBNC   1934\n",
      "Accuracy: 0.5774395702775291\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.72       637\n",
      "           1       0.60      0.05      0.10       480\n",
      "\n",
      "    accuracy                           0.58      1117\n",
      "   macro avg       0.59      0.51      0.41      1117\n",
      "weighted avg       0.58      0.58      0.45      1117\n",
      "\n",
      "Accuracy List Length : 1674\n",
      "HBT   1935\n",
      "Accuracy: 0.45739910313901344\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.89      0.60       102\n",
      "           1       0.50      0.09      0.15       121\n",
      "\n",
      "    accuracy                           0.46       223\n",
      "   macro avg       0.48      0.49      0.38       223\n",
      "weighted avg       0.48      0.46      0.36       223\n",
      "\n",
      "Accuracy List Length : 1675\n",
      "HCAT   1936\n",
      "Accuracy: 0.49572649572649574\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.88      0.64       121\n",
      "           1       0.40      0.09      0.14       113\n",
      "\n",
      "    accuracy                           0.50       234\n",
      "   macro avg       0.45      0.48      0.39       234\n",
      "weighted avg       0.46      0.50      0.40       234\n",
      "\n",
      "Accuracy List Length : 1676\n",
      "HCKT   1937\n",
      "Accuracy: 0.5365665896843725\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.93      0.68       698\n",
      "           1       0.49      0.08      0.14       601\n",
      "\n",
      "    accuracy                           0.54      1299\n",
      "   macro avg       0.52      0.50      0.41      1299\n",
      "weighted avg       0.52      0.54      0.43      1299\n",
      "\n",
      "Accuracy List Length : 1677\n",
      "HCM   1938\n",
      "Accuracy: 0.4640198511166253\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.15      0.24       226\n",
      "           1       0.44      0.86      0.58       177\n",
      "\n",
      "    accuracy                           0.46       403\n",
      "   macro avg       0.51      0.51      0.41       403\n",
      "weighted avg       0.52      0.46      0.39       403\n",
      "\n",
      "Accuracy List Length : 1678\n",
      "HCOW   1939\n",
      "Accuracy: 0.56\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.17      0.27        12\n",
      "           1       0.55      0.92      0.69        13\n",
      "\n",
      "    accuracy                           0.56        25\n",
      "   macro avg       0.61      0.54      0.48        25\n",
      "weighted avg       0.60      0.56      0.48        25\n",
      "\n",
      "Accuracy List Length : 1679\n",
      "HCP   1940\n",
      "Accuracy: 0.41228070175438597\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.88      0.56        49\n",
      "           1       0.40      0.06      0.11        65\n",
      "\n",
      "    accuracy                           0.41       114\n",
      "   macro avg       0.41      0.47      0.33       114\n",
      "weighted avg       0.41      0.41      0.30       114\n",
      "\n",
      "Accuracy List Length : 1680\n",
      "HCSG   1941\n",
      "Accuracy: 0.5408464566929134\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.69      1114\n",
      "           1       0.42      0.04      0.07       918\n",
      "\n",
      "    accuracy                           0.54      2032\n",
      "   macro avg       0.48      0.50      0.38      2032\n",
      "weighted avg       0.49      0.54      0.41      2032\n",
      "\n",
      "Accuracy List Length : 1681\n",
      "HCTI   1942\n",
      "Accuracy: 0.5819672131147541\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71        64\n",
      "           1       0.77      0.17      0.28        58\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.66      0.56      0.49       122\n",
      "weighted avg       0.66      0.58      0.50       122\n",
      "\n",
      "Accuracy List Length : 1682\n",
      "HCVI   1943\n",
      "Accuracy: 0.6120689655172413\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        70\n",
      "           1       1.00      0.02      0.04        46\n",
      "\n",
      "    accuracy                           0.61       116\n",
      "   macro avg       0.80      0.51      0.40       116\n",
      "weighted avg       0.76      0.61      0.47       116\n",
      "\n",
      "Accuracy List Length : 1683\n",
      "HCVIU   1944\n",
      "Accuracy: 0.7983870967741935\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       105\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.80       124\n",
      "   macro avg       0.42      0.47      0.44       124\n",
      "weighted avg       0.71      0.80      0.75       124\n",
      "\n",
      "Accuracy List Length : 1684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HCVIW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCWB   1946\n",
      "Accuracy: 0.6791044776119403\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80        90\n",
      "           1       0.57      0.09      0.16        44\n",
      "\n",
      "    accuracy                           0.68       134\n",
      "   macro avg       0.63      0.53      0.48       134\n",
      "weighted avg       0.65      0.68      0.59       134\n",
      "\n",
      "Accuracy List Length : 1685\n",
      "HDSN   1948\n",
      "Accuracy: 0.579445571331981\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       856\n",
      "           1       0.53      0.01      0.03       623\n",
      "\n",
      "    accuracy                           0.58      1479\n",
      "   macro avg       0.55      0.50      0.38      1479\n",
      "weighted avg       0.56      0.58      0.44      1479\n",
      "\n",
      "Accuracy List Length : 1686\n",
      "HEAR   1949\n",
      "Accuracy: 0.5208333333333334\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.92      0.67       360\n",
      "           1       0.39      0.06      0.10       312\n",
      "\n",
      "    accuracy                           0.52       672\n",
      "   macro avg       0.46      0.49      0.39       672\n",
      "weighted avg       0.47      0.52      0.41       672\n",
      "\n",
      "Accuracy List Length : 1687\n",
      "HEES   1951\n",
      "Accuracy: 0.4611171960569551\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.02      0.05       482\n",
      "           1       0.47      0.95      0.62       431\n",
      "\n",
      "    accuracy                           0.46       913\n",
      "   macro avg       0.41      0.49      0.34       913\n",
      "weighted avg       0.41      0.46      0.32       913\n",
      "\n",
      "Accuracy List Length : 1688\n",
      "HELE   1953\n",
      "Accuracy: 0.586450540315877\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.96      0.73      1410\n",
      "           1       0.50      0.05      0.09       996\n",
      "\n",
      "    accuracy                           0.59      2406\n",
      "   macro avg       0.55      0.51      0.41      2406\n",
      "weighted avg       0.55      0.59      0.47      2406\n",
      "\n",
      "Accuracy List Length : 1689\n",
      "HEPA   1954\n",
      "Accuracy: 0.5854616895874263\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.97      0.74       303\n",
      "           1       0.27      0.01      0.03       206\n",
      "\n",
      "    accuracy                           0.59       509\n",
      "   macro avg       0.43      0.49      0.38       509\n",
      "weighted avg       0.46      0.59      0.45       509\n",
      "\n",
      "Accuracy List Length : 1690\n",
      "HEPS   1955\n",
      "Accuracy: 0.5036496350364964\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.94      0.67        72\n",
      "           1       0.20      0.02      0.03        65\n",
      "\n",
      "    accuracy                           0.50       137\n",
      "   macro avg       0.36      0.48      0.35       137\n",
      "weighted avg       0.37      0.50      0.36       137\n",
      "\n",
      "Accuracy List Length : 1691\n",
      "HERD   1956\n",
      "Accuracy: 0.5795918367346938\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73       142\n",
      "           1       0.50      0.04      0.07       103\n",
      "\n",
      "    accuracy                           0.58       245\n",
      "   macro avg       0.54      0.51      0.40       245\n",
      "weighted avg       0.55      0.58      0.45       245\n",
      "\n",
      "Accuracy List Length : 1692\n",
      "HERO   1957\n",
      "Accuracy: 0.5565610859728507\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.41      0.47       105\n",
      "           1       0.56      0.69      0.62       116\n",
      "\n",
      "    accuracy                           0.56       221\n",
      "   macro avg       0.55      0.55      0.54       221\n",
      "weighted avg       0.55      0.56      0.55       221\n",
      "\n",
      "Accuracy List Length : 1693\n",
      "HFBL   1958\n",
      "Accuracy: 0.7461447212336892\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85       628\n",
      "           1       1.00      0.00      0.01       215\n",
      "\n",
      "    accuracy                           0.75       843\n",
      "   macro avg       0.87      0.50      0.43       843\n",
      "weighted avg       0.81      0.75      0.64       843\n",
      "\n",
      "Accuracy List Length : 1694\n",
      "HFFG   1959\n",
      "Accuracy: 0.5835866261398176\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.72       184\n",
      "           1       0.70      0.10      0.17       145\n",
      "\n",
      "    accuracy                           0.58       329\n",
      "   macro avg       0.64      0.53      0.45       329\n",
      "weighted avg       0.63      0.58      0.48       329\n",
      "\n",
      "Accuracy List Length : 1695\n",
      "HFWA   1961\n",
      "Accuracy: 0.5522273425499232\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       708\n",
      "           1       0.74      0.03      0.06       594\n",
      "\n",
      "    accuracy                           0.55      1302\n",
      "   macro avg       0.64      0.51      0.38      1302\n",
      "weighted avg       0.64      0.55      0.41      1302\n",
      "\n",
      "Accuracy List Length : 1696\n",
      "HGBL   1962\n",
      "Accuracy: 0.7021140294682896\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.99      0.82      1100\n",
      "           1       0.39      0.02      0.03       461\n",
      "\n",
      "    accuracy                           0.70      1561\n",
      "   macro avg       0.55      0.50      0.43      1561\n",
      "weighted avg       0.61      0.70      0.59      1561\n",
      "\n",
      "Accuracy List Length : 1697\n",
      "HHS   1963\n",
      "Accuracy: 0.5552648790058862\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71       837\n",
      "           1       0.62      0.05      0.09       692\n",
      "\n",
      "    accuracy                           0.56      1529\n",
      "   macro avg       0.58      0.51      0.40      1529\n",
      "weighted avg       0.58      0.56      0.43      1529\n",
      "\n",
      "Accuracy List Length : 1698\n",
      "HIDE   1964\n",
      "Accuracy: 0.5074626865671642\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.20      0.30        35\n",
      "           1       0.49      0.84      0.62        32\n",
      "\n",
      "    accuracy                           0.51        67\n",
      "   macro avg       0.54      0.52      0.46        67\n",
      "weighted avg       0.54      0.51      0.45        67\n",
      "\n",
      "Accuracy List Length : 1699\n",
      "HIFS   1965\n",
      "Accuracy: 0.6454698930782217\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78      1142\n",
      "           1       0.54      0.05      0.10       635\n",
      "\n",
      "    accuracy                           0.65      1777\n",
      "   macro avg       0.59      0.51      0.44      1777\n",
      "weighted avg       0.61      0.65      0.54      1777\n",
      "\n",
      "Accuracy List Length : 1700\n",
      "HIHO   1966\n",
      "Accuracy: 0.6161689730517116\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       849\n",
      "           1       0.20      0.00      0.00       524\n",
      "\n",
      "    accuracy                           0.62      1373\n",
      "   macro avg       0.41      0.50      0.38      1373\n",
      "weighted avg       0.46      0.62      0.47      1373\n",
      "\n",
      "Accuracy List Length : 1701\n",
      "HIMX   1967\n",
      "Accuracy: 0.5248618784530387\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       470\n",
      "           1       0.59      0.04      0.07       435\n",
      "\n",
      "    accuracy                           0.52       905\n",
      "   macro avg       0.56      0.51      0.38       905\n",
      "weighted avg       0.56      0.52      0.39       905\n",
      "\n",
      "Accuracy List Length : 1702\n",
      "HISF   1968\n",
      "Accuracy: 0.5279503105590062\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.18      0.26       232\n",
      "           1       0.53      0.85      0.65       251\n",
      "\n",
      "    accuracy                           0.53       483\n",
      "   macro avg       0.53      0.51      0.46       483\n",
      "weighted avg       0.53      0.53      0.47       483\n",
      "\n",
      "Accuracy List Length : 1703\n",
      "HITI   1969\n",
      "Accuracy: 0.4968944099378882\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.65        79\n",
      "           1       0.55      0.07      0.13        82\n",
      "\n",
      "    accuracy                           0.50       161\n",
      "   macro avg       0.52      0.50      0.39       161\n",
      "weighted avg       0.52      0.50      0.38       161\n",
      "\n",
      "Accuracy List Length : 1704\n",
      "HIVE   1970\n",
      "Accuracy: 0.762481089258699\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       506\n",
      "           1       0.42      0.03      0.06       155\n",
      "\n",
      "    accuracy                           0.76       661\n",
      "   macro avg       0.59      0.51      0.46       661\n",
      "weighted avg       0.69      0.76      0.68       661\n",
      "\n",
      "Accuracy List Length : 1705\n",
      "HKIT   1971\n",
      "Accuracy: 0.5306122448979592\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.88      0.67        26\n",
      "           1       0.50      0.13      0.21        23\n",
      "\n",
      "    accuracy                           0.53        49\n",
      "   macro avg       0.52      0.51      0.44        49\n",
      "weighted avg       0.52      0.53      0.45        49\n",
      "\n",
      "Accuracy List Length : 1706\n",
      "HLAL   1972\n",
      "Accuracy: 0.5508474576271186\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.03      0.05       106\n",
      "           1       0.55      0.98      0.71       130\n",
      "\n",
      "    accuracy                           0.55       236\n",
      "   macro avg       0.53      0.50      0.38       236\n",
      "weighted avg       0.53      0.55      0.41       236\n",
      "\n",
      "Accuracy List Length : 1707\n",
      "HLIT   1973\n",
      "Accuracy: 0.5210199862164024\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.97      0.68       751\n",
      "           1       0.56      0.04      0.07       700\n",
      "\n",
      "    accuracy                           0.52      1451\n",
      "   macro avg       0.54      0.50      0.37      1451\n",
      "weighted avg       0.54      0.52      0.38      1451\n",
      "\n",
      "Accuracy List Length : 1708\n",
      "HLMN   1974\n",
      "Accuracy: 0.463855421686747\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.79      0.61        87\n",
      "           1       0.31      0.10      0.15        79\n",
      "\n",
      "    accuracy                           0.46       166\n",
      "   macro avg       0.40      0.45      0.38       166\n",
      "weighted avg       0.40      0.46      0.39       166\n",
      "\n",
      "Accuracy List Length : 1709\n",
      "HLNE   1975\n",
      "Accuracy: 0.5267605633802817\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.07      0.12       174\n",
      "           1       0.52      0.97      0.68       181\n",
      "\n",
      "    accuracy                           0.53       355\n",
      "   macro avg       0.59      0.52      0.40       355\n",
      "weighted avg       0.59      0.53      0.41       355\n",
      "\n",
      "Accuracy List Length : 1710\n",
      "HLP   1976\n",
      "Accuracy: 0.6122448979591837\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.93      0.74        29\n",
      "           1       0.60      0.15      0.24        20\n",
      "\n",
      "    accuracy                           0.61        49\n",
      "   macro avg       0.61      0.54      0.49        49\n",
      "weighted avg       0.61      0.61      0.54        49\n",
      "\n",
      "Accuracy List Length : 1711\n",
      "HLVX   1977\n",
      "Accuracy: 0.47368421052631576\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.88      0.63        48\n",
      "           1       0.33      0.06      0.11        47\n",
      "\n",
      "    accuracy                           0.47        95\n",
      "   macro avg       0.41      0.47      0.37        95\n",
      "weighted avg       0.41      0.47      0.37        95\n",
      "\n",
      "Accuracy List Length : 1712\n",
      "HLXB   1978\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "Accuracy List Length : 1713\n",
      "HMST   1979\n",
      "Accuracy: 0.5024630541871922\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.94      0.65       303\n",
      "           1       0.54      0.07      0.12       306\n",
      "\n",
      "    accuracy                           0.50       609\n",
      "   macro avg       0.52      0.50      0.39       609\n",
      "weighted avg       0.52      0.50      0.39       609\n",
      "\n",
      "Accuracy List Length : 1714\n",
      "HNDL   1980\n",
      "Accuracy: 0.5548387096774193\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.04      0.07       135\n",
      "           1       0.56      0.95      0.71       175\n",
      "\n",
      "    accuracy                           0.55       310\n",
      "   macro avg       0.47      0.50      0.39       310\n",
      "weighted avg       0.48      0.55      0.43       310\n",
      "\n",
      "Accuracy List Length : 1715\n",
      "HNNA   1981\n",
      "Accuracy: 0.6388308977035491\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.78       611\n",
      "           1       0.52      0.04      0.07       347\n",
      "\n",
      "    accuracy                           0.64       958\n",
      "   macro avg       0.58      0.51      0.42       958\n",
      "weighted avg       0.60      0.64      0.52       958\n",
      "\n",
      "Accuracy List Length : 1716\n",
      "HNNAZ   1982\n",
      "Accuracy: 0.7851239669421488\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88        96\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.79       121\n",
      "   macro avg       0.40      0.49      0.44       121\n",
      "weighted avg       0.63      0.79      0.70       121\n",
      "\n",
      "Accuracy List Length : 1717\n",
      "HNRG   1983\n",
      "Accuracy: 0.7420424403183024\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85      1125\n",
      "           1       0.29      0.01      0.02       383\n",
      "\n",
      "    accuracy                           0.74      1508\n",
      "   macro avg       0.52      0.50      0.44      1508\n",
      "weighted avg       0.63      0.74      0.64      1508\n",
      "\n",
      "Accuracy List Length : 1718\n",
      "HNST   1984\n",
      "Accuracy: 0.6\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.74        83\n",
      "           1       0.75      0.10      0.17        62\n",
      "\n",
      "    accuracy                           0.60       145\n",
      "   macro avg       0.67      0.54      0.45       145\n",
      "weighted avg       0.66      0.60      0.49       145\n",
      "\n",
      "Accuracy List Length : 1719\n",
      "HNVR   1985\n",
      "Accuracy: 0.6021505376344086\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.93      0.74        57\n",
      "           1       0.43      0.08      0.14        36\n",
      "\n",
      "    accuracy                           0.60        93\n",
      "   macro avg       0.52      0.51      0.44        93\n",
      "weighted avg       0.54      0.60      0.51        93\n",
      "\n",
      "Accuracy List Length : 1720\n",
      "HOFT   1986\n",
      "Accuracy: 0.5018281535648994\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.13      0.21       552\n",
      "           1       0.50      0.88      0.64       542\n",
      "\n",
      "    accuracy                           0.50      1094\n",
      "   macro avg       0.51      0.51      0.42      1094\n",
      "weighted avg       0.51      0.50      0.42      1094\n",
      "\n",
      "Accuracy List Length : 1721\n",
      "HOFV   1987\n",
      "Accuracy: 0.6336633663366337\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.96      0.77       195\n",
      "           1       0.36      0.04      0.07       108\n",
      "\n",
      "    accuracy                           0.63       303\n",
      "   macro avg       0.50      0.50      0.42       303\n",
      "weighted avg       0.54      0.63      0.52       303\n",
      "\n",
      "Accuracy List Length : 1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HOFVW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLO   1989\n",
      "Accuracy: 0.5378787878787878\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69        70\n",
      "           1       0.67      0.03      0.06        62\n",
      "\n",
      "    accuracy                           0.54       132\n",
      "   macro avg       0.60      0.51      0.38       132\n",
      "weighted avg       0.60      0.54      0.40       132\n",
      "\n",
      "Accuracy List Length : 1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HOLOW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLX   1991\n",
      "Accuracy: 0.5250582750582751\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.93      0.67       894\n",
      "           1       0.53      0.08      0.14       822\n",
      "\n",
      "    accuracy                           0.53      1716\n",
      "   macro avg       0.53      0.51      0.41      1716\n",
      "weighted avg       0.53      0.53      0.42      1716\n",
      "\n",
      "Accuracy List Length : 1724\n",
      "HON   1992\n",
      "Accuracy: 0.5258620689655172\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.92      0.67      1672\n",
      "           1       0.45      0.08      0.14      1460\n",
      "\n",
      "    accuracy                           0.53      3132\n",
      "   macro avg       0.49      0.50      0.40      3132\n",
      "weighted avg       0.49      0.53      0.42      3132\n",
      "\n",
      "Accuracy List Length : 1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HONDW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HONE   1996\n",
      "Accuracy: 0.480719794344473\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.76      0.61       205\n",
      "           1       0.39      0.17      0.23       184\n",
      "\n",
      "    accuracy                           0.48       389\n",
      "   macro avg       0.45      0.46      0.42       389\n",
      "weighted avg       0.45      0.48      0.43       389\n",
      "\n",
      "Accuracy List Length : 1726\n",
      "HOOD   1997\n",
      "Accuracy: 0.5639097744360902\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.64        61\n",
      "           1       0.71      0.33      0.45        72\n",
      "\n",
      "    accuracy                           0.56       133\n",
      "   macro avg       0.61      0.58      0.55       133\n",
      "weighted avg       0.62      0.56      0.54       133\n",
      "\n",
      "Accuracy List Length : 1727\n",
      "HOOK   1998\n",
      "Accuracy: 0.5725806451612904\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       139\n",
      "           1       0.58      0.10      0.17       109\n",
      "\n",
      "    accuracy                           0.57       248\n",
      "   macro avg       0.58      0.52      0.44       248\n",
      "weighted avg       0.58      0.57      0.47       248\n",
      "\n",
      "Accuracy List Length : 1728\n",
      "HOPE   1999\n",
      "Accuracy: 0.5144376899696048\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66       674\n",
      "           1       0.52      0.07      0.13       642\n",
      "\n",
      "    accuracy                           0.51      1316\n",
      "   macro avg       0.52      0.50      0.40      1316\n",
      "weighted avg       0.52      0.51      0.40      1316\n",
      "\n",
      "Accuracy List Length : 1729\n",
      "HOTH   2000\n",
      "Accuracy: 0.56640625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       144\n",
      "           1       0.67      0.02      0.03       112\n",
      "\n",
      "    accuracy                           0.57       256\n",
      "   macro avg       0.62      0.51      0.38       256\n",
      "weighted avg       0.61      0.57      0.42       256\n",
      "\n",
      "Accuracy List Length : 1730\n",
      "HOUR   2001\n",
      "Accuracy: 0.5454545454545454\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71        61\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.55       110\n",
      "   macro avg       0.28      0.49      0.35       110\n",
      "weighted avg       0.31      0.55      0.39       110\n",
      "\n",
      "Accuracy List Length : 1731\n",
      "HOVNP   2002\n",
      "Accuracy: 0.5928338762214984\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       544\n",
      "           1       0.62      0.01      0.03       377\n",
      "\n",
      "    accuracy                           0.59       921\n",
      "   macro avg       0.61      0.50      0.38       921\n",
      "weighted avg       0.61      0.59      0.45       921\n",
      "\n",
      "Accuracy List Length : 1732\n",
      "HOVR   2003\n",
      "Accuracy: 0.5102040816326531\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.96      0.67        25\n",
      "           1       0.50      0.04      0.08        24\n",
      "\n",
      "    accuracy                           0.51        49\n",
      "   macro avg       0.51      0.50      0.37        49\n",
      "weighted avg       0.51      0.51      0.38        49\n",
      "\n",
      "Accuracy List Length : 1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HOVRW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOWL   2005\n",
      "Accuracy: 0.6137931034482759\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.94      0.75        89\n",
      "           1       0.50      0.09      0.15        56\n",
      "\n",
      "    accuracy                           0.61       145\n",
      "   macro avg       0.56      0.52      0.45       145\n",
      "weighted avg       0.58      0.61      0.52       145\n",
      "\n",
      "Accuracy List Length : 1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPAIW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPH   2008\n",
      "Accuracy: 0.5776892430278885\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.73       154\n",
      "           1       0.26      0.05      0.09        97\n",
      "\n",
      "    accuracy                           0.58       251\n",
      "   macro avg       0.43      0.48      0.41       251\n",
      "weighted avg       0.47      0.58      0.48       251\n",
      "\n",
      "Accuracy List Length : 1735\n",
      "HPK   2009\n",
      "Accuracy: 0.43686006825938567\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.80      0.58       143\n",
      "           1       0.32      0.09      0.14       150\n",
      "\n",
      "    accuracy                           0.44       293\n",
      "   macro avg       0.39      0.45      0.36       293\n",
      "weighted avg       0.39      0.44      0.35       293\n",
      "\n",
      "Accuracy List Length : 1736\n",
      "HPKEW   2010\n",
      "Accuracy: 0.6815068493150684\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81       200\n",
      "           1       0.45      0.05      0.10        92\n",
      "\n",
      "    accuracy                           0.68       292\n",
      "   macro avg       0.57      0.51      0.45       292\n",
      "weighted avg       0.62      0.68      0.58       292\n",
      "\n",
      "Accuracy List Length : 1737\n",
      "HQGO   2011\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50         5\n",
      "           1       0.73      0.89      0.80         9\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.70      0.64      0.65        14\n",
      "weighted avg       0.71      0.71      0.69        14\n",
      "\n",
      "Accuracy List Length : 1738\n",
      "HQI   2012\n",
      "Accuracy: 0.6650485436893204\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       688\n",
      "           1       0.33      0.01      0.02       342\n",
      "\n",
      "    accuracy                           0.67      1030\n",
      "   macro avg       0.50      0.50      0.41      1030\n",
      "weighted avg       0.56      0.67      0.54      1030\n",
      "\n",
      "Accuracy List Length : 1739\n",
      "HQY   2013\n",
      "Accuracy: 0.5319587628865979\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.06      0.10       224\n",
      "           1       0.54      0.94      0.68       261\n",
      "\n",
      "    accuracy                           0.53       485\n",
      "   macro avg       0.49      0.50      0.39       485\n",
      "weighted avg       0.50      0.53      0.42       485\n",
      "\n",
      "Accuracy List Length : 1740\n",
      "HRMY   2014\n",
      "Accuracy: 0.48333333333333334\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.64        89\n",
      "           1       0.38      0.03      0.06        91\n",
      "\n",
      "    accuracy                           0.48       180\n",
      "   macro avg       0.43      0.49      0.35       180\n",
      "weighted avg       0.43      0.48      0.35       180\n",
      "\n",
      "Accuracy List Length : 1741\n",
      "HROW   2015\n",
      "Accuracy: 0.6417370325693607\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78       532\n",
      "           1       0.50      0.00      0.01       297\n",
      "\n",
      "    accuracy                           0.64       829\n",
      "   macro avg       0.57      0.50      0.39       829\n",
      "weighted avg       0.59      0.64      0.50       829\n",
      "\n",
      "Accuracy List Length : 1742\n",
      "HROWL   2016\n",
      "Accuracy: 0.4513888888888889\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.82      0.60        72\n",
      "           1       0.32      0.08      0.13        72\n",
      "\n",
      "    accuracy                           0.45       144\n",
      "   macro avg       0.39      0.45      0.37       144\n",
      "weighted avg       0.39      0.45      0.37       144\n",
      "\n",
      "Accuracy List Length : 1743\n",
      "HROWM   2017\n",
      "Accuracy: 0.4262295081967213\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.69      0.53        29\n",
      "           1       0.40      0.19      0.26        32\n",
      "\n",
      "    accuracy                           0.43        61\n",
      "   macro avg       0.42      0.44      0.39        61\n",
      "weighted avg       0.42      0.43      0.39        61\n",
      "\n",
      "Accuracy List Length : 1744\n",
      "HRTS   2018\n",
      "Accuracy: 0.4375\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         9\n",
      "           1       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.44        16\n",
      "   macro avg       0.38      0.40      0.38        16\n",
      "weighted avg       0.39      0.44      0.40        16\n",
      "\n",
      "Accuracy List Length : 1745\n",
      "HRTX   2019\n",
      "Accuracy: 0.5903418339663592\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74      1089\n",
      "           1       0.33      0.00      0.00       754\n",
      "\n",
      "    accuracy                           0.59      1843\n",
      "   macro avg       0.46      0.50      0.37      1843\n",
      "weighted avg       0.49      0.59      0.44      1843\n",
      "\n",
      "Accuracy List Length : 1746\n",
      "HRYU   2020\n",
      "Accuracy: 0.53125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.37      0.48        19\n",
      "           1       0.45      0.77      0.57        13\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.58      0.57      0.53        32\n",
      "weighted avg       0.60      0.53      0.52        32\n",
      "\n",
      "Accuracy List Length : 1747\n",
      "HRZN   2021\n",
      "Accuracy: 0.48813056379821956\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.03      0.05       340\n",
      "           1       0.49      0.96      0.65       334\n",
      "\n",
      "    accuracy                           0.49       674\n",
      "   macro avg       0.44      0.49      0.35       674\n",
      "weighted avg       0.44      0.49      0.35       674\n",
      "\n",
      "Accuracy List Length : 1748\n",
      "HSAI   2022\n",
      "Accuracy: 0.5357142857142857\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.21      0.32        28\n",
      "           1       0.52      0.86      0.65        28\n",
      "\n",
      "    accuracy                           0.54        56\n",
      "   macro avg       0.56      0.54      0.48        56\n",
      "weighted avg       0.56      0.54      0.48        56\n",
      "\n",
      "Accuracy List Length : 1749\n",
      "HSCS   2023\n",
      "Accuracy: 0.5454545454545454\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70        48\n",
      "           1       0.50      0.03      0.05        40\n",
      "\n",
      "    accuracy                           0.55        88\n",
      "   macro avg       0.52      0.50      0.37        88\n",
      "weighted avg       0.53      0.55      0.40        88\n",
      "\n",
      "Accuracy List Length : 1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HSCSW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSDT   2025\n",
      "Accuracy: 0.5591836734693878\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72       273\n",
      "           1       0.67      0.01      0.02       217\n",
      "\n",
      "    accuracy                           0.56       490\n",
      "   macro avg       0.61      0.50      0.37       490\n",
      "weighted avg       0.61      0.56      0.41       490\n",
      "\n",
      "Accuracy List Length : 1751\n",
      "HSIC   2026\n",
      "Accuracy: 0.47549019607843135\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.86      0.61       681\n",
      "           1       0.49      0.13      0.20       747\n",
      "\n",
      "    accuracy                           0.48      1428\n",
      "   macro avg       0.48      0.49      0.41      1428\n",
      "weighted avg       0.48      0.48      0.40      1428\n",
      "\n",
      "Accuracy List Length : 1752\n",
      "HSII   2027\n",
      "Accuracy: 0.5203511572226656\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.92      0.66       639\n",
      "           1       0.55      0.11      0.18       614\n",
      "\n",
      "    accuracy                           0.52      1253\n",
      "   macro avg       0.54      0.51      0.42      1253\n",
      "weighted avg       0.53      0.52      0.43      1253\n",
      "\n",
      "Accuracy List Length : 1753\n",
      "HSON   2028\n",
      "Accuracy: 0.5321361058601134\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.69       577\n",
      "           1       0.37      0.04      0.07       481\n",
      "\n",
      "    accuracy                           0.53      1058\n",
      "   macro avg       0.46      0.49      0.38      1058\n",
      "weighted avg       0.46      0.53      0.41      1058\n",
      "\n",
      "Accuracy List Length : 1754\n",
      "HSPO   2029\n",
      "Accuracy: 0.6724137931034483\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        39\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.67        58\n",
      "   macro avg       0.34      0.50      0.40        58\n",
      "weighted avg       0.45      0.67      0.54        58\n",
      "\n",
      "Accuracy List Length : 1755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "HSPOR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSPOU   2031\n",
      "Accuracy: 0.9354838709677419\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        58\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.94        62\n",
      "   macro avg       0.47      0.50      0.48        62\n",
      "weighted avg       0.88      0.94      0.90        62\n",
      "\n",
      "Accuracy List Length : 1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "HSPOW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HST   2034\n",
      "Accuracy: 0.5389815232086526\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.93      0.68      1186\n",
      "           1       0.53      0.09      0.16      1033\n",
      "\n",
      "    accuracy                           0.54      2219\n",
      "   macro avg       0.53      0.51      0.42      2219\n",
      "weighted avg       0.53      0.54      0.44      2219\n",
      "\n",
      "Accuracy List Length : 1757\n",
      "HSTM   2035\n",
      "Accuracy: 0.5062240663900415\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.94      0.66       611\n",
      "           1       0.49      0.06      0.11       594\n",
      "\n",
      "    accuracy                           0.51      1205\n",
      "   macro avg       0.50      0.50      0.39      1205\n",
      "weighted avg       0.50      0.51      0.39      1205\n",
      "\n",
      "Accuracy List Length : 1758\n",
      "HTBI   2036\n",
      "Accuracy: 0.5187074829931972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.90      0.67       315\n",
      "           1       0.40      0.08      0.13       273\n",
      "\n",
      "    accuracy                           0.52       588\n",
      "   macro avg       0.47      0.49      0.40       588\n",
      "weighted avg       0.47      0.52      0.42       588\n",
      "\n",
      "Accuracy List Length : 1759\n",
      "HTBK   2037\n",
      "Accuracy: 0.5441176470588235\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69       696\n",
      "           1       0.56      0.06      0.10       596\n",
      "\n",
      "    accuracy                           0.54      1292\n",
      "   macro avg       0.55      0.51      0.40      1292\n",
      "weighted avg       0.55      0.54      0.42      1292\n",
      "\n",
      "Accuracy List Length : 1760\n",
      "HTCO   2038\n",
      "Accuracy: 0.584\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        69\n",
      "           1       1.00      0.07      0.13        56\n",
      "\n",
      "    accuracy                           0.58       125\n",
      "   macro avg       0.79      0.54      0.43       125\n",
      "weighted avg       0.76      0.58      0.46       125\n",
      "\n",
      "Accuracy List Length : 1761\n",
      "HTCR   2039\n",
      "Accuracy: 0.4811320754716981\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.55        60\n",
      "           1       0.40      0.37      0.38        46\n",
      "\n",
      "    accuracy                           0.48       106\n",
      "   macro avg       0.47      0.47      0.47       106\n",
      "weighted avg       0.48      0.48      0.48       106\n",
      "\n",
      "Accuracy List Length : 1762\n",
      "HTHT   2040\n",
      "Accuracy: 0.5071022727272727\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.95      0.66       355\n",
      "           1       0.53      0.06      0.11       349\n",
      "\n",
      "    accuracy                           0.51       704\n",
      "   macro avg       0.52      0.50      0.38       704\n",
      "weighted avg       0.52      0.51      0.39       704\n",
      "\n",
      "Accuracy List Length : 1763\n",
      "HTIA   2041\n",
      "Accuracy: 0.5255813953488372\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.91      0.65       103\n",
      "           1       0.68      0.17      0.27       112\n",
      "\n",
      "    accuracy                           0.53       215\n",
      "   macro avg       0.59      0.54      0.46       215\n",
      "weighted avg       0.59      0.53      0.45       215\n",
      "\n",
      "Accuracy List Length : 1764\n",
      "HTIBP   2042\n",
      "Accuracy: 0.5483870967741935\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.92      0.67        63\n",
      "           1       0.67      0.16      0.26        61\n",
      "\n",
      "    accuracy                           0.55       124\n",
      "   macro avg       0.60      0.54      0.47       124\n",
      "weighted avg       0.60      0.55      0.47       124\n",
      "\n",
      "Accuracy List Length : 1765\n",
      "HTLD   2043\n",
      "Accuracy: 0.5342538502389803\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69      1012\n",
      "           1       0.47      0.05      0.08       871\n",
      "\n",
      "    accuracy                           0.53      1883\n",
      "   macro avg       0.50      0.50      0.39      1883\n",
      "weighted avg       0.50      0.53      0.41      1883\n",
      "\n",
      "Accuracy List Length : 1766\n",
      "HTLF   2044\n",
      "Accuracy: 0.5673758865248227\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.71       710\n",
      "           1       0.58      0.07      0.12       559\n",
      "\n",
      "    accuracy                           0.57      1269\n",
      "   macro avg       0.57      0.51      0.42      1269\n",
      "weighted avg       0.57      0.57      0.45      1269\n",
      "\n",
      "Accuracy List Length : 1767\n",
      "HTLFP   2045\n",
      "Accuracy: 0.5238095238095238\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.82      0.64        96\n",
      "           1       0.54      0.22      0.31        93\n",
      "\n",
      "    accuracy                           0.52       189\n",
      "   macro avg       0.53      0.52      0.47       189\n",
      "weighted avg       0.53      0.52      0.48       189\n",
      "\n",
      "Accuracy List Length : 1768\n",
      "HTOO   2047\n",
      "Accuracy: 0.6060606060606061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75       101\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.61       165\n",
      "   macro avg       0.30      0.50      0.38       165\n",
      "weighted avg       0.37      0.61      0.46       165\n",
      "\n",
      "Accuracy List Length : 1769\n",
      "HTOOW   2048\n",
      "Accuracy: 0.6341463414634146\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.92      0.77       108\n",
      "           1       0.36      0.09      0.14        56\n",
      "\n",
      "    accuracy                           0.63       164\n",
      "   macro avg       0.51      0.50      0.46       164\n",
      "weighted avg       0.56      0.63      0.55       164\n",
      "\n",
      "Accuracy List Length : 1770\n",
      "HTZ   2049\n",
      "Accuracy: 0.46715328467153283\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.94      0.63        66\n",
      "           1       0.33      0.03      0.05        71\n",
      "\n",
      "    accuracy                           0.47       137\n",
      "   macro avg       0.40      0.48      0.34       137\n",
      "weighted avg       0.40      0.47      0.33       137\n",
      "\n",
      "Accuracy List Length : 1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTZWW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUBC   2051\n",
      "Accuracy: 0.5495495495495496\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.91      0.70        65\n",
      "           1       0.25      0.04      0.07        46\n",
      "\n",
      "    accuracy                           0.55       111\n",
      "   macro avg       0.41      0.48      0.39       111\n",
      "weighted avg       0.44      0.55      0.44       111\n",
      "\n",
      "Accuracy List Length : 1772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HUBCW: Period 'max' is invalid, must be one of ['1d', '5d']\n",
      "HUBCZ: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUBG   2054\n",
      "Accuracy: 0.5237420269312544\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.92      0.67       736\n",
      "           1       0.51      0.09      0.16       675\n",
      "\n",
      "    accuracy                           0.52      1411\n",
      "   macro avg       0.52      0.51      0.41      1411\n",
      "weighted avg       0.52      0.52      0.42      1411\n",
      "\n",
      "Accuracy List Length : 1773\n",
      "HUDA   2055\n",
      "Accuracy: 0.8225806451612904\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        51\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.82        62\n",
      "   macro avg       0.41      0.50      0.45        62\n",
      "weighted avg       0.68      0.82      0.74        62\n",
      "\n",
      "Accuracy List Length : 1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUDAR   2056\n",
      "Accuracy: 0.9193548387096774\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96        57\n",
      "           1       0.50      0.20      0.29         5\n",
      "\n",
      "    accuracy                           0.92        62\n",
      "   macro avg       0.72      0.59      0.62        62\n",
      "weighted avg       0.90      0.92      0.90        62\n",
      "\n",
      "Accuracy List Length : 1775\n",
      "HUDAU   2057\n",
      "Accuracy: 0.9583333333333334\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        69\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.96        72\n",
      "   macro avg       0.48      0.50      0.49        72\n",
      "weighted avg       0.92      0.96      0.94        72\n",
      "\n",
      "Accuracy List Length : 1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUDI   2058\n",
      "Accuracy: 0.5974842767295597\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75        95\n",
      "           1       0.50      0.02      0.03        64\n",
      "\n",
      "    accuracy                           0.60       159\n",
      "   macro avg       0.55      0.50      0.39       159\n",
      "weighted avg       0.56      0.60      0.46       159\n",
      "\n",
      "Accuracy List Length : 1777\n",
      "HUIZ   2060\n",
      "Accuracy: 0.6135265700483091\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.94      0.75       125\n",
      "           1       0.56      0.11      0.18        82\n",
      "\n",
      "    accuracy                           0.61       207\n",
      "   macro avg       0.59      0.53      0.47       207\n",
      "weighted avg       0.60      0.61      0.52       207\n",
      "\n",
      "Accuracy List Length : 1778\n",
      "HUMA   2061\n",
      "Accuracy: 0.536144578313253\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70        93\n",
      "           1       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.54       166\n",
      "   macro avg       0.27      0.48      0.35       166\n",
      "weighted avg       0.31      0.54      0.39       166\n",
      "\n",
      "Accuracy List Length : 1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HUMAW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HURA   2063\n",
      "Accuracy: 0.5985663082437276\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.75       336\n",
      "           1       0.40      0.02      0.03       222\n",
      "\n",
      "    accuracy                           0.60       558\n",
      "   macro avg       0.50      0.50      0.39       558\n",
      "weighted avg       0.52      0.60      0.46       558\n",
      "\n",
      "Accuracy List Length : 1780\n",
      "HURC   2064\n",
      "Accuracy: 0.6001821493624773\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.75      1311\n",
      "           1       0.56      0.04      0.07       885\n",
      "\n",
      "    accuracy                           0.60      2196\n",
      "   macro avg       0.58      0.51      0.41      2196\n",
      "weighted avg       0.59      0.60      0.47      2196\n",
      "\n",
      "Accuracy List Length : 1781\n",
      "HURN   2065\n",
      "Accuracy: 0.5102249488752556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.02      0.04       477\n",
      "           1       0.51      0.98      0.67       501\n",
      "\n",
      "    accuracy                           0.51       978\n",
      "   macro avg       0.48      0.50      0.36       978\n",
      "weighted avg       0.48      0.51      0.36       978\n",
      "\n",
      "Accuracy List Length : 1782\n",
      "HUT   2066\n",
      "Accuracy: 0.4967105263157895\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65       158\n",
      "           1       0.36      0.06      0.11       146\n",
      "\n",
      "    accuracy                           0.50       304\n",
      "   macro avg       0.43      0.48      0.38       304\n",
      "weighted avg       0.44      0.50      0.39       304\n",
      "\n",
      "Accuracy List Length : 1783\n",
      "HWBK   2068\n",
      "Accuracy: 0.6038647342995169\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       746\n",
      "           1       0.55      0.04      0.08       496\n",
      "\n",
      "    accuracy                           0.60      1242\n",
      "   macro avg       0.58      0.51      0.41      1242\n",
      "weighted avg       0.58      0.60      0.48      1242\n",
      "\n",
      "Accuracy List Length : 1784\n",
      "HWC   2069\n",
      "Accuracy: 0.4975786924939467\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.96      0.66       827\n",
      "           1       0.46      0.04      0.07       825\n",
      "\n",
      "    accuracy                           0.50      1652\n",
      "   macro avg       0.48      0.50      0.36      1652\n",
      "weighted avg       0.48      0.50      0.36      1652\n",
      "\n",
      "Accuracy List Length : 1785\n",
      "HWCPZ   2070\n",
      "Accuracy: 0.4656084656084656\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.07      0.12       102\n",
      "           1       0.46      0.93      0.62        87\n",
      "\n",
      "    accuracy                           0.47       189\n",
      "   macro avg       0.50      0.50      0.37       189\n",
      "weighted avg       0.50      0.47      0.35       189\n",
      "\n",
      "Accuracy List Length : 1786\n",
      "HWH   2071\n",
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.99      0.82        68\n",
      "           1       0.80      0.12      0.22        32\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.75      0.56      0.52       100\n",
      "weighted avg       0.74      0.71      0.63       100\n",
      "\n",
      "Accuracy List Length : 1787\n",
      "HWKN   2072\n",
      "Accuracy: 0.6575033799008563\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.96      0.79      1463\n",
      "           1       0.48      0.07      0.12       756\n",
      "\n",
      "    accuracy                           0.66      2219\n",
      "   macro avg       0.57      0.51      0.45      2219\n",
      "weighted avg       0.60      0.66      0.56      2219\n",
      "\n",
      "Accuracy List Length : 1788\n",
      "HYDR   2074\n",
      "Accuracy: 0.5555555555555556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70        73\n",
      "           1       0.67      0.06      0.12        62\n",
      "\n",
      "    accuracy                           0.56       135\n",
      "   macro avg       0.61      0.52      0.41       135\n",
      "weighted avg       0.60      0.56      0.43       135\n",
      "\n",
      "Accuracy List Length : 1789\n",
      "HYFM   2075\n",
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69        87\n",
      "           1       0.67      0.03      0.05        78\n",
      "\n",
      "    accuracy                           0.53       165\n",
      "   macro avg       0.60      0.51      0.37       165\n",
      "weighted avg       0.60      0.53      0.39       165\n",
      "\n",
      "Accuracy List Length : 1790\n",
      "HYLS   2076\n",
      "Accuracy: 0.518850987432675\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.03      0.06       267\n",
      "           1       0.52      0.97      0.68       290\n",
      "\n",
      "    accuracy                           0.52       557\n",
      "   macro avg       0.50      0.50      0.37       557\n",
      "weighted avg       0.50      0.52      0.38       557\n",
      "\n",
      "Accuracy List Length : 1791\n",
      "HYMC   2077\n",
      "Accuracy: 0.5511551155115512\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71       170\n",
      "           1       0.29      0.02      0.03       133\n",
      "\n",
      "    accuracy                           0.55       303\n",
      "   macro avg       0.42      0.49      0.37       303\n",
      "weighted avg       0.44      0.55      0.41       303\n",
      "\n",
      "Accuracy List Length : 1792\n",
      "HYMCL   2078\n",
      "Accuracy: 0.6206896551724138\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.76       109\n",
      "           1       0.33      0.02      0.03        65\n",
      "\n",
      "    accuracy                           0.62       174\n",
      "   macro avg       0.48      0.50      0.40       174\n",
      "weighted avg       0.52      0.62      0.49       174\n",
      "\n",
      "Accuracy List Length : 1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HYMCW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPR   2080\n",
      "Accuracy: 0.5822784810126582\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71        92\n",
      "           1       0.50      0.17      0.25        66\n",
      "\n",
      "    accuracy                           0.58       158\n",
      "   macro avg       0.55      0.52      0.48       158\n",
      "weighted avg       0.56      0.58      0.52       158\n",
      "\n",
      "Accuracy List Length : 1794\n",
      "HYXF   2081\n",
      "Accuracy: 0.5384615384615384\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.72      0.64       222\n",
      "           1       0.45      0.30      0.36       168\n",
      "\n",
      "    accuracy                           0.54       390\n",
      "   macro avg       0.51      0.51      0.50       390\n",
      "weighted avg       0.52      0.54      0.52       390\n",
      "\n",
      "Accuracy List Length : 1795\n",
      "HYZD   2082\n",
      "Accuracy: 0.5174418604651163\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.22      0.32       264\n",
      "           1       0.50      0.83      0.63       252\n",
      "\n",
      "    accuracy                           0.52       516\n",
      "   macro avg       0.54      0.52      0.47       516\n",
      "weighted avg       0.54      0.52      0.47       516\n",
      "\n",
      "Accuracy List Length : 1796\n",
      "HYZN   2083\n",
      "Accuracy: 0.5609756097560976\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.70        91\n",
      "           1       0.55      0.08      0.14        73\n",
      "\n",
      "    accuracy                           0.56       164\n",
      "   macro avg       0.55      0.51      0.42       164\n",
      "weighted avg       0.55      0.56      0.45       164\n",
      "\n",
      "Accuracy List Length : 1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HYZNW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAC   2085\n",
      "Accuracy: 0.5127388535031847\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.96      0.67       811\n",
      "           1       0.45      0.04      0.07       759\n",
      "\n",
      "    accuracy                           0.51      1570\n",
      "   macro avg       0.48      0.50      0.37      1570\n",
      "weighted avg       0.48      0.51      0.38      1570\n",
      "\n",
      "Accuracy List Length : 1798\n",
      "IART   2086\n",
      "Accuracy: 0.49583333333333335\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.90      0.64       728\n",
      "           1       0.45      0.09      0.15       712\n",
      "\n",
      "    accuracy                           0.50      1440\n",
      "   macro avg       0.48      0.49      0.39      1440\n",
      "weighted avg       0.48      0.50      0.40      1440\n",
      "\n",
      "Accuracy List Length : 1799\n",
      "IAS   2087\n",
      "Accuracy: 0.43795620437956206\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.74      0.54        62\n",
      "           1       0.47      0.19      0.27        75\n",
      "\n",
      "    accuracy                           0.44       137\n",
      "   macro avg       0.45      0.46      0.41       137\n",
      "weighted avg       0.45      0.44      0.39       137\n",
      "\n",
      "Accuracy List Length : 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IBACR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBB   2091\n",
      "Accuracy: 0.5258175559380379\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.01      0.03       550\n",
      "           1       0.53      0.99      0.69       612\n",
      "\n",
      "    accuracy                           0.53      1162\n",
      "   macro avg       0.50      0.50      0.36      1162\n",
      "weighted avg       0.50      0.53      0.37      1162\n",
      "\n",
      "Accuracy List Length : 1801\n",
      "IBBQ   2092\n",
      "Accuracy: 0.4857142857142857\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.13      0.20        70\n",
      "           1       0.49      0.84      0.62        70\n",
      "\n",
      "    accuracy                           0.49       140\n",
      "   macro avg       0.47      0.49      0.41       140\n",
      "weighted avg       0.47      0.49      0.41       140\n",
      "\n",
      "Accuracy List Length : 1802\n",
      "IBCP   2093\n",
      "Accuracy: 0.5774575398867731\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73      1112\n",
      "           1       0.59      0.04      0.07       831\n",
      "\n",
      "    accuracy                           0.58      1943\n",
      "   macro avg       0.58      0.51      0.40      1943\n",
      "weighted avg       0.58      0.58      0.45      1943\n",
      "\n",
      "Accuracy List Length : 1803\n",
      "IBEX   2094\n",
      "Accuracy: 0.46703296703296704\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.85      0.58        79\n",
      "           1       0.60      0.17      0.27       103\n",
      "\n",
      "    accuracy                           0.47       182\n",
      "   macro avg       0.52      0.51      0.43       182\n",
      "weighted avg       0.53      0.47      0.40       182\n",
      "\n",
      "Accuracy List Length : 1804\n",
      "IBIT   2098\n",
      "Accuracy: 0.4\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.29      0.40         7\n",
      "           1       0.29      0.67      0.40         3\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.48      0.48      0.40        10\n",
      "weighted avg       0.55      0.40      0.40        10\n",
      "\n",
      "Accuracy List Length : 1805\n",
      "IBKR   2099\n",
      "Accuracy: 0.49411764705882355\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.04       430\n",
      "           1       0.49      0.98      0.66       420\n",
      "\n",
      "    accuracy                           0.49       850\n",
      "   macro avg       0.50      0.50      0.35       850\n",
      "weighted avg       0.50      0.49      0.35       850\n",
      "\n",
      "Accuracy List Length : 1806\n",
      "IBOC   2100\n",
      "Accuracy: 0.541029207232267\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69       773\n",
      "           1       0.53      0.07      0.12       665\n",
      "\n",
      "    accuracy                           0.54      1438\n",
      "   macro avg       0.54      0.51      0.41      1438\n",
      "weighted avg       0.54      0.54      0.43      1438\n",
      "\n",
      "Accuracy List Length : 1807\n",
      "IBOT   2101\n",
      "Accuracy: 0.4791666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.27      0.36        26\n",
      "           1       0.46      0.73      0.56        22\n",
      "\n",
      "    accuracy                           0.48        48\n",
      "   macro avg       0.50      0.50      0.46        48\n",
      "weighted avg       0.50      0.48      0.45        48\n",
      "\n",
      "Accuracy List Length : 1808\n",
      "IBRX   2102\n",
      "Accuracy: 0.5494252873563218\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.70       243\n",
      "           1       0.36      0.03      0.05       192\n",
      "\n",
      "    accuracy                           0.55       435\n",
      "   macro avg       0.46      0.49      0.38       435\n",
      "weighted avg       0.47      0.55      0.42       435\n",
      "\n",
      "Accuracy List Length : 1809\n",
      "IBTE   2103\n",
      "Accuracy: 0.5049019607843137\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.93      0.67       110\n",
      "           1       0.11      0.01      0.02        94\n",
      "\n",
      "    accuracy                           0.50       204\n",
      "   macro avg       0.32      0.47      0.34       204\n",
      "weighted avg       0.33      0.50      0.37       204\n",
      "\n",
      "Accuracy List Length : 1810\n",
      "IBTF   2104\n",
      "Accuracy: 0.6127450980392157\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76       125\n",
      "           1       0.50      0.04      0.07        79\n",
      "\n",
      "    accuracy                           0.61       204\n",
      "   macro avg       0.56      0.51      0.41       204\n",
      "weighted avg       0.57      0.61      0.49       204\n",
      "\n",
      "Accuracy List Length : 1811\n",
      "IBTG   2105\n",
      "Accuracy: 0.553921568627451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       120\n",
      "           1       0.23      0.04      0.06        84\n",
      "\n",
      "    accuracy                           0.55       204\n",
      "   macro avg       0.40      0.48      0.38       204\n",
      "weighted avg       0.43      0.55      0.44       204\n",
      "\n",
      "Accuracy List Length : 1812\n",
      "IBTH   2106\n",
      "Accuracy: 0.5343137254901961\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.88      0.68       116\n",
      "           1       0.33      0.08      0.13        88\n",
      "\n",
      "    accuracy                           0.53       204\n",
      "   macro avg       0.45      0.48      0.41       204\n",
      "weighted avg       0.46      0.53      0.44       204\n",
      "\n",
      "Accuracy List Length : 1813\n",
      "IBTI   2107\n",
      "Accuracy: 0.5441176470588235\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.70       118\n",
      "           1       0.11      0.01      0.02        86\n",
      "\n",
      "    accuracy                           0.54       204\n",
      "   macro avg       0.34      0.47      0.36       204\n",
      "weighted avg       0.37      0.54      0.42       204\n",
      "\n",
      "Accuracy List Length : 1814\n",
      "IBTJ   2108\n",
      "Accuracy: 0.5049019607843137\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.88      0.66       113\n",
      "           1       0.22      0.04      0.07        91\n",
      "\n",
      "    accuracy                           0.50       204\n",
      "   macro avg       0.38      0.46      0.37       204\n",
      "weighted avg       0.39      0.50      0.40       204\n",
      "\n",
      "Accuracy List Length : 1815\n",
      "IBTK   2109\n",
      "Accuracy: 0.6324324324324324\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77       118\n",
      "           1       0.40      0.03      0.06        67\n",
      "\n",
      "    accuracy                           0.63       185\n",
      "   macro avg       0.52      0.50      0.41       185\n",
      "weighted avg       0.55      0.63      0.51       185\n",
      "\n",
      "Accuracy List Length : 1816\n",
      "IBTL   2110\n",
      "Accuracy: 0.4883720930232558\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.92      0.62        59\n",
      "           1       0.64      0.13      0.21        70\n",
      "\n",
      "    accuracy                           0.49       129\n",
      "   macro avg       0.56      0.52      0.42       129\n",
      "weighted avg       0.56      0.49      0.40       129\n",
      "\n",
      "Accuracy List Length : 1817\n",
      "IBTM   2111\n",
      "Accuracy: 0.5348837209302325\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.28      0.38        43\n",
      "           1       0.52      0.79      0.63        43\n",
      "\n",
      "    accuracy                           0.53        86\n",
      "   macro avg       0.55      0.53      0.50        86\n",
      "weighted avg       0.55      0.53      0.50        86\n",
      "\n",
      "Accuracy List Length : 1818\n",
      "IBTO   2112\n",
      "Accuracy: 0.5555555555555556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.53      0.50        15\n",
      "           1       0.63      0.57      0.60        21\n",
      "\n",
      "    accuracy                           0.56        36\n",
      "   macro avg       0.55      0.55      0.55        36\n",
      "weighted avg       0.56      0.56      0.56        36\n",
      "\n",
      "Accuracy List Length : 1819\n",
      "IBTX   2114\n",
      "Accuracy: 0.4945652173913043\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.93      0.64       264\n",
      "           1       0.60      0.09      0.16       288\n",
      "\n",
      "    accuracy                           0.49       552\n",
      "   macro avg       0.54      0.51      0.40       552\n",
      "weighted avg       0.55      0.49      0.39       552\n",
      "\n",
      "Accuracy List Length : 1820\n",
      "ICAD   2115\n",
      "Accuracy: 0.5886811520970187\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74      1165\n",
      "           1       0.50      0.00      0.00       814\n",
      "\n",
      "    accuracy                           0.59      1979\n",
      "   macro avg       0.54      0.50      0.37      1979\n",
      "weighted avg       0.55      0.59      0.44      1979\n",
      "\n",
      "Accuracy List Length : 1821\n",
      "ICCC   2116\n",
      "Accuracy: 0.6686390532544378\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80      1244\n",
      "           1       0.00      0.00      0.00       615\n",
      "\n",
      "    accuracy                           0.67      1859\n",
      "   macro avg       0.33      0.50      0.40      1859\n",
      "weighted avg       0.45      0.67      0.54      1859\n",
      "\n",
      "Accuracy List Length : 1822\n",
      "ICCH   2117\n",
      "Accuracy: 0.8034188034188035\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       279\n",
      "           1       0.80      0.06      0.10        72\n",
      "\n",
      "    accuracy                           0.80       351\n",
      "   macro avg       0.80      0.53      0.50       351\n",
      "weighted avg       0.80      0.80      0.73       351\n",
      "\n",
      "Accuracy List Length : 1823\n",
      "ICCM   2118\n",
      "Accuracy: 0.5581395348837209\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70        72\n",
      "           1       0.50      0.07      0.12        57\n",
      "\n",
      "    accuracy                           0.56       129\n",
      "   macro avg       0.53      0.51      0.41       129\n",
      "weighted avg       0.53      0.56      0.45       129\n",
      "\n",
      "Accuracy List Length : 1824\n",
      "ICCT   2119\n",
      "Accuracy: 0.6071428571428571\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        17\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.30      0.50      0.38        28\n",
      "weighted avg       0.37      0.61      0.46        28\n",
      "\n",
      "Accuracy List Length : 1825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICFI   2120\n",
      "Accuracy: 0.5079545454545454\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.03      0.05       429\n",
      "           1       0.51      0.96      0.67       451\n",
      "\n",
      "    accuracy                           0.51       880\n",
      "   macro avg       0.47      0.50      0.36       880\n",
      "weighted avg       0.47      0.51      0.37       880\n",
      "\n",
      "Accuracy List Length : 1826\n",
      "ICG   2121\n",
      "Accuracy: 0.5098039215686274\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67        30\n",
      "           1       0.17      0.05      0.07        21\n",
      "\n",
      "    accuracy                           0.51        51\n",
      "   macro avg       0.36      0.44      0.37        51\n",
      "weighted avg       0.40      0.51      0.42        51\n",
      "\n",
      "Accuracy List Length : 1827\n",
      "ICHR   2122\n",
      "Accuracy: 0.4781420765027322\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.12      0.19       188\n",
      "           1       0.48      0.86      0.62       178\n",
      "\n",
      "    accuracy                           0.48       366\n",
      "   macro avg       0.47      0.49      0.40       366\n",
      "weighted avg       0.47      0.48      0.40       366\n",
      "\n",
      "Accuracy List Length : 1828\n",
      "ICLK   2123\n",
      "Accuracy: 0.4840764331210191\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.93      0.64       151\n",
      "           1       0.52      0.07      0.12       163\n",
      "\n",
      "    accuracy                           0.48       314\n",
      "   macro avg       0.50      0.50      0.38       314\n",
      "weighted avg       0.50      0.48      0.37       314\n",
      "\n",
      "Accuracy List Length : 1829\n",
      "ICLN   2124\n",
      "Accuracy: 0.51010101010101\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66       401\n",
      "           1       0.52      0.08      0.15       391\n",
      "\n",
      "    accuracy                           0.51       792\n",
      "   macro avg       0.52      0.50      0.40       792\n",
      "weighted avg       0.52      0.51      0.40       792\n",
      "\n",
      "Accuracy List Length : 1830\n",
      "ICLR   2125\n",
      "Accuracy: 0.49884704073789393\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.91      0.65       667\n",
      "           1       0.42      0.07      0.12       634\n",
      "\n",
      "    accuracy                           0.50      1301\n",
      "   macro avg       0.46      0.49      0.38      1301\n",
      "weighted avg       0.46      0.50      0.39      1301\n",
      "\n",
      "Accuracy List Length : 1831\n",
      "ICMB   2126\n",
      "Accuracy: 0.5481335952848723\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.93      0.69       279\n",
      "           1       0.50      0.08      0.14       230\n",
      "\n",
      "    accuracy                           0.55       509\n",
      "   macro avg       0.53      0.51      0.42       509\n",
      "weighted avg       0.53      0.55      0.44       509\n",
      "\n",
      "Accuracy List Length : 1832\n",
      "ICOP   2128\n",
      "Accuracy: 0.5675675675675675\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67        20\n",
      "           1       0.56      0.29      0.38        17\n",
      "\n",
      "    accuracy                           0.57        37\n",
      "   macro avg       0.56      0.55      0.53        37\n",
      "weighted avg       0.56      0.57      0.54        37\n",
      "\n",
      "Accuracy List Length : 1833\n",
      "ICU   2129\n",
      "Accuracy: 0.6357615894039735\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.78        97\n",
      "           1       0.33      0.02      0.04        54\n",
      "\n",
      "    accuracy                           0.64       151\n",
      "   macro avg       0.49      0.50      0.41       151\n",
      "weighted avg       0.53      0.64      0.51       151\n",
      "\n",
      "Accuracy List Length : 1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ICUCW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICUI   2131\n",
      "Accuracy: 0.5180124223602485\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.88      0.66       865\n",
      "           1       0.41      0.10      0.16       745\n",
      "\n",
      "    accuracy                           0.52      1610\n",
      "   macro avg       0.47      0.49      0.41      1610\n",
      "weighted avg       0.48      0.52      0.43      1610\n",
      "\n",
      "Accuracy List Length : 1835\n",
      "IDAI   2132\n",
      "Accuracy: 0.567741935483871\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.72        90\n",
      "           1       0.25      0.02      0.03        65\n",
      "\n",
      "    accuracy                           0.57       155\n",
      "   macro avg       0.41      0.49      0.38       155\n",
      "weighted avg       0.44      0.57      0.43       155\n",
      "\n",
      "Accuracy List Length : 1836\n",
      "IDCC   2133\n",
      "Accuracy: 0.5620608899297423\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71      1202\n",
      "           1       0.49      0.06      0.11       933\n",
      "\n",
      "    accuracy                           0.56      2135\n",
      "   macro avg       0.53      0.51      0.41      2135\n",
      "weighted avg       0.53      0.56      0.45      2135\n",
      "\n",
      "Accuracy List Length : 1837\n",
      "IDN   2134\n",
      "Accuracy: 0.5424836601307189\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70       661\n",
      "           1       0.56      0.02      0.05       563\n",
      "\n",
      "    accuracy                           0.54      1224\n",
      "   macro avg       0.55      0.50      0.37      1224\n",
      "weighted avg       0.55      0.54      0.40      1224\n",
      "\n",
      "Accuracy List Length : 1838\n",
      "IDXX   2135\n",
      "Accuracy: 0.48787878787878786\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.01      0.03       838\n",
      "           1       0.49      0.98      0.65       812\n",
      "\n",
      "    accuracy                           0.49      1650\n",
      "   macro avg       0.44      0.50      0.34      1650\n",
      "weighted avg       0.44      0.49      0.34      1650\n",
      "\n",
      "Accuracy List Length : 1839\n",
      "IDYA   2136\n",
      "Accuracy: 0.5720164609053497\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.22      0.32       110\n",
      "           1       0.57      0.86      0.69       133\n",
      "\n",
      "    accuracy                           0.57       243\n",
      "   macro avg       0.57      0.54      0.50       243\n",
      "weighted avg       0.57      0.57      0.52       243\n",
      "\n",
      "Accuracy List Length : 1840\n",
      "IEF   2137\n",
      "Accuracy: 0.5165137614678899\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.05      0.10       532\n",
      "           1       0.51      0.96      0.67       558\n",
      "\n",
      "    accuracy                           0.52      1090\n",
      "   macro avg       0.53      0.51      0.38      1090\n",
      "weighted avg       0.53      0.52      0.39      1090\n",
      "\n",
      "Accuracy List Length : 1841\n",
      "IEI   2138\n",
      "Accuracy: 0.5121387283236994\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.03      0.05       423\n",
      "           1       0.51      0.98      0.67       442\n",
      "\n",
      "    accuracy                           0.51       865\n",
      "   macro avg       0.52      0.50      0.36       865\n",
      "weighted avg       0.52      0.51      0.37       865\n",
      "\n",
      "Accuracy List Length : 1842\n",
      "IEP   2139\n",
      "Accuracy: 0.5714285714285714\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72      1052\n",
      "           1       0.53      0.05      0.09       796\n",
      "\n",
      "    accuracy                           0.57      1848\n",
      "   macro avg       0.55      0.51      0.40      1848\n",
      "weighted avg       0.55      0.57      0.45      1848\n",
      "\n",
      "Accuracy List Length : 1843\n",
      "IESC   2140\n",
      "Accuracy: 0.5189969604863222\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.91      0.66       686\n",
      "           1       0.49      0.09      0.15       630\n",
      "\n",
      "    accuracy                           0.52      1316\n",
      "   macro avg       0.50      0.50      0.41      1316\n",
      "weighted avg       0.51      0.52      0.42      1316\n",
      "\n",
      "Accuracy List Length : 1844\n",
      "IEUS   2141\n",
      "Accuracy: 0.5267639902676399\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.02      0.04       391\n",
      "           1       0.53      0.99      0.69       431\n",
      "\n",
      "    accuracy                           0.53       822\n",
      "   macro avg       0.55      0.50      0.36       822\n",
      "weighted avg       0.55      0.53      0.38       822\n",
      "\n",
      "Accuracy List Length : 1845\n",
      "IFBD   2142\n",
      "Accuracy: 0.5714285714285714\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.72        88\n",
      "           1       0.17      0.02      0.03        59\n",
      "\n",
      "    accuracy                           0.57       147\n",
      "   macro avg       0.38      0.48      0.38       147\n",
      "weighted avg       0.42      0.57      0.45       147\n",
      "\n",
      "Accuracy List Length : 1846\n",
      "IFGL   2143\n",
      "Accuracy: 0.5206812652068127\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.02      0.04       390\n",
      "           1       0.52      0.97      0.68       432\n",
      "\n",
      "    accuracy                           0.52       822\n",
      "   macro avg       0.46      0.50      0.36       822\n",
      "weighted avg       0.47      0.52      0.38       822\n",
      "\n",
      "Accuracy List Length : 1847\n",
      "IFRX   2144\n",
      "Accuracy: 0.565625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       185\n",
      "           1       0.41      0.07      0.11       135\n",
      "\n",
      "    accuracy                           0.57       320\n",
      "   macro avg       0.49      0.50      0.41       320\n",
      "weighted avg       0.51      0.57      0.46       320\n",
      "\n",
      "Accuracy List Length : 1848\n",
      "IFV   2145\n",
      "Accuracy: 0.5041152263374485\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.09      0.15       245\n",
      "           1       0.50      0.93      0.65       241\n",
      "\n",
      "    accuracy                           0.50       486\n",
      "   macro avg       0.53      0.51      0.40       486\n",
      "weighted avg       0.53      0.50      0.40       486\n",
      "\n",
      "Accuracy List Length : 1849\n",
      "IGF   2146\n",
      "Accuracy: 0.5238095238095238\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.01      0.01       391\n",
      "           1       0.52      1.00      0.69       428\n",
      "\n",
      "    accuracy                           0.52       819\n",
      "   macro avg       0.59      0.50      0.35       819\n",
      "weighted avg       0.59      0.52      0.36       819\n",
      "\n",
      "Accuracy List Length : 1850\n",
      "IGIB   2147\n",
      "Accuracy: 0.5468208092485549\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.02       392\n",
      "           1       0.55      0.99      0.70       473\n",
      "\n",
      "    accuracy                           0.55       865\n",
      "   macro avg       0.52      0.50      0.36       865\n",
      "weighted avg       0.53      0.55      0.40       865\n",
      "\n",
      "Accuracy List Length : 1851\n",
      "IGIC   2148\n",
      "Accuracy: 0.5518394648829431\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.90      0.70       172\n",
      "           1       0.37      0.08      0.13       127\n",
      "\n",
      "    accuracy                           0.55       299\n",
      "   macro avg       0.47      0.49      0.41       299\n",
      "weighted avg       0.49      0.55      0.46       299\n",
      "\n",
      "Accuracy List Length : 1852\n",
      "IGMS   2149\n",
      "Accuracy: 0.5198237885462555\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.68       125\n",
      "           1       0.11      0.01      0.02       102\n",
      "\n",
      "    accuracy                           0.52       227\n",
      "   macro avg       0.32      0.47      0.35       227\n",
      "weighted avg       0.35      0.52      0.38       227\n",
      "\n",
      "Accuracy List Length : 1853\n",
      "IGOV   2150\n",
      "Accuracy: 0.4816272965879265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.91      0.63       364\n",
      "           1       0.52      0.09      0.15       398\n",
      "\n",
      "    accuracy                           0.48       762\n",
      "   macro avg       0.50      0.50      0.39       762\n",
      "weighted avg       0.50      0.48      0.38       762\n",
      "\n",
      "Accuracy List Length : 1854\n",
      "IGSB   2151\n",
      "Accuracy: 0.5433526011560693\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.03      0.05       396\n",
      "           1       0.54      0.98      0.70       469\n",
      "\n",
      "    accuracy                           0.54       865\n",
      "   macro avg       0.54      0.50      0.37       865\n",
      "weighted avg       0.54      0.54      0.40       865\n",
      "\n",
      "Accuracy List Length : 1855\n",
      "IGTA   2152\n",
      "Accuracy: 0.7339449541284404\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        80\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.73       109\n",
      "   macro avg       0.37      0.50      0.42       109\n",
      "weighted avg       0.54      0.73      0.62       109\n",
      "\n",
      "Accuracy List Length : 1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "IGTAR: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGTAU   2154\n",
      "Accuracy: 0.9649122807017544\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       110\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.48      0.50      0.49       114\n",
      "weighted avg       0.93      0.96      0.95       114\n",
      "\n",
      "Accuracy List Length : 1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "IGTAW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IHRT   2156\n",
      "Accuracy: 0.47478991596638653\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.91      0.64       121\n",
      "           1       0.21      0.03      0.05       117\n",
      "\n",
      "    accuracy                           0.47       238\n",
      "   macro avg       0.35      0.47      0.34       238\n",
      "weighted avg       0.36      0.47      0.35       238\n",
      "\n",
      "Accuracy List Length : 1858\n",
      "IHYF   2157\n",
      "Accuracy: 0.49696969696969695\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.97      0.65        78\n",
      "           1       0.75      0.07      0.13        87\n",
      "\n",
      "    accuracy                           0.50       165\n",
      "   macro avg       0.62      0.52      0.39       165\n",
      "weighted avg       0.62      0.50      0.37       165\n",
      "\n",
      "Accuracy List Length : 1859\n",
      "III   2158\n",
      "Accuracy: 0.5435540069686411\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69       492\n",
      "           1       0.33      0.06      0.10       369\n",
      "\n",
      "    accuracy                           0.54       861\n",
      "   macro avg       0.45      0.48      0.40       861\n",
      "weighted avg       0.46      0.54      0.44       861\n",
      "\n",
      "Accuracy List Length : 1860\n",
      "IIIV   2159\n",
      "Accuracy: 0.5051903114186851\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.85      0.62       137\n",
      "           1       0.59      0.19      0.29       152\n",
      "\n",
      "    accuracy                           0.51       289\n",
      "   macro avg       0.54      0.52      0.45       289\n",
      "weighted avg       0.54      0.51      0.45       289\n",
      "\n",
      "Accuracy List Length : 1861\n",
      "IINN   2160\n",
      "Accuracy: 0.5777777777777777\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72        75\n",
      "           1       0.80      0.07      0.12        60\n",
      "\n",
      "    accuracy                           0.58       135\n",
      "   macro avg       0.68      0.53      0.42       135\n",
      "weighted avg       0.67      0.58      0.46       135\n",
      "\n",
      "Accuracy List Length : 1862\n",
      "IINNW   2161\n",
      "Accuracy: 0.7407407407407407\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       100\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.74       135\n",
      "   macro avg       0.37      0.50      0.43       135\n",
      "weighted avg       0.55      0.74      0.63       135\n",
      "\n",
      "Accuracy List Length : 1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IJT   2162\n",
      "Accuracy: 0.5226890756302521\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.01      0.03       569\n",
      "           1       0.52      0.99      0.68       621\n",
      "\n",
      "    accuracy                           0.52      1190\n",
      "   macro avg       0.53      0.50      0.36      1190\n",
      "weighted avg       0.53      0.52      0.37      1190\n",
      "\n",
      "Accuracy List Length : 1864\n",
      "IKNA   2163\n",
      "Accuracy: 0.6066666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.97      0.75        92\n",
      "           1       0.40      0.03      0.06        58\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.51      0.50      0.41       150\n",
      "weighted avg       0.53      0.61      0.49       150\n",
      "\n",
      "Accuracy List Length : 1865\n",
      "IKT   2164\n",
      "Accuracy: 0.6319018404907976\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76       104\n",
      "           1       0.47      0.12      0.19        59\n",
      "\n",
      "    accuracy                           0.63       163\n",
      "   macro avg       0.56      0.52      0.48       163\n",
      "weighted avg       0.58      0.63      0.55       163\n",
      "\n",
      "Accuracy List Length : 1866\n",
      "ILAG   2165\n",
      "Accuracy: 0.5529411764705883\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.90      0.69        48\n",
      "           1       0.44      0.11      0.17        37\n",
      "\n",
      "    accuracy                           0.55        85\n",
      "   macro avg       0.51      0.50      0.43        85\n",
      "weighted avg       0.51      0.55      0.47        85\n",
      "\n",
      "Accuracy List Length : 1867\n",
      "ILIT   2166\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.95      0.67        19\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.50        36\n",
      "   macro avg       0.26      0.47      0.33        36\n",
      "weighted avg       0.27      0.50      0.35        36\n",
      "\n",
      "Accuracy List Length : 1868\n",
      "ILLR   2167\n",
      "Accuracy: 0.6837606837606838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81       158\n",
      "           1       1.00      0.03      0.05        76\n",
      "\n",
      "    accuracy                           0.68       234\n",
      "   macro avg       0.84      0.51      0.43       234\n",
      "weighted avg       0.78      0.68      0.56       234\n",
      "\n",
      "Accuracy List Length : 1869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ILLRW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILMN   2169\n",
      "Accuracy: 0.5243697478991597\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.04      0.07       569\n",
      "           1       0.52      0.97      0.68       621\n",
      "\n",
      "    accuracy                           0.52      1190\n",
      "   macro avg       0.53      0.50      0.38      1190\n",
      "weighted avg       0.53      0.52      0.39      1190\n",
      "\n",
      "Accuracy List Length : 1870\n",
      "ILPT   2170\n",
      "Accuracy: 0.5016077170418006\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.96      0.65       148\n",
      "           1       0.70      0.09      0.15       163\n",
      "\n",
      "    accuracy                           0.50       311\n",
      "   macro avg       0.59      0.52      0.40       311\n",
      "weighted avg       0.60      0.50      0.39       311\n",
      "\n",
      "Accuracy List Length : 1871\n",
      "IMAB   2171\n",
      "Accuracy: 0.5714285714285714\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.72       123\n",
      "           1       0.38      0.06      0.10        87\n",
      "\n",
      "    accuracy                           0.57       210\n",
      "   macro avg       0.48      0.50      0.41       210\n",
      "weighted avg       0.50      0.57      0.46       210\n",
      "\n",
      "Accuracy List Length : 1872\n",
      "IMCC   2172\n",
      "Accuracy: 0.6113989637305699\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.97      0.75       118\n",
      "           1       0.50      0.04      0.07        75\n",
      "\n",
      "    accuracy                           0.61       193\n",
      "   macro avg       0.56      0.51      0.41       193\n",
      "weighted avg       0.57      0.61      0.49       193\n",
      "\n",
      "Accuracy List Length : 1873\n",
      "IMCR   2173\n",
      "Accuracy: 0.5477707006369427\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.79      0.66        86\n",
      "           1       0.50      0.25      0.34        71\n",
      "\n",
      "    accuracy                           0.55       157\n",
      "   macro avg       0.53      0.52      0.50       157\n",
      "weighted avg       0.53      0.55      0.51       157\n",
      "\n",
      "Accuracy List Length : 1874\n",
      "IMCV   2174\n",
      "Accuracy: 0.5489404641775983\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.05      0.09       450\n",
      "           1       0.55      0.96      0.70       541\n",
      "\n",
      "    accuracy                           0.55       991\n",
      "   macro avg       0.54      0.51      0.40       991\n",
      "weighted avg       0.54      0.55      0.42       991\n",
      "\n",
      "Accuracy List Length : 1875\n",
      "IMG   2175\n",
      "Accuracy: 0.6243386243386243\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.77       118\n",
      "           1       0.50      0.03      0.05        71\n",
      "\n",
      "    accuracy                           0.62       189\n",
      "   macro avg       0.56      0.51      0.41       189\n",
      "weighted avg       0.58      0.62      0.50       189\n",
      "\n",
      "Accuracy List Length : 1876\n",
      "IMKTA   2176\n",
      "Accuracy: 0.5415986949429038\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.94      0.69      1009\n",
      "           1       0.44      0.06      0.10       830\n",
      "\n",
      "    accuracy                           0.54      1839\n",
      "   macro avg       0.49      0.50      0.40      1839\n",
      "weighted avg       0.50      0.54      0.43      1839\n",
      "\n",
      "Accuracy List Length : 1877\n",
      "IMMP   2177\n",
      "Accuracy: 0.585\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       352\n",
      "           1       0.00      0.00      0.00       248\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.29      0.50      0.37       600\n",
      "weighted avg       0.34      0.58      0.43       600\n",
      "\n",
      "Accuracy List Length : 1878\n",
      "IMMR   2178\n",
      "Accuracy: 0.5126530612244898\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67       632\n",
      "           1       0.41      0.02      0.03       593\n",
      "\n",
      "    accuracy                           0.51      1225\n",
      "   macro avg       0.46      0.50      0.35      1225\n",
      "weighted avg       0.46      0.51      0.36      1225\n",
      "\n",
      "Accuracy List Length : 1879\n",
      "IMMX   2179\n",
      "Accuracy: 0.5132743362831859\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.90      0.67        61\n",
      "           1       0.33      0.06      0.10        52\n",
      "\n",
      "    accuracy                           0.51       113\n",
      "   macro avg       0.43      0.48      0.38       113\n",
      "weighted avg       0.44      0.51      0.41       113\n",
      "\n",
      "Accuracy List Length : 1880\n",
      "IMNM   2180\n",
      "Accuracy: 0.5402298850574713\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69        93\n",
      "           1       0.55      0.07      0.13        81\n",
      "\n",
      "    accuracy                           0.54       174\n",
      "   macro avg       0.54      0.51      0.41       174\n",
      "weighted avg       0.54      0.54      0.43       174\n",
      "\n",
      "Accuracy List Length : 1881\n",
      "IMNN   2181\n",
      "Accuracy: 0.584456780333069\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.74       737\n",
      "           1       0.50      0.01      0.02       524\n",
      "\n",
      "    accuracy                           0.58      1261\n",
      "   macro avg       0.54      0.50      0.38      1261\n",
      "weighted avg       0.55      0.58      0.44      1261\n",
      "\n",
      "Accuracy List Length : 1882\n",
      "IMOM   2182\n",
      "Accuracy: 0.5156626506024097\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.13      0.21       202\n",
      "           1       0.52      0.88      0.65       213\n",
      "\n",
      "    accuracy                           0.52       415\n",
      "   macro avg       0.51      0.51      0.43       415\n",
      "weighted avg       0.51      0.52      0.44       415\n",
      "\n",
      "Accuracy List Length : 1883\n",
      "IMOS   2183\n",
      "Accuracy: 0.5254074784276127\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.90      0.67       556\n",
      "           1       0.46      0.09      0.15       487\n",
      "\n",
      "    accuracy                           0.53      1043\n",
      "   macro avg       0.50      0.50      0.41      1043\n",
      "weighted avg       0.50      0.53      0.43      1043\n",
      "\n",
      "Accuracy List Length : 1884\n",
      "IMPP   2184\n",
      "Accuracy: 0.6347826086956522\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.90      0.74        67\n",
      "           1       0.65      0.27      0.38        48\n",
      "\n",
      "    accuracy                           0.63       115\n",
      "   macro avg       0.64      0.58      0.56       115\n",
      "weighted avg       0.64      0.63      0.59       115\n",
      "\n",
      "Accuracy List Length : 1885\n",
      "IMPPP   2185\n",
      "Accuracy: 0.5565217391304348\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71        67\n",
      "           1       0.20      0.02      0.04        48\n",
      "\n",
      "    accuracy                           0.56       115\n",
      "   macro avg       0.39      0.48      0.37       115\n",
      "weighted avg       0.42      0.56      0.43       115\n",
      "\n",
      "Accuracy List Length : 1886\n",
      "IMRN   2186\n",
      "Accuracy: 0.6275659824046921\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.99      0.77       214\n",
      "           1       0.50      0.02      0.03       127\n",
      "\n",
      "    accuracy                           0.63       341\n",
      "   macro avg       0.56      0.50      0.40       341\n",
      "weighted avg       0.58      0.63      0.49       341\n",
      "\n",
      "Accuracy List Length : 1887\n",
      "IMRX   2187\n",
      "Accuracy: 0.5639097744360902\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72        80\n",
      "           1       0.22      0.04      0.06        53\n",
      "\n",
      "    accuracy                           0.56       133\n",
      "   macro avg       0.41      0.48      0.39       133\n",
      "weighted avg       0.44      0.56      0.46       133\n",
      "\n",
      "Accuracy List Length : 1888\n",
      "IMTE   2188\n",
      "Accuracy: 0.5391566265060241\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       184\n",
      "           1       0.22      0.01      0.03       148\n",
      "\n",
      "    accuracy                           0.54       332\n",
      "   macro avg       0.39      0.49      0.36       332\n",
      "weighted avg       0.40      0.54      0.40       332\n",
      "\n",
      "Accuracy List Length : 1889\n",
      "IMTX   2189\n",
      "Accuracy: 0.5584905660377358\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.93      0.69       143\n",
      "           1       0.60      0.12      0.20       122\n",
      "\n",
      "    accuracy                           0.56       265\n",
      "   macro avg       0.58      0.53      0.45       265\n",
      "weighted avg       0.58      0.56      0.47       265\n",
      "\n",
      "Accuracy List Length : 1890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMTXW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMUX   2191\n",
      "Accuracy: 0.528\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.94      0.68       267\n",
      "           1       0.45      0.06      0.10       233\n",
      "\n",
      "    accuracy                           0.53       500\n",
      "   macro avg       0.49      0.50      0.39       500\n",
      "weighted avg       0.49      0.53      0.41       500\n",
      "\n",
      "Accuracy List Length : 1891\n",
      "IMVT   2192\n",
      "Accuracy: 0.4435146443514644\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.63      0.52       115\n",
      "           1       0.44      0.27      0.34       124\n",
      "\n",
      "    accuracy                           0.44       239\n",
      "   macro avg       0.44      0.45      0.43       239\n",
      "weighted avg       0.44      0.44      0.43       239\n",
      "\n",
      "Accuracy List Length : 1892\n",
      "IMXI   2193\n",
      "Accuracy: 0.5511363636363636\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.93      0.69       191\n",
      "           1       0.55      0.11      0.18       161\n",
      "\n",
      "    accuracy                           0.55       352\n",
      "   macro avg       0.55      0.52      0.43       352\n",
      "weighted avg       0.55      0.55      0.46       352\n",
      "\n",
      "Accuracy List Length : 1893\n",
      "INAB   2194\n",
      "Accuracy: 0.6015037593984962\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.95      0.75        84\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.60       133\n",
      "   macro avg       0.31      0.48      0.38       133\n",
      "weighted avg       0.39      0.60      0.47       133\n",
      "\n",
      "Accuracy List Length : 1894\n",
      "INAQ   2195\n",
      "Accuracy: 0.7372881355932204\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85        87\n",
      "           1       0.50      0.03      0.06        31\n",
      "\n",
      "    accuracy                           0.74       118\n",
      "   macro avg       0.62      0.51      0.45       118\n",
      "weighted avg       0.68      0.74      0.64       118\n",
      "\n",
      "Accuracy List Length : 1895\n",
      "INAQU   2196\n",
      "Accuracy: 0.9523809523809523\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       121\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.95       126\n",
      "   macro avg       0.48      0.50      0.49       126\n",
      "weighted avg       0.92      0.95      0.94       126\n",
      "\n",
      "Accuracy List Length : 1896\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Initialize and train the model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \n\u001b[1;32m---> 23\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Save the scaler and model for reuse\u001b[39;00m\n\u001b[0;32m     27\u001b[0m dump(scaler, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstock\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_scaler.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:199\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    191\u001b[0m         X,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n\u001b[0;32m    204\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:742\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of classes has to be greater than one; got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m class\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    744\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    745\u001b[0m     )\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "for index, row in stock_list.iloc[1569:].iterrows():\n",
    "    stock=row['Stocks']\n",
    "    data=fetch_data(stock)\n",
    "    if (not data.empty) & (len(data)>11):\n",
    "        data=preprocess_data(data)\n",
    "        model_dir=f\"./models/{stock}/\"\n",
    "        if not os.path.exists(model_dir):\n",
    "                    os.mkdir(model_dir)\n",
    "        accuracy_list.to_csv(\"Accuracy_Data_NASDAQ.csv\",index=False)\n",
    "        # Define features (X) and target (y)\n",
    "        features = data[['open-close', 'high-low', 'Volume', 'is_quarter_end','SMA_10','SMA_50',\"SMA_200\",'EMA_10','EMA_50',\"EMA_200\"]]\n",
    "        target = np.where(data['Close'].shift(-1) > data['Close'], 1, 0)  # 1 foSr price increase, 0 otherwise\n",
    "        if features.shape[0] > 0 and target.shape[0] > 0:\n",
    "   \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Standardize features\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            # Initialize and train the model\n",
    "            model = SVC(kernel='poly', probability=True, random_state=42)  \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Save the scaler and model for reuse\n",
    "            \n",
    "            dump(scaler, f\"{model_dir}{stock}_scaler.joblib\")\n",
    "            dump(model, f\"{model_dir}{stock}_predictor.joblib\")\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Evaluate performance\n",
    "            print(stock,\" \",index)\n",
    "            print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "            print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "            stock_accuracy=pd.DataFrame({\"Symbol\":[row['Stocks']],\"Accuracy\":[accuracy_score(y_test,y_pred)*100]})\n",
    "            accuracy_list=pd.concat([accuracy_list,stock_accuracy])\n",
    "            print(\"Accuracy List Length :\",len(accuracy_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bae035-00ac-4d50-8f0d-e2eadfec3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list.to_csv(\"Accuracy_Data_NASDAQ.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d531d-1620-4f00-9a1c-e1069a43b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
