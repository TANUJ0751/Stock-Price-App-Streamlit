{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e61db464-5580-482d-a984-f553ce0a122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump,load\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def fetch_data(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(period=\"max\")  # Fetch 5 years of data\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0817f7a2-988f-40ed-b25a-be8733531885",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list=pd.read_csv('nasdaq-listed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "421a56ca-0add-461d-a395-17c359f3d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data):\n",
    "    # Feature engineering: Create relevant columns\n",
    "    data['open-close'] = data['Open'] - data['Close']\n",
    "    data['high-low'] = data['High'] - data['Low']\n",
    "    data['price-change'] = data['Close'].pct_change()\n",
    "    data['is_quarter_end'] = np.where((data['Date'].dt.month % 3 == 0) & (data['Date'].dt.day > 23), 1, 0)\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['SMA_200'] = data['Close'].rolling(window=200).mean()\n",
    "    data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "    data['EMA_200'] = data['Close'].ewm(span=200, adjust=False).mean()\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['Dividends', 'Stock Splits'], axis=1, errors='ignore')\n",
    "    data.dropna(inplace=True)  # Handle missing values\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8653f251-024d-4212-b1a1-7ad24ae1abae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    STOCK   Accuracy Symbol\n",
      "0     NaN  55.911330   AACG\n",
      "1     NaN  54.248366   AADI\n",
      "2     NaN  53.197674   AADR\n",
      "3     NaN  49.354839    AAL\n",
      "4     NaN  67.598017   AAME\n",
      "5     NaN  49.715370   AAOI\n",
      "6     NaN  52.986023   AAON\n",
      "7     NaN  51.851852   AAPB\n",
      "8     NaN  55.555556   AAPD\n",
      "9     NaN  50.527281   AAPL\n",
      "10    NaN  55.911330   AACG\n",
      "11    NaN  54.248366   AADI\n",
      "12    NaN  53.197674   AADR\n",
      "13    NaN  49.354839    AAL\n",
      "14    NaN  67.598017   AAME\n",
      "15    NaN  49.715370   AAOI\n",
      "16    NaN  52.986023   AAON\n",
      "17    NaN  51.851852   AAPB\n",
      "18    NaN  55.555556   AAPD\n",
      "19    NaN  50.527281   AAPL\n",
      "20    NaN  48.148148   AAPU\n",
      "21    NaN  52.993631   AAXJ\n",
      "22    NaN  56.403941   ABAT\n",
      "23    NaN  46.951220   ABCL\n",
      "24    NaN  66.666667   ABCS\n",
      "25    NaN  63.565891   ABEO\n",
      "26    NaN  66.101695    ABL\n",
      "27    NaN  56.250000  ABLLL\n",
      "28    NaN  56.250000  ABLLL\n",
      "29    NaN  44.444444   ABLV\n",
      "30    NaN  59.756098   ABNB\n",
      "31    NaN  49.264706   ABOS\n",
      "32    NaN  72.549020    ABP\n",
      "33    NaN  50.000000   ABSI\n",
      "34    NaN  64.600000   ABTS\n",
      "35    NaN  54.653938   ABUS\n",
      "36    NaN  85.112936   ABVC\n",
      "37    NaN  75.000000   ABVX\n",
      "38    NaN  54.062187   ACAD\n",
      "39    NaN  55.646817    ACB\n",
      "40    NaN  55.080214   ACCD\n",
      "41    NaN  53.763441   ACDC\n",
      "42    NaN  53.721683   ACET\n",
      "43    NaN  49.477352   ACGL\n",
      "44    NaN  54.285714  ACGLN\n",
      "45    NaN  49.546828  ACGLO\n",
      "46    NaN  58.201058   ACHC\n",
      "47    NaN  61.073826   ACHL\n",
      "48    NaN  58.211041   ACHV\n",
      "49    NaN  65.613609   ACIC\n",
      "50    NaN  51.861702   ACIU\n",
      "51    NaN  50.239234   ACIW\n",
      "52    NaN  52.348993   ACLS\n",
      "53    NaN  41.509434   ACLX\n",
      "54    NaN  52.812500   ACMR\n",
      "55    NaN  63.395225   ACNB\n",
      "56    NaN  59.801712   ACNT\n"
     ]
    }
   ],
   "source": [
    "accuracy_list=pd.read_csv(\"Accuracy_Data_NASDAQ.csv\")\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fac55b-fd50-41b1-9597-3cc75a65a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACNT   50\n",
      "Accuracy: 0.598017124831005\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75      1326\n",
      "           1       0.53      0.01      0.02       893\n",
      "\n",
      "    accuracy                           0.60      2219\n",
      "   macro avg       0.57      0.50      0.38      2219\n",
      "weighted avg       0.57      0.60      0.45      2219\n",
      "\n",
      "Accuracy List Length : 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ACONW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACON   52\n",
      "Accuracy: 0.5416666666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70        52\n",
      "           1       0.50      0.02      0.04        44\n",
      "\n",
      "    accuracy                           0.54        96\n",
      "   macro avg       0.52      0.50      0.37        96\n",
      "weighted avg       0.52      0.54      0.40        96\n",
      "\n",
      "Accuracy List Length : 80\n",
      "ACRS   54\n",
      "Accuracy: 0.5458823529411765\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69       242\n",
      "           1       0.36      0.07      0.12       183\n",
      "\n",
      "    accuracy                           0.55       425\n",
      "   macro avg       0.46      0.49      0.41       425\n",
      "weighted avg       0.48      0.55      0.45       425\n",
      "\n",
      "Accuracy List Length : 81\n",
      "ACRV   55\n",
      "Accuracy: 0.4925373134328358\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.75      0.59        32\n",
      "           1       0.53      0.26      0.35        35\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.50      0.50      0.47        67\n",
      "weighted avg       0.51      0.49      0.46        67\n",
      "\n",
      "Accuracy List Length : 82\n",
      "ACT   56\n",
      "Accuracy: 0.48412698412698413\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.06      0.11        62\n",
      "           1       0.50      0.89      0.64        64\n",
      "\n",
      "    accuracy                           0.48       126\n",
      "   macro avg       0.43      0.48      0.37       126\n",
      "weighted avg       0.43      0.48      0.38       126\n",
      "\n",
      "Accuracy List Length : 83\n",
      "ACTG   57\n",
      "Accuracy: 0.5429906542056074\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       584\n",
      "           1       0.47      0.05      0.09       486\n",
      "\n",
      "    accuracy                           0.54      1070\n",
      "   macro avg       0.51      0.50      0.39      1070\n",
      "weighted avg       0.51      0.54      0.42      1070\n",
      "\n",
      "Accuracy List Length : 84\n",
      "ACVA   59\n",
      "Accuracy: 0.4666666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.67      0.54        70\n",
      "           1       0.50      0.29      0.37        80\n",
      "\n",
      "    accuracy                           0.47       150\n",
      "   macro avg       0.48      0.48      0.45       150\n",
      "weighted avg       0.48      0.47      0.45       150\n",
      "\n",
      "Accuracy List Length : 85\n",
      "ACWI   60\n",
      "Accuracy: 0.5460199004975125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.01      0.02       368\n",
      "           1       0.54      1.00      0.70       436\n",
      "\n",
      "    accuracy                           0.55       804\n",
      "   macro avg       0.67      0.50      0.36       804\n",
      "weighted avg       0.66      0.55      0.39       804\n",
      "\n",
      "Accuracy List Length : 86\n",
      "ACWX   61\n",
      "Accuracy: 0.4987562189054726\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.02      0.04       408\n",
      "           1       0.50      0.99      0.66       396\n",
      "\n",
      "    accuracy                           0.50       804\n",
      "   macro avg       0.61      0.51      0.35       804\n",
      "weighted avg       0.61      0.50      0.34       804\n",
      "\n",
      "Accuracy List Length : 87\n",
      "ACXP   62\n",
      "Accuracy: 0.5693430656934306\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.88      0.70        77\n",
      "           1       0.53      0.17      0.25        60\n",
      "\n",
      "    accuracy                           0.57       137\n",
      "   macro avg       0.55      0.52      0.48       137\n",
      "weighted avg       0.55      0.57      0.50       137\n",
      "\n",
      "Accuracy List Length : 88\n",
      "ADAG   63\n",
      "Accuracy: 0.5576923076923077\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.71        90\n",
      "           1       0.36      0.06      0.10        66\n",
      "\n",
      "    accuracy                           0.56       156\n",
      "   macro avg       0.47      0.49      0.41       156\n",
      "weighted avg       0.48      0.56      0.45       156\n",
      "\n",
      "Accuracy List Length : 89\n",
      "ADAP   64\n",
      "Accuracy: 0.5538116591928252\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71       247\n",
      "           1       0.50      0.04      0.07       199\n",
      "\n",
      "    accuracy                           0.55       446\n",
      "   macro avg       0.53      0.50      0.39       446\n",
      "weighted avg       0.53      0.55      0.42       446\n",
      "\n",
      "Accuracy List Length : 90\n",
      "ADBE   65\n",
      "Accuracy: 0.49973614775725594\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.92      0.65       957\n",
      "           1       0.47      0.08      0.13       938\n",
      "\n",
      "    accuracy                           0.50      1895\n",
      "   macro avg       0.48      0.50      0.39      1895\n",
      "weighted avg       0.49      0.50      0.39      1895\n",
      "\n",
      "Accuracy List Length : 91\n",
      "ADD   66\n",
      "Accuracy: 0.616580310880829\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       475\n",
      "           1       0.67      0.01      0.01       297\n",
      "\n",
      "    accuracy                           0.62       772\n",
      "   macro avg       0.64      0.50      0.39       772\n",
      "weighted avg       0.64      0.62      0.47       772\n",
      "\n",
      "Accuracy List Length : 92\n",
      "ADEA   67\n",
      "Accuracy: 0.5224609375\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.94      0.67       530\n",
      "           1       0.54      0.08      0.13       494\n",
      "\n",
      "    accuracy                           0.52      1024\n",
      "   macro avg       0.53      0.51      0.40      1024\n",
      "weighted avg       0.53      0.52      0.41      1024\n",
      "\n",
      "Accuracy List Length : 93\n",
      "ADI   69\n",
      "Accuracy: 0.5349256421811627\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.68      1195\n",
      "           1       0.47      0.06      0.11      1024\n",
      "\n",
      "    accuracy                           0.53      2219\n",
      "   macro avg       0.51      0.50      0.40      2219\n",
      "weighted avg       0.51      0.53      0.42      2219\n",
      "\n",
      "Accuracy List Length : 94\n",
      "ADIL   70\n",
      "Accuracy: 0.5950704225352113\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.94      0.74       171\n",
      "           1       0.45      0.08      0.14       113\n",
      "\n",
      "    accuracy                           0.60       284\n",
      "   macro avg       0.53      0.51      0.44       284\n",
      "weighted avg       0.54      0.60      0.50       284\n",
      "\n",
      "Accuracy List Length : 95\n",
      "ADMA   71\n",
      "Accuracy: 0.5400763358778626\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.69       277\n",
      "           1       0.69      0.04      0.08       247\n",
      "\n",
      "    accuracy                           0.54       524\n",
      "   macro avg       0.61      0.51      0.39       524\n",
      "weighted avg       0.61      0.54      0.41       524\n",
      "\n",
      "Accuracy List Length : 96\n",
      "ADN   72\n",
      "Accuracy: 0.5752895752895753\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73       150\n",
      "           1       0.43      0.03      0.05       109\n",
      "\n",
      "    accuracy                           0.58       259\n",
      "   macro avg       0.50      0.50      0.39       259\n",
      "weighted avg       0.52      0.58      0.44       259\n",
      "\n",
      "Accuracy List Length : 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ADNWW: Period 'max' is invalid, must be one of ['1d', '5d']\n"
     ]
    }
   ],
   "source": [
    "for index, row in stock_list.iloc[50:].iterrows():\n",
    "    stock=row['Stocks']\n",
    "    data=fetch_data(stock)\n",
    "    if (not data.empty) & (len(data)>11):\n",
    "        data=preprocess_data(data)\n",
    "        model_dir=f\"./models/{stock}/\"\n",
    "        if not os.path.exists(model_dir):\n",
    "                    os.mkdir(model_dir)\n",
    "        accuracy_list.to_csv(\"Accuracy_Data_NASDAQ.csv\",index=False)\n",
    "        # Define features (X) and target (y)\n",
    "        features = data[['open-close', 'high-low', 'Volume', 'is_quarter_end','SMA_10','SMA_50',\"SMA_200\",'EMA_10','EMA_50',\"EMA_200\"]]\n",
    "        target = np.where(data['Close'].shift(-1) > data['Close'], 1, 0)  # 1 foSr price increase, 0 otherwise\n",
    "        if features.shape[0] > 0 and target.shape[0] > 0:\n",
    "   \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Standardize features\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            # Initialize and train the model\n",
    "            model = SVC(kernel='poly', probability=True, random_state=42)  \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Save the scaler and model for reuse\n",
    "            \n",
    "            dump(scaler, f\"{model_dir}{stock}_scaler.joblib\")\n",
    "            dump(model, f\"{model_dir}{stock}_predictor.joblib\")\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Evaluate performance\n",
    "            print(stock,\" \",index)\n",
    "            print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "            print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "            stock_accuracy=pd.DataFrame({\"Symbol\":[row['Stocks']],\"Accuracy\":[accuracy_score(y_test,y_pred)*100]})\n",
    "            accuracy_list=pd.concat([accuracy_list,stock_accuracy])\n",
    "            print(\"Accuracy List Length :\",len(accuracy_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bae035-00ac-4d50-8f0d-e2eadfec3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list.to_csv(\"Accuracy_Data_NASDAQ.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d531d-1620-4f00-9a1c-e1069a43b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
