{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e61db464-5580-482d-a984-f553ce0a122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump,load\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def fetch_data(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(period=\"max\")  # Fetch 5 years of data\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0817f7a2-988f-40ed-b25a-be8733531885",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list=pd.read_csv('nasdaq-listed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "421a56ca-0add-461d-a395-17c359f3d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data):\n",
    "    # Feature engineering: Create relevant columns\n",
    "    data['open-close'] = data['Open'] - data['Close']\n",
    "    data['high-low'] = data['High'] - data['Low']\n",
    "    data['price-change'] = data['Close'].pct_change()\n",
    "    data['is_quarter_end'] = np.where((data['Date'].dt.month % 3 == 0) & (data['Date'].dt.day > 23), 1, 0)\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['SMA_200'] = data['Close'].rolling(window=200).mean()\n",
    "    data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "    data['EMA_200'] = data['Close'].ewm(span=200, adjust=False).mean()\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['Dividends', 'Stock Splits'], axis=1, errors='ignore')\n",
    "    data.dropna(inplace=True)  # Handle missing values\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8653f251-024d-4212-b1a1-7ad24ae1abae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    STOCK   Accuracy Symbol\n",
      "0     NaN  55.911330   AACG\n",
      "1     NaN  54.248366   AADI\n",
      "2     NaN  53.197674   AADR\n",
      "3     NaN  49.354839    AAL\n",
      "4     NaN  67.598017   AAME\n",
      "5     NaN  49.715370   AAOI\n",
      "6     NaN  52.986023   AAON\n",
      "7     NaN  51.851852   AAPB\n",
      "8     NaN  55.555556   AAPD\n",
      "9     NaN  50.527281   AAPL\n",
      "10    NaN  55.911330   AACG\n",
      "11    NaN  54.248366   AADI\n",
      "12    NaN  53.197674   AADR\n",
      "13    NaN  49.354839    AAL\n",
      "14    NaN  67.598017   AAME\n",
      "15    NaN  49.715370   AAOI\n",
      "16    NaN  52.986023   AAON\n",
      "17    NaN  51.851852   AAPB\n",
      "18    NaN  55.555556   AAPD\n",
      "19    NaN  50.527281   AAPL\n",
      "20    NaN  48.148148   AAPU\n",
      "21    NaN  52.993631   AAXJ\n",
      "22    NaN  56.403941   ABAT\n",
      "23    NaN  46.951220   ABCL\n",
      "24    NaN  66.666667   ABCS\n",
      "25    NaN  63.565891   ABEO\n",
      "26    NaN  66.101695    ABL\n",
      "27    NaN  56.250000  ABLLL\n",
      "28    NaN  56.250000  ABLLL\n",
      "29    NaN  44.444444   ABLV\n",
      "30    NaN  59.756098   ABNB\n",
      "31    NaN  49.264706   ABOS\n",
      "32    NaN  72.549020    ABP\n",
      "33    NaN  50.000000   ABSI\n",
      "34    NaN  64.600000   ABTS\n",
      "35    NaN  54.653938   ABUS\n",
      "36    NaN  85.112936   ABVC\n",
      "37    NaN  75.000000   ABVX\n",
      "38    NaN  54.062187   ACAD\n",
      "39    NaN  55.646817    ACB\n",
      "40    NaN  55.080214   ACCD\n",
      "41    NaN  53.763441   ACDC\n",
      "42    NaN  53.721683   ACET\n",
      "43    NaN  49.477352   ACGL\n",
      "44    NaN  54.285714  ACGLN\n",
      "45    NaN  49.546828  ACGLO\n",
      "46    NaN  58.201058   ACHC\n",
      "47    NaN  61.073826   ACHL\n",
      "48    NaN  58.211041   ACHV\n",
      "49    NaN  65.613609   ACIC\n",
      "50    NaN  51.861702   ACIU\n",
      "51    NaN  50.239234   ACIW\n",
      "52    NaN  52.348993   ACLS\n",
      "53    NaN  41.509434   ACLX\n",
      "54    NaN  52.812500   ACMR\n",
      "55    NaN  63.395225   ACNB\n",
      "56    NaN  59.801712   ACNT\n"
     ]
    }
   ],
   "source": [
    "accuracy_list=pd.read_csv(\"Accuracy_Data_NASDAQ.csv\")\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fac55b-fd50-41b1-9597-3cc75a65a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABVX   31\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        15\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.38      0.50      0.43        20\n",
      "weighted avg       0.56      0.75      0.64        20\n",
      "\n",
      "Accuracy List Length : 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACAD   32\n",
      "Accuracy: 0.5406218655967904\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70       538\n",
      "           1       0.52      0.03      0.06       459\n",
      "\n",
      "    accuracy                           0.54       997\n",
      "   macro avg       0.53      0.50      0.38       997\n",
      "weighted avg       0.53      0.54      0.40       997\n",
      "\n",
      "Accuracy List Length : 59\n",
      "ACB   33\n",
      "Accuracy: 0.5564681724845996\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71       276\n",
      "           1       0.27      0.01      0.03       211\n",
      "\n",
      "    accuracy                           0.56       487\n",
      "   macro avg       0.42      0.49      0.37       487\n",
      "weighted avg       0.44      0.56      0.42       487\n",
      "\n",
      "Accuracy List Length : 60\n",
      "ACCD   34\n",
      "Accuracy: 0.5508021390374331\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69       102\n",
      "           1       0.53      0.11      0.18        85\n",
      "\n",
      "    accuracy                           0.55       187\n",
      "   macro avg       0.54      0.51      0.43       187\n",
      "weighted avg       0.54      0.55      0.46       187\n",
      "\n",
      "Accuracy List Length : 61\n",
      "ACDC   35\n",
      "Accuracy: 0.5376344086021505\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69        52\n",
      "           1       0.33      0.05      0.09        41\n",
      "\n",
      "    accuracy                           0.54        93\n",
      "   macro avg       0.44      0.49      0.39        93\n",
      "weighted avg       0.46      0.54      0.42        93\n",
      "\n",
      "Accuracy List Length : 62\n",
      "ACET   36\n",
      "Accuracy: 0.5372168284789643\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       163\n",
      "           1       0.58      0.08      0.13       146\n",
      "\n",
      "    accuracy                           0.54       309\n",
      "   macro avg       0.56      0.51      0.41       309\n",
      "weighted avg       0.56      0.54      0.42       309\n",
      "\n",
      "Accuracy List Length : 63\n",
      "ACGL   37\n",
      "Accuracy: 0.49477351916376305\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.93      0.64       695\n",
      "           1       0.57      0.08      0.14       740\n",
      "\n",
      "    accuracy                           0.49      1435\n",
      "   macro avg       0.53      0.51      0.39      1435\n",
      "weighted avg       0.53      0.49      0.39      1435\n",
      "\n",
      "Accuracy List Length : 64\n",
      "ACGLN   38\n",
      "Accuracy: 0.5428571428571428\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.89      0.68        76\n",
      "           1       0.50      0.12      0.20        64\n",
      "\n",
      "    accuracy                           0.54       140\n",
      "   macro avg       0.52      0.51      0.44       140\n",
      "weighted avg       0.53      0.54      0.46       140\n",
      "\n",
      "Accuracy List Length : 65\n",
      "ACGLO   39\n",
      "Accuracy: 0.4954682779456193\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.83      0.61       156\n",
      "           1       0.57      0.19      0.29       175\n",
      "\n",
      "    accuracy                           0.50       331\n",
      "   macro avg       0.52      0.51      0.45       331\n",
      "weighted avg       0.53      0.50      0.44       331\n",
      "\n",
      "Accuracy List Length : 66\n",
      "ACHC   40\n",
      "Accuracy: 0.582010582010582\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       880\n",
      "           1       0.50      0.01      0.02       632\n",
      "\n",
      "    accuracy                           0.58      1512\n",
      "   macro avg       0.54      0.50      0.38      1512\n",
      "weighted avg       0.55      0.58      0.44      1512\n",
      "\n",
      "Accuracy List Length : 67\n",
      "ACHL   41\n",
      "Accuracy: 0.610738255033557\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74        89\n",
      "           1       0.56      0.15      0.24        60\n",
      "\n",
      "    accuracy                           0.61       149\n",
      "   macro avg       0.59      0.54      0.49       149\n",
      "weighted avg       0.59      0.61      0.54       149\n",
      "\n",
      "Accuracy List Length : 68\n"
     ]
    }
   ],
   "source": [
    "for index, row in stock_list.iloc[31:].iterrows():\n",
    "    stock=row['Stocks']\n",
    "    data=fetch_data(stock)\n",
    "    if not data.empty:\n",
    "        data=preprocess_data(data)\n",
    "        model_dir=f\"./models/{stock}/\"\n",
    "        if not os.path.exists(model_dir):\n",
    "                    os.mkdir(model_dir)\n",
    "        accuracy_list.to_csv(\"Accuracy_Data_NASDAQ.csv\",index=False)\n",
    "        # Define features (X) and target (y)\n",
    "        features = data[['open-close', 'high-low', 'Volume', 'is_quarter_end','SMA_10','SMA_50',\"SMA_200\",'EMA_10','EMA_50',\"EMA_200\"]]\n",
    "        target = np.where(data['Close'].shift(-1) > data['Close'], 1, 0)  # 1 foSr price increase, 0 otherwise\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # Initialize and train the model\n",
    "        model = SVC(kernel='poly', probability=True, random_state=42)  \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the scaler and model for reuse\n",
    "        \n",
    "        dump(scaler, f\"{model_dir}{stock}_scaler.joblib\")\n",
    "        dump(model, f\"{model_dir}{stock}_predictor.joblib\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        print(stock,\" \",index)\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        stock_accuracy=pd.DataFrame({\"Symbol\":[row['Stocks']],\"Accuracy\":[accuracy_score(y_test,y_pred)*100]})\n",
    "        accuracy_list=pd.concat([accuracy_list,stock_accuracy])\n",
    "        print(\"Accuracy List Length :\",len(accuracy_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bae035-00ac-4d50-8f0d-e2eadfec3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list.to_csv(\"Accuracy_Data_NASDAQ.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d531d-1620-4f00-9a1c-e1069a43b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
