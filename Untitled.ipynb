{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e61db464-5580-482d-a984-f553ce0a122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump,load\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def fetch_data(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(period=\"max\")  # Fetch 5 years of data\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0817f7a2-988f-40ed-b25a-be8733531885",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list=pd.read_csv('NSE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "421a56ca-0add-461d-a395-17c359f3d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data):\n",
    "    # Feature engineering: Create relevant columns\n",
    "    data['open-close'] = data['Open'] - data['Close']\n",
    "    data['high-low'] = data['High'] - data['Low']\n",
    "    data['price-change'] = data['Close'].pct_change()\n",
    "    data['is_quarter_end'] = np.where(data['Date'].dt.month % 3 == 0, 1, 0)\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['SMA_200'] = data['Close'].rolling(window=200).mean()\n",
    "    data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "    data['EMA_200'] = data['Close'].ewm(span=200, adjust=False).mean()\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['Dividends', 'Stock Splits'], axis=1, errors='ignore')\n",
    "    data.dropna(inplace=True)  # Handle missing values\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8653f251-024d-4212-b1a1-7ad24ae1abae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Symbol    Accuracy\n",
      "0      20MICRONS   54.736842\n",
      "1     21STCENMGM   52.302632\n",
      "2         360ONE   43.243243\n",
      "3      3IINFOLTD   59.656652\n",
      "4        3MINDIA   54.317549\n",
      "...          ...         ...\n",
      "1558     SIGACHI   53.913043\n",
      "1559      SIGIND   57.924528\n",
      "1560       SIGMA   61.585366\n",
      "1561   SIGNATURE   45.454545\n",
      "1562    SIGNPOST  100.000000\n",
      "\n",
      "[1563 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list=pd.read_csv(\"Accuracy_Data.csv\")\n",
    "\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51fac55b-fd50-41b1-9597-3cc75a65a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGNPOST.NS   1658\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "Accuracy List Length : 1564\n",
      "SIKKO.NS   1659\n",
      "Accuracy: 0.7003058103975535\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       233\n",
      "           1       0.25      0.02      0.04        94\n",
      "\n",
      "    accuracy                           0.70       327\n",
      "   macro avg       0.48      0.50      0.43       327\n",
      "weighted avg       0.58      0.70      0.60       327\n",
      "\n",
      "Accuracy List Length : 1565\n",
      "SIL.NS   1660\n",
      "Accuracy: 0.5816326530612245\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       625\n",
      "           1       0.58      0.02      0.03       453\n",
      "\n",
      "    accuracy                           0.58      1078\n",
      "   macro avg       0.58      0.50      0.38      1078\n",
      "weighted avg       0.58      0.58      0.44      1078\n",
      "\n",
      "Accuracy List Length : 1566\n",
      "SILGO.NS   1661\n",
      "Accuracy: 0.6716981132075471\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80       180\n",
      "           1       0.33      0.02      0.04        85\n",
      "\n",
      "    accuracy                           0.67       265\n",
      "   macro avg       0.51      0.50      0.42       265\n",
      "weighted avg       0.57      0.67      0.56       265\n",
      "\n",
      "Accuracy List Length : 1567\n",
      "SILINV.NS   1662\n",
      "Accuracy: 0.5608170844939647\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72       617\n",
      "           1       0.07      0.00      0.00       460\n",
      "\n",
      "    accuracy                           0.56      1077\n",
      "   macro avg       0.32      0.49      0.36      1077\n",
      "weighted avg       0.35      0.56      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1568\n",
      "SILLYMONKS.NS   1663\n",
      "Accuracy: 0.6039603960396039\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       185\n",
      "           1       0.33      0.02      0.03       118\n",
      "\n",
      "    accuracy                           0.60       303\n",
      "   macro avg       0.47      0.50      0.39       303\n",
      "weighted avg       0.50      0.60      0.47       303\n",
      "\n",
      "Accuracy List Length : 1569\n",
      "SILVERTUC.NS   1664\n",
      "Accuracy: 0.6699029126213593\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       211\n",
      "           1       0.44      0.15      0.23        98\n",
      "\n",
      "    accuracy                           0.67       309\n",
      "   macro avg       0.57      0.53      0.51       309\n",
      "weighted avg       0.62      0.67      0.61       309\n",
      "\n",
      "Accuracy List Length : 1570\n",
      "SIMBHALS.NS   1665\n",
      "Accuracy: 0.561282932416953\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.72       490\n",
      "           1       0.50      0.02      0.04       383\n",
      "\n",
      "    accuracy                           0.56       873\n",
      "   macro avg       0.53      0.50      0.38       873\n",
      "weighted avg       0.53      0.56      0.42       873\n",
      "\n",
      "Accuracy List Length : 1571\n",
      "SIMPLEXINF.NS   1666\n",
      "Accuracy: 0.5545454545454546\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.71       550\n",
      "           1       0.45      0.01      0.02       440\n",
      "\n",
      "    accuracy                           0.55       990\n",
      "   macro avg       0.51      0.50      0.37       990\n",
      "weighted avg       0.51      0.55      0.41       990\n",
      "\n",
      "Accuracy List Length : 1572\n",
      "SINDHUTRAD.NS   1668\n",
      "Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.79        24\n",
      "           1       0.50      0.08      0.14        12\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.59      0.52      0.47        36\n",
      "weighted avg       0.62      0.67      0.58        36\n",
      "\n",
      "Accuracy List Length : 1573\n",
      "SINTERCOM.NS   1669\n",
      "Accuracy: 0.6020066889632107\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.74       181\n",
      "           1       0.48      0.11      0.18       118\n",
      "\n",
      "    accuracy                           0.60       299\n",
      "   macro avg       0.55      0.52      0.46       299\n",
      "weighted avg       0.56      0.60      0.52       299\n",
      "\n",
      "Accuracy List Length : 1574\n",
      "SIRCA.NS   1670\n",
      "Accuracy: 0.5335689045936396\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.91      0.68       153\n",
      "           1       0.46      0.09      0.15       130\n",
      "\n",
      "    accuracy                           0.53       283\n",
      "   macro avg       0.50      0.50      0.42       283\n",
      "weighted avg       0.50      0.53      0.44       283\n",
      "\n",
      "Accuracy List Length : 1575\n",
      "SIS.NS   1671\n",
      "Accuracy: 0.5815384615384616\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       193\n",
      "           1       0.43      0.10      0.16       132\n",
      "\n",
      "    accuracy                           0.58       325\n",
      "   macro avg       0.51      0.51      0.44       325\n",
      "weighted avg       0.53      0.58      0.49       325\n",
      "\n",
      "Accuracy List Length : 1576\n",
      "SITINET.NS   1672\n",
      "Accuracy: 0.6052009456264775\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       518\n",
      "           1       0.25      0.01      0.02       328\n",
      "\n",
      "    accuracy                           0.61       846\n",
      "   macro avg       0.43      0.50      0.39       846\n",
      "weighted avg       0.47      0.61      0.47       846\n",
      "\n",
      "Accuracy List Length : 1577\n",
      "SIYSIL.NS   1673\n",
      "Accuracy: 0.6047794117647058\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       664\n",
      "           1       0.36      0.02      0.04       424\n",
      "\n",
      "    accuracy                           0.60      1088\n",
      "   macro avg       0.49      0.50      0.39      1088\n",
      "weighted avg       0.51      0.60      0.47      1088\n",
      "\n",
      "Accuracy List Length : 1578\n",
      "SJS.NS   1674\n",
      "Accuracy: 0.4260869565217391\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.34      0.40        65\n",
      "           1       0.39      0.54      0.45        50\n",
      "\n",
      "    accuracy                           0.43       115\n",
      "   macro avg       0.44      0.44      0.43       115\n",
      "weighted avg       0.44      0.43      0.42       115\n",
      "\n",
      "Accuracy List Length : 1579\n",
      "SJVN.NS   1675\n",
      "Accuracy: 0.5410557184750733\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.70       364\n",
      "           1       0.69      0.03      0.05       318\n",
      "\n",
      "    accuracy                           0.54       682\n",
      "   macro avg       0.62      0.51      0.38       682\n",
      "weighted avg       0.61      0.54      0.40       682\n",
      "\n",
      "Accuracy List Length : 1580\n",
      "SKFINDIA.NS   1676\n",
      "Accuracy: 0.4976657329598506\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.95      0.65       537\n",
      "           1       0.46      0.05      0.09       534\n",
      "\n",
      "    accuracy                           0.50      1071\n",
      "   macro avg       0.48      0.50      0.37      1071\n",
      "weighted avg       0.48      0.50      0.37      1071\n",
      "\n",
      "Accuracy List Length : 1581\n",
      "SKIPPER.NS   1677\n",
      "Accuracy: 0.5230414746543779\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       222\n",
      "           1       0.67      0.05      0.09       212\n",
      "\n",
      "    accuracy                           0.52       434\n",
      "   macro avg       0.59      0.51      0.38       434\n",
      "weighted avg       0.59      0.52      0.39       434\n",
      "\n",
      "Accuracy List Length : 1582\n",
      "SKMEGGPROD.NS   1678\n",
      "Accuracy: 0.5506035283194057\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.71       597\n",
      "           1       0.42      0.02      0.04       480\n",
      "\n",
      "    accuracy                           0.55      1077\n",
      "   macro avg       0.49      0.50      0.37      1077\n",
      "weighted avg       0.50      0.55      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1583\n",
      "SKYGOLD.NS   1679\n",
      "Accuracy: 0.5517241379310345\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.04      0.07        25\n",
      "           1       0.56      0.94      0.70        33\n",
      "\n",
      "    accuracy                           0.55        58\n",
      "   macro avg       0.45      0.49      0.39        58\n",
      "weighted avg       0.46      0.55      0.43        58\n",
      "\n",
      "Accuracy List Length : 1584\n",
      "SMARTLINK.NS   1680\n",
      "Accuracy: 0.5673166202414113\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       616\n",
      "           1       0.22      0.00      0.01       461\n",
      "\n",
      "    accuracy                           0.57      1077\n",
      "   macro avg       0.40      0.50      0.37      1077\n",
      "weighted avg       0.42      0.57      0.42      1077\n",
      "\n",
      "Accuracy List Length : 1585\n",
      "SMCGLOBAL.NS   1681\n",
      "Accuracy: 0.4866666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.94      0.63        70\n",
      "           1       0.64      0.09      0.15        80\n",
      "\n",
      "    accuracy                           0.49       150\n",
      "   macro avg       0.56      0.52      0.39       150\n",
      "weighted avg       0.56      0.49      0.38       150\n",
      "\n",
      "Accuracy List Length : 1586\n",
      "SMLISUZU.NS   1682\n",
      "Accuracy: 0.532033426183844\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       576\n",
      "           1       0.36      0.01      0.02       501\n",
      "\n",
      "    accuracy                           0.53      1077\n",
      "   macro avg       0.45      0.50      0.35      1077\n",
      "weighted avg       0.45      0.53      0.38      1077\n",
      "\n",
      "Accuracy List Length : 1587\n",
      "SMLT.NS   1683\n",
      "Accuracy: 0.4778761061946903\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63        54\n",
      "           1       0.50      0.05      0.09        59\n",
      "\n",
      "    accuracy                           0.48       113\n",
      "   macro avg       0.49      0.50      0.36       113\n",
      "weighted avg       0.49      0.48      0.35       113\n",
      "\n",
      "Accuracy List Length : 1588\n",
      "SMSLIFE.NS   1684\n",
      "Accuracy: 0.5061728395061729\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67       166\n",
      "           1       0.33      0.01      0.02       158\n",
      "\n",
      "    accuracy                           0.51       324\n",
      "   macro avg       0.42      0.49      0.35       324\n",
      "weighted avg       0.42      0.51      0.35       324\n",
      "\n",
      "Accuracy List Length : 1589\n",
      "SMSPHARMA.NS   1685\n",
      "Accuracy: 0.5428571428571428\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70       452\n",
      "           1       1.00      0.01      0.02       388\n",
      "\n",
      "    accuracy                           0.54       840\n",
      "   macro avg       0.77      0.51      0.36       840\n",
      "weighted avg       0.75      0.54      0.39       840\n",
      "\n",
      "Accuracy List Length : 1590\n",
      "SNOWMAN.NS   1686\n",
      "Accuracy: 0.5405982905982906\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70       249\n",
      "           1       1.00      0.02      0.04       219\n",
      "\n",
      "    accuracy                           0.54       468\n",
      "   macro avg       0.77      0.51      0.37       468\n",
      "weighted avg       0.75      0.54      0.39       468\n",
      "\n",
      "Accuracy List Length : 1591\n",
      "SOBHA.NS   1687\n",
      "Accuracy: 0.5206124852767963\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.99      0.68       443\n",
      "           1       0.45      0.01      0.02       406\n",
      "\n",
      "    accuracy                           0.52       849\n",
      "   macro avg       0.49      0.50      0.35       849\n",
      "weighted avg       0.49      0.52      0.37       849\n",
      "\n",
      "Accuracy List Length : 1592\n",
      "SOFTTECH.NS   1688\n",
      "Accuracy: 0.6118881118881119\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.95      0.75       174\n",
      "           1       0.53      0.08      0.14       112\n",
      "\n",
      "    accuracy                           0.61       286\n",
      "   macro avg       0.57      0.52      0.44       286\n",
      "weighted avg       0.58      0.61      0.51       286\n",
      "\n",
      "Accuracy List Length : 1593\n",
      "SOLARA.NS   1689\n",
      "Accuracy: 0.6014234875444839\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.93      0.74       176\n",
      "           1       0.32      0.06      0.10       105\n",
      "\n",
      "    accuracy                           0.60       281\n",
      "   macro avg       0.47      0.49      0.42       281\n",
      "weighted avg       0.51      0.60      0.50       281\n",
      "\n",
      "Accuracy List Length : 1594\n",
      "SOLARINDS.NS   1690\n",
      "Accuracy: 0.5163841807909605\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.04      0.08       431\n",
      "           1       0.52      0.97      0.67       454\n",
      "\n",
      "    accuracy                           0.52       885\n",
      "   macro avg       0.53      0.50      0.37       885\n",
      "weighted avg       0.53      0.52      0.38       885\n",
      "\n",
      "Accuracy List Length : 1595\n",
      "SOMANYCERA.NS   1691\n",
      "Accuracy: 0.5445269016697588\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.69       587\n",
      "           1       0.50      0.06      0.11       491\n",
      "\n",
      "    accuracy                           0.54      1078\n",
      "   macro avg       0.52      0.50      0.40      1078\n",
      "weighted avg       0.53      0.54      0.43      1078\n",
      "\n",
      "Accuracy List Length : 1596\n",
      "SOMATEX.NS   1692\n",
      "Accuracy: 0.6072423398328691\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75       657\n",
      "           1       0.38      0.01      0.02       420\n",
      "\n",
      "    accuracy                           0.61      1077\n",
      "   macro avg       0.50      0.50      0.39      1077\n",
      "weighted avg       0.52      0.61      0.47      1077\n",
      "\n",
      "Accuracy List Length : 1597\n",
      "SOMICONVEY.NS   1693\n",
      "Accuracy: 0.5396825396825397\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.69       207\n",
      "           1       0.40      0.04      0.06       171\n",
      "\n",
      "    accuracy                           0.54       378\n",
      "   macro avg       0.47      0.50      0.38       378\n",
      "weighted avg       0.48      0.54      0.41       378\n",
      "\n",
      "Accuracy List Length : 1598\n",
      "SONACOMS.NS   1694\n",
      "Accuracy: 0.5522388059701493\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.85      0.68        75\n",
      "           1       0.48      0.17      0.25        59\n",
      "\n",
      "    accuracy                           0.55       134\n",
      "   macro avg       0.52      0.51      0.47       134\n",
      "weighted avg       0.53      0.55      0.49       134\n",
      "\n",
      "Accuracy List Length : 1599\n",
      "SONAMLTD.NS   1695\n",
      "Accuracy: 0.608540925266904\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       169\n",
      "           1       0.62      0.04      0.08       112\n",
      "\n",
      "    accuracy                           0.61       281\n",
      "   macro avg       0.62      0.51      0.42       281\n",
      "weighted avg       0.61      0.61      0.48       281\n",
      "\n",
      "Accuracy List Length : 1600\n",
      "SONATSOFTW.NS   1696\n",
      "Accuracy: 0.5710306406685237\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72       616\n",
      "           1       0.48      0.02      0.04       461\n",
      "\n",
      "    accuracy                           0.57      1077\n",
      "   macro avg       0.52      0.50      0.38      1077\n",
      "weighted avg       0.53      0.57      0.43      1077\n",
      "\n",
      "Accuracy List Length : 1601\n",
      "SOTL.NS   1697\n",
      "Accuracy: 0.5376044568245125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70       582\n",
      "           1       0.43      0.02      0.03       495\n",
      "\n",
      "    accuracy                           0.54      1077\n",
      "   macro avg       0.48      0.50      0.37      1077\n",
      "weighted avg       0.49      0.54      0.39      1077\n",
      "\n",
      "Accuracy List Length : 1602\n",
      "SOUTHBANK.NS   1698\n",
      "Accuracy: 0.5839936608557845\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       739\n",
      "           1       0.38      0.01      0.01       523\n",
      "\n",
      "    accuracy                           0.58      1262\n",
      "   macro avg       0.48      0.50      0.37      1262\n",
      "weighted avg       0.50      0.58      0.44      1262\n",
      "\n",
      "Accuracy List Length : 1603\n",
      "SOUTHWEST.NS   1699\n",
      "Accuracy: 0.5451505016722408\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       162\n",
      "           1       0.55      0.04      0.08       137\n",
      "\n",
      "    accuracy                           0.55       299\n",
      "   macro avg       0.55      0.51      0.39       299\n",
      "weighted avg       0.55      0.55      0.42       299\n",
      "\n",
      "Accuracy List Length : 1604\n",
      "SPAL.NS   1700\n",
      "Accuracy: 0.516042780748663\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       192\n",
      "           1       0.56      0.03      0.05       182\n",
      "\n",
      "    accuracy                           0.52       374\n",
      "   macro avg       0.54      0.50      0.36       374\n",
      "weighted avg       0.53      0.52      0.37       374\n",
      "\n",
      "Accuracy List Length : 1605\n",
      "SPANDANA.NS   1701\n",
      "Accuracy: 0.5486725663716814\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70       124\n",
      "           1       0.50      0.03      0.06       102\n",
      "\n",
      "    accuracy                           0.55       226\n",
      "   macro avg       0.53      0.50      0.38       226\n",
      "weighted avg       0.53      0.55      0.41       226\n",
      "\n",
      "Accuracy List Length : 1606\n",
      "SPARC.NS   1702\n",
      "Accuracy: 0.6352380952380953\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.77       671\n",
      "           1       0.40      0.02      0.04       379\n",
      "\n",
      "    accuracy                           0.64      1050\n",
      "   macro avg       0.52      0.50      0.41      1050\n",
      "weighted avg       0.55      0.64      0.51      1050\n",
      "\n",
      "Accuracy List Length : 1607\n",
      "SPCENET.NS   1703\n",
      "Accuracy: 0.7544204322200393\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86       379\n",
      "           1       0.73      0.06      0.11       130\n",
      "\n",
      "    accuracy                           0.75       509\n",
      "   macro avg       0.74      0.53      0.49       509\n",
      "weighted avg       0.75      0.75      0.67       509\n",
      "\n",
      "Accuracy List Length : 1608\n",
      "SPECIALITY.NS   1704\n",
      "Accuracy: 0.5370051635111877\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.70       312\n",
      "           1       0.50      0.01      0.02       269\n",
      "\n",
      "    accuracy                           0.54       581\n",
      "   macro avg       0.52      0.50      0.36       581\n",
      "weighted avg       0.52      0.54      0.38       581\n",
      "\n",
      "Accuracy List Length : 1609\n",
      "SPENCERS.NS   1705\n",
      "Accuracy: 0.5573122529644269\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71       141\n",
      "           1       0.50      0.04      0.08       112\n",
      "\n",
      "    accuracy                           0.56       253\n",
      "   macro avg       0.53      0.50      0.40       253\n",
      "weighted avg       0.53      0.56      0.43       253\n",
      "\n",
      "Accuracy List Length : 1610\n",
      "SPIC.NS   1706\n",
      "Accuracy: 0.5543175487465181\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       601\n",
      "           1       0.38      0.01      0.02       476\n",
      "\n",
      "    accuracy                           0.55      1077\n",
      "   macro avg       0.47      0.50      0.37      1077\n",
      "weighted avg       0.48      0.55      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1611\n",
      "SPLIL.NS   1707\n",
      "Accuracy: 0.5756256800870512\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       535\n",
      "           1       0.20      0.01      0.01       384\n",
      "\n",
      "    accuracy                           0.58       919\n",
      "   macro avg       0.39      0.50      0.37       919\n",
      "weighted avg       0.42      0.58      0.43       919\n",
      "\n",
      "Accuracy List Length : 1612\n",
      "SPLPETRO.NS   1708\n",
      "Accuracy: 0.5292479108635098\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       568\n",
      "           1       0.58      0.01      0.03       509\n",
      "\n",
      "    accuracy                           0.53      1077\n",
      "   macro avg       0.56      0.50      0.36      1077\n",
      "weighted avg       0.55      0.53      0.38      1077\n",
      "\n",
      "Accuracy List Length : 1613\n",
      "SPMLINFRA.NS   1709\n",
      "Accuracy: 0.5602968460111317\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       609\n",
      "           1       0.40      0.02      0.04       469\n",
      "\n",
      "    accuracy                           0.56      1078\n",
      "   macro avg       0.48      0.50      0.38      1078\n",
      "weighted avg       0.49      0.56      0.42      1078\n",
      "\n",
      "Accuracy List Length : 1614\n",
      "SPORTKING.NS   1710\n",
      "Accuracy: 0.4342105263157895\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.44      0.47        43\n",
      "           1       0.37      0.42      0.39        33\n",
      "\n",
      "    accuracy                           0.43        76\n",
      "   macro avg       0.43      0.43      0.43        76\n",
      "weighted avg       0.44      0.43      0.44        76\n",
      "\n",
      "Accuracy List Length : 1615\n",
      "SREEL.NS   1712\n",
      "Accuracy: 0.5776892430278885\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73       287\n",
      "           1       0.80      0.02      0.04       215\n",
      "\n",
      "    accuracy                           0.58       502\n",
      "   macro avg       0.69      0.51      0.38       502\n",
      "weighted avg       0.67      0.58      0.43       502\n",
      "\n",
      "Accuracy List Length : 1616\n",
      "SRF.NS   1713\n",
      "Accuracy: 0.5013927576601671\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.19      0.28       554\n",
      "           1       0.49      0.83      0.62       523\n",
      "\n",
      "    accuracy                           0.50      1077\n",
      "   macro avg       0.52      0.51      0.45      1077\n",
      "weighted avg       0.52      0.50      0.44      1077\n",
      "\n",
      "Accuracy List Length : 1617\n",
      "SRGHFL.NS   1714\n",
      "Accuracy: 0.5769230769230769\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.92      0.67        12\n",
      "           1       0.80      0.29      0.42        14\n",
      "\n",
      "    accuracy                           0.58        26\n",
      "   macro avg       0.66      0.60      0.54        26\n",
      "weighted avg       0.67      0.58      0.53        26\n",
      "\n",
      "Accuracy List Length : 1618\n",
      "SRHHYPOLTD.NS   1715\n",
      "Accuracy: 0.5535499398315282\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       463\n",
      "           1       0.38      0.01      0.03       368\n",
      "\n",
      "    accuracy                           0.55       831\n",
      "   macro avg       0.47      0.50      0.37       831\n",
      "weighted avg       0.48      0.55      0.41       831\n",
      "\n",
      "Accuracy List Length : 1619\n",
      "SRPL.NS   1717\n",
      "Accuracy: 0.72\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83       208\n",
      "           1       0.68      0.16      0.26        92\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.70      0.56      0.55       300\n",
      "weighted avg       0.71      0.72      0.65       300\n",
      "\n",
      "Accuracy List Length : 1620\n",
      "SSWL.NS   1719\n",
      "Accuracy: 0.5388768898488121\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70       497\n",
      "           1       0.55      0.03      0.05       429\n",
      "\n",
      "    accuracy                           0.54       926\n",
      "   macro avg       0.54      0.50      0.37       926\n",
      "weighted avg       0.54      0.54      0.40       926\n",
      "\n",
      "Accuracy List Length : 1621\n",
      "STAR.NS   1721\n",
      "Accuracy: 0.5180722891566265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.95      0.67       564\n",
      "           1       0.45      0.05      0.09       515\n",
      "\n",
      "    accuracy                           0.52      1079\n",
      "   macro avg       0.49      0.50      0.38      1079\n",
      "weighted avg       0.49      0.52      0.39      1079\n",
      "\n",
      "Accuracy List Length : 1622\n",
      "STARCEMENT.NS   1722\n",
      "Accuracy: 0.5572289156626506\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       186\n",
      "           1       0.43      0.02      0.04       146\n",
      "\n",
      "    accuracy                           0.56       332\n",
      "   macro avg       0.49      0.50      0.38       332\n",
      "weighted avg       0.50      0.56      0.42       332\n",
      "\n",
      "Accuracy List Length : 1623\n",
      "STARHEALTH.NS   1723\n",
      "Accuracy: 0.5225225225225225\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.86      0.66        59\n",
      "           1       0.47      0.13      0.21        52\n",
      "\n",
      "    accuracy                           0.52       111\n",
      "   macro avg       0.50      0.50      0.43       111\n",
      "weighted avg       0.50      0.52      0.45       111\n",
      "\n",
      "Accuracy List Length : 1624\n",
      "STARPAPER.NS   1724\n",
      "Accuracy: 0.5278293135435993\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       576\n",
      "           1       0.33      0.01      0.03       502\n",
      "\n",
      "    accuracy                           0.53      1078\n",
      "   macro avg       0.43      0.49      0.36      1078\n",
      "weighted avg       0.44      0.53      0.38      1078\n",
      "\n",
      "Accuracy List Length : 1625\n",
      "STARTECK.NS   1725\n",
      "Accuracy: 0.6086956521739131\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.69        53\n",
      "           1       0.55      0.41      0.47        39\n",
      "\n",
      "    accuracy                           0.61        92\n",
      "   macro avg       0.59      0.58      0.58        92\n",
      "weighted avg       0.60      0.61      0.60        92\n",
      "\n",
      "Accuracy List Length : 1626\n",
      "STCINDIA.NS   1726\n",
      "Accuracy: 0.5279383429672447\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       547\n",
      "           1       0.53      0.02      0.04       491\n",
      "\n",
      "    accuracy                           0.53      1038\n",
      "   macro avg       0.53      0.50      0.36      1038\n",
      "weighted avg       0.53      0.53      0.38      1038\n",
      "\n",
      "Accuracy List Length : 1627\n",
      "STEELCAS.NS   1727\n",
      "Accuracy: 0.4824561403508772\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.26      0.34        58\n",
      "           1       0.48      0.71      0.58        56\n",
      "\n",
      "    accuracy                           0.48       114\n",
      "   macro avg       0.48      0.49      0.46       114\n",
      "weighted avg       0.48      0.48      0.45       114\n",
      "\n",
      "Accuracy List Length : 1628\n",
      "STEELCITY.NS   1728\n",
      "Accuracy: 0.5710144927536231\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.73       199\n",
      "           1       0.25      0.01      0.01       146\n",
      "\n",
      "    accuracy                           0.57       345\n",
      "   macro avg       0.41      0.50      0.37       345\n",
      "weighted avg       0.44      0.57      0.42       345\n",
      "\n",
      "Accuracy List Length : 1629\n",
      "STEELXIND.NS   1729\n",
      "Accuracy: 0.5213414634146342\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.84      0.65       174\n",
      "           1       0.47      0.16      0.23       154\n",
      "\n",
      "    accuracy                           0.52       328\n",
      "   macro avg       0.50      0.50      0.44       328\n",
      "weighted avg       0.50      0.52      0.46       328\n",
      "\n",
      "Accuracy List Length : 1630\n",
      "STEL.NS   1730\n",
      "Accuracy: 0.5503875968992248\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       356\n",
      "           1       0.48      0.03      0.06       289\n",
      "\n",
      "    accuracy                           0.55       645\n",
      "   macro avg       0.51      0.50      0.38       645\n",
      "weighted avg       0.52      0.55      0.42       645\n",
      "\n",
      "Accuracy List Length : 1631\n",
      "STERTOOLS.NS   1731\n",
      "Accuracy: 0.5240761478163494\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.68       473\n",
      "           1       0.38      0.02      0.04       420\n",
      "\n",
      "    accuracy                           0.52       893\n",
      "   macro avg       0.45      0.50      0.36       893\n",
      "weighted avg       0.46      0.52      0.38       893\n",
      "\n",
      "Accuracy List Length : 1632\n",
      "STLTECH.NS   1732\n",
      "Accuracy: 0.5047454702329595\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.99      0.67       584\n",
      "           1       0.55      0.01      0.02       575\n",
      "\n",
      "    accuracy                           0.50      1159\n",
      "   macro avg       0.52      0.50      0.34      1159\n",
      "weighted avg       0.52      0.50      0.35      1159\n",
      "\n",
      "Accuracy List Length : 1633\n",
      "STOVEKRAFT.NS   1733\n",
      "Accuracy: 0.477124183006536\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.76      0.60        80\n",
      "           1       0.39      0.16      0.23        73\n",
      "\n",
      "    accuracy                           0.48       153\n",
      "   macro avg       0.44      0.46      0.42       153\n",
      "weighted avg       0.45      0.48      0.43       153\n",
      "\n",
      "Accuracy List Length : 1634\n",
      "STYLAMIND.NS   1734\n",
      "Accuracy: 0.46511627906976744\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.41      0.46        70\n",
      "           1       0.43      0.53      0.47        59\n",
      "\n",
      "    accuracy                           0.47       129\n",
      "   macro avg       0.47      0.47      0.46       129\n",
      "weighted avg       0.47      0.47      0.46       129\n",
      "\n",
      "Accuracy List Length : 1635\n",
      "STYRENIX.NS   1736\n",
      "Accuracy: 0.5508870214752568\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71       598\n",
      "           1       0.33      0.02      0.03       473\n",
      "\n",
      "    accuracy                           0.55      1071\n",
      "   macro avg       0.44      0.50      0.37      1071\n",
      "weighted avg       0.46      0.55      0.41      1071\n",
      "\n",
      "Accuracy List Length : 1636\n",
      "SUBEXLTD.NS   1737\n",
      "Accuracy: 0.5698818897637795\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       581\n",
      "           1       0.47      0.03      0.06       435\n",
      "\n",
      "    accuracy                           0.57      1016\n",
      "   macro avg       0.52      0.50      0.39      1016\n",
      "weighted avg       0.53      0.57      0.44      1016\n",
      "\n",
      "Accuracy List Length : 1637\n",
      "SUBROS.NS   1738\n",
      "Accuracy: 0.566304347826087\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72       525\n",
      "           1       0.38      0.02      0.03       395\n",
      "\n",
      "    accuracy                           0.57       920\n",
      "   macro avg       0.47      0.50      0.37       920\n",
      "weighted avg       0.49      0.57      0.42       920\n",
      "\n",
      "Accuracy List Length : 1638\n",
      "SUDARSCHEM.NS   1739\n",
      "Accuracy: 0.5804046858359957\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73       546\n",
      "           1       0.48      0.03      0.06       393\n",
      "\n",
      "    accuracy                           0.58       939\n",
      "   macro avg       0.53      0.50      0.40       939\n",
      "weighted avg       0.54      0.58      0.45       939\n",
      "\n",
      "Accuracy List Length : 1639\n",
      "SUKHJITS.NS   1740\n",
      "Accuracy: 0.5606060606060606\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69        37\n",
      "           1       0.50      0.17      0.26        29\n",
      "\n",
      "    accuracy                           0.56        66\n",
      "   macro avg       0.54      0.52      0.47        66\n",
      "weighted avg       0.54      0.56      0.50        66\n",
      "\n",
      "Accuracy List Length : 1640\n",
      "SULA.NS   1741\n",
      "Accuracy: 0.6333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74        41\n",
      "           1       0.40      0.32      0.35        19\n",
      "\n",
      "    accuracy                           0.63        60\n",
      "   macro avg       0.56      0.55      0.55        60\n",
      "weighted avg       0.61      0.63      0.62        60\n",
      "\n",
      "Accuracy List Length : 1641\n",
      "SUMICHEM.NS   1742\n",
      "Accuracy: 0.5343137254901961\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.92      0.68       109\n",
      "           1       0.50      0.09      0.16        95\n",
      "\n",
      "    accuracy                           0.53       204\n",
      "   macro avg       0.52      0.51      0.42       204\n",
      "weighted avg       0.52      0.53      0.44       204\n",
      "\n",
      "Accuracy List Length : 1642\n",
      "SUMIT.NS   1743\n",
      "Accuracy: 0.5241635687732342\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.96      0.68       141\n",
      "           1       0.50      0.04      0.07       128\n",
      "\n",
      "    accuracy                           0.52       269\n",
      "   macro avg       0.51      0.50      0.38       269\n",
      "weighted avg       0.51      0.52      0.39       269\n",
      "\n",
      "Accuracy List Length : 1643\n",
      "SUMMITSEC.NS   1744\n",
      "Accuracy: 0.5219858156028369\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       365\n",
      "           1       0.59      0.03      0.06       340\n",
      "\n",
      "    accuracy                           0.52       705\n",
      "   macro avg       0.55      0.51      0.37       705\n",
      "weighted avg       0.55      0.52      0.38       705\n",
      "\n",
      "Accuracy List Length : 1644\n",
      "SUNCLAY.NS   1745\n",
      "Accuracy: 0.3333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.50      0.25         2\n",
      "           1       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.33         9\n",
      "   macro avg       0.42      0.39      0.33         9\n",
      "weighted avg       0.56      0.33      0.37         9\n",
      "\n",
      "Accuracy List Length : 1645\n",
      "SUNDARAM.NS   1746\n",
      "Accuracy: 0.638235294117647\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       441\n",
      "           1       0.32      0.03      0.05       239\n",
      "\n",
      "    accuracy                           0.64       680\n",
      "   macro avg       0.48      0.50      0.41       680\n",
      "weighted avg       0.53      0.64      0.52       680\n",
      "\n",
      "Accuracy List Length : 1646\n",
      "SUNDARMFIN.NS   1747\n",
      "Accuracy: 0.5181058495821727\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.78      0.63       557\n",
      "           1       0.50      0.24      0.33       520\n",
      "\n",
      "    accuracy                           0.52      1077\n",
      "   macro avg       0.51      0.51      0.48      1077\n",
      "weighted avg       0.51      0.52      0.48      1077\n",
      "\n",
      "Accuracy List Length : 1647\n",
      "SUNDARMHLD.NS   1748\n",
      "Accuracy: 0.5816326530612245\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73       171\n",
      "           1       0.50      0.03      0.06       123\n",
      "\n",
      "    accuracy                           0.58       294\n",
      "   macro avg       0.54      0.50      0.40       294\n",
      "weighted avg       0.55      0.58      0.45       294\n",
      "\n",
      "Accuracy List Length : 1648\n",
      "SUNDRMBRAK.NS   1749\n",
      "Accuracy: 0.5191409897292251\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       560\n",
      "           1       0.41      0.02      0.03       511\n",
      "\n",
      "    accuracy                           0.52      1071\n",
      "   macro avg       0.47      0.50      0.36      1071\n",
      "weighted avg       0.47      0.52      0.37      1071\n",
      "\n",
      "Accuracy List Length : 1649\n",
      "SUNDRMFAST.NS   1750\n",
      "Accuracy: 0.5398886827458256\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.69       580\n",
      "           1       0.53      0.03      0.06       498\n",
      "\n",
      "    accuracy                           0.54      1078\n",
      "   macro avg       0.54      0.50      0.38      1078\n",
      "weighted avg       0.54      0.54      0.40      1078\n",
      "\n",
      "Accuracy List Length : 1650\n",
      "SUNFLAG.NS   1751\n",
      "Accuracy: 0.5659340659340659\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       518\n",
      "           1       0.44      0.03      0.05       392\n",
      "\n",
      "    accuracy                           0.57       910\n",
      "   macro avg       0.50      0.50      0.39       910\n",
      "weighted avg       0.51      0.57      0.43       910\n",
      "\n",
      "Accuracy List Length : 1651\n",
      "SUNPHARMA.NS   1752\n",
      "Accuracy: 0.49258997882851097\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.90      0.63       686\n",
      "           1       0.54      0.11      0.19       731\n",
      "\n",
      "    accuracy                           0.49      1417\n",
      "   macro avg       0.51      0.51      0.41      1417\n",
      "weighted avg       0.51      0.49      0.40      1417\n",
      "\n",
      "Accuracy List Length : 1652\n",
      "SUNTECK.NS   1753\n",
      "Accuracy: 0.5233380480905233\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.64       368\n",
      "           1       0.51      0.19      0.28       339\n",
      "\n",
      "    accuracy                           0.52       707\n",
      "   macro avg       0.52      0.51      0.46       707\n",
      "weighted avg       0.52      0.52      0.47       707\n",
      "\n",
      "Accuracy List Length : 1653\n",
      "SUNTV.NS   1754\n",
      "Accuracy: 0.4965986394557823\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.95      0.65       440\n",
      "           1       0.47      0.04      0.08       442\n",
      "\n",
      "    accuracy                           0.50       882\n",
      "   macro avg       0.49      0.50      0.37       882\n",
      "weighted avg       0.49      0.50      0.37       882\n",
      "\n",
      "Accuracy List Length : 1654\n",
      "SUPERHOUSE.NS   1755\n",
      "Accuracy: 0.5171673819742489\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68       241\n",
      "           1       0.50      0.00      0.01       225\n",
      "\n",
      "    accuracy                           0.52       466\n",
      "   macro avg       0.51      0.50      0.34       466\n",
      "weighted avg       0.51      0.52      0.36       466\n",
      "\n",
      "Accuracy List Length : 1655\n",
      "SUPERSPIN.NS   1756\n",
      "Accuracy: 0.5709876543209876\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.73       554\n",
      "           1       0.57      0.01      0.02       418\n",
      "\n",
      "    accuracy                           0.57       972\n",
      "   macro avg       0.57      0.50      0.37       972\n",
      "weighted avg       0.57      0.57      0.42       972\n",
      "\n",
      "Accuracy List Length : 1656\n",
      "SUPRAJIT.NS   1757\n",
      "Accuracy: 0.5430393198724761\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.70       511\n",
      "           1       0.50      0.04      0.08       430\n",
      "\n",
      "    accuracy                           0.54       941\n",
      "   macro avg       0.52      0.50      0.39       941\n",
      "weighted avg       0.52      0.54      0.42       941\n",
      "\n",
      "Accuracy List Length : 1657\n",
      "SUPREMEENG.NS   1758\n",
      "Accuracy: 0.6171003717472119\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.95      0.75       167\n",
      "           1       0.47      0.08      0.13       102\n",
      "\n",
      "    accuracy                           0.62       269\n",
      "   macro avg       0.55      0.51      0.44       269\n",
      "weighted avg       0.57      0.62      0.52       269\n",
      "\n",
      "Accuracy List Length : 1658\n",
      "SUPREMEIND.NS   1759\n",
      "Accuracy: 0.5032497678737233\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.07      0.12       536\n",
      "           1       0.50      0.94      0.65       541\n",
      "\n",
      "    accuracy                           0.50      1077\n",
      "   macro avg       0.51      0.50      0.39      1077\n",
      "weighted avg       0.51      0.50      0.39      1077\n",
      "\n",
      "Accuracy List Length : 1659\n",
      "SUPREMEINF.NS   1760\n",
      "Accuracy: 0.5618811881188119\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       461\n",
      "           1       0.29      0.01      0.03       347\n",
      "\n",
      "    accuracy                           0.56       808\n",
      "   macro avg       0.43      0.49      0.37       808\n",
      "weighted avg       0.45      0.56      0.42       808\n",
      "\n",
      "Accuracy List Length : 1660\n",
      "SUPRIYA.NS   1761\n",
      "Accuracy: 0.5688073394495413\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70        55\n",
      "           1       0.89      0.15      0.25        54\n",
      "\n",
      "    accuracy                           0.57       109\n",
      "   macro avg       0.71      0.56      0.48       109\n",
      "weighted avg       0.71      0.57      0.48       109\n",
      "\n",
      "Accuracy List Length : 1661\n",
      "SURAJEST.NS   1762\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.25      0.50      0.33        10\n",
      "weighted avg       0.25      0.50      0.33        10\n",
      "\n",
      "Accuracy List Length : 1662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SURANASOL.NS   1765\n",
      "Accuracy: 0.5891690009337068\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       629\n",
      "           1       0.57      0.02      0.04       442\n",
      "\n",
      "    accuracy                           0.59      1071\n",
      "   macro avg       0.58      0.50      0.39      1071\n",
      "weighted avg       0.58      0.59      0.45      1071\n",
      "\n",
      "Accuracy List Length : 1663\n",
      "SURANAT&P.NS   1766\n",
      "Accuracy: 0.5686456400742115\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       613\n",
      "           1       0.50      0.02      0.03       465\n",
      "\n",
      "    accuracy                           0.57      1078\n",
      "   macro avg       0.53      0.50      0.38      1078\n",
      "weighted avg       0.54      0.57      0.42      1078\n",
      "\n",
      "Accuracy List Length : 1664\n",
      "SURYALAXMI.NS   1767\n",
      "Accuracy: 0.5547309833024119\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.71       602\n",
      "           1       0.36      0.01      0.02       476\n",
      "\n",
      "    accuracy                           0.55      1078\n",
      "   macro avg       0.46      0.50      0.37      1078\n",
      "weighted avg       0.47      0.55      0.41      1078\n",
      "\n",
      "Accuracy List Length : 1665\n",
      "SURYAROSNI.NS   1768\n",
      "Accuracy: 0.5431754874651811\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       590\n",
      "           1       0.43      0.03      0.06       487\n",
      "\n",
      "    accuracy                           0.54      1077\n",
      "   macro avg       0.49      0.50      0.38      1077\n",
      "weighted avg       0.49      0.54      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1666\n",
      "SURYODAY.NS   1769\n",
      "Accuracy: 0.4589041095890411\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.96      0.62        68\n",
      "           1       0.40      0.03      0.05        78\n",
      "\n",
      "    accuracy                           0.46       146\n",
      "   macro avg       0.43      0.49      0.34       146\n",
      "weighted avg       0.43      0.46      0.32       146\n",
      "\n",
      "Accuracy List Length : 1667\n",
      "SUTLEJTEX.NS   1770\n",
      "Accuracy: 0.5284780578898226\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       571\n",
      "           1       0.33      0.01      0.02       500\n",
      "\n",
      "    accuracy                           0.53      1071\n",
      "   macro avg       0.43      0.50      0.35      1071\n",
      "weighted avg       0.44      0.53      0.38      1071\n",
      "\n",
      "Accuracy List Length : 1668\n",
      "SUULD.NS   1771\n",
      "Accuracy: 0.6289752650176679\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.94      0.76       172\n",
      "           1       0.62      0.14      0.23       111\n",
      "\n",
      "    accuracy                           0.63       283\n",
      "   macro avg       0.62      0.54      0.49       283\n",
      "weighted avg       0.62      0.63      0.55       283\n",
      "\n",
      "Accuracy List Length : 1669\n",
      "SUVEN.NS   1772\n",
      "Accuracy: 0.5044598612487612\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.99      0.67       507\n",
      "           1       0.62      0.01      0.02       502\n",
      "\n",
      "    accuracy                           0.50      1009\n",
      "   macro avg       0.56      0.50      0.34      1009\n",
      "weighted avg       0.56      0.50      0.35      1009\n",
      "\n",
      "Accuracy List Length : 1670\n",
      "SUVENPHAR.NS   1773\n",
      "Accuracy: 0.5656565656565656\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       112\n",
      "           1       0.50      0.03      0.07        86\n",
      "\n",
      "    accuracy                           0.57       198\n",
      "   macro avg       0.53      0.50      0.39       198\n",
      "weighted avg       0.54      0.57      0.43       198\n",
      "\n",
      "Accuracy List Length : 1671\n",
      "SUVIDHAA.NS   1774\n",
      "Accuracy: 0.636986301369863\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.77        94\n",
      "           1       0.43      0.06      0.10        52\n",
      "\n",
      "    accuracy                           0.64       146\n",
      "   macro avg       0.54      0.51      0.44       146\n",
      "weighted avg       0.57      0.64      0.53       146\n",
      "\n",
      "Accuracy List Length : 1672\n",
      "SUZLON.NS   1776\n",
      "Accuracy: 0.5622932745314223\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71       509\n",
      "           1       0.51      0.05      0.08       398\n",
      "\n",
      "    accuracy                           0.56       907\n",
      "   macro avg       0.54      0.51      0.40       907\n",
      "weighted avg       0.54      0.56      0.44       907\n",
      "\n",
      "Accuracy List Length : 1673\n",
      "SVLL.NS   1777\n",
      "Accuracy: 0.6925795053003534\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82       197\n",
      "           1       0.43      0.03      0.06        86\n",
      "\n",
      "    accuracy                           0.69       283\n",
      "   macro avg       0.56      0.51      0.44       283\n",
      "weighted avg       0.62      0.69      0.59       283\n",
      "\n",
      "Accuracy List Length : 1674\n",
      "SVPGLOB.NS   1778\n",
      "Accuracy: 0.648854961832061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.95      0.78        87\n",
      "           1       0.33      0.05      0.08        44\n",
      "\n",
      "    accuracy                           0.65       131\n",
      "   macro avg       0.50      0.50      0.43       131\n",
      "weighted avg       0.55      0.65      0.55       131\n",
      "\n",
      "Accuracy List Length : 1675\n",
      "SWANENERGY.NS   1779\n",
      "Accuracy: 0.5851979345955249\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.73       337\n",
      "           1       0.59      0.04      0.08       244\n",
      "\n",
      "    accuracy                           0.59       581\n",
      "   macro avg       0.59      0.51      0.40       581\n",
      "weighted avg       0.59      0.59      0.46       581\n",
      "\n",
      "Accuracy List Length : 1676\n",
      "SWARAJENG.NS   1780\n",
      "Accuracy: 0.5273909006499535\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       566\n",
      "           1       0.54      0.03      0.05       511\n",
      "\n",
      "    accuracy                           0.53      1077\n",
      "   macro avg       0.53      0.50      0.37      1077\n",
      "weighted avg       0.53      0.53      0.38      1077\n",
      "\n",
      "Accuracy List Length : 1677\n",
      "SWELECTES.NS   1781\n",
      "Accuracy: 0.525\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       464\n",
      "           1       0.42      0.01      0.02       416\n",
      "\n",
      "    accuracy                           0.53       880\n",
      "   macro avg       0.47      0.50      0.35       880\n",
      "weighted avg       0.47      0.53      0.37       880\n",
      "\n",
      "Accuracy List Length : 1678\n",
      "SWSOLAR.NS   1783\n",
      "Accuracy: 0.5176991150442478\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.94      0.67       120\n",
      "           1       0.36      0.04      0.07       106\n",
      "\n",
      "    accuracy                           0.52       226\n",
      "   macro avg       0.44      0.49      0.37       226\n",
      "weighted avg       0.45      0.52      0.39       226\n",
      "\n",
      "Accuracy List Length : 1679\n",
      "SYMPHONY.NS   1784\n",
      "Accuracy: 0.5286624203821656\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.69       337\n",
      "           1       0.31      0.01      0.03       291\n",
      "\n",
      "    accuracy                           0.53       628\n",
      "   macro avg       0.42      0.49      0.36       628\n",
      "weighted avg       0.43      0.53      0.38       628\n",
      "\n",
      "Accuracy List Length : 1680\n",
      "SYNCOMF.NS   1785\n",
      "Accuracy: 0.5076923076923077\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.67        33\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.51        65\n",
      "   macro avg       0.25      0.50      0.34        65\n",
      "weighted avg       0.26      0.51      0.34        65\n",
      "\n",
      "Accuracy List Length : 1681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNGENE.NS   1786\n",
      "Accuracy: 0.46335697399527187\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.17      0.26       234\n",
      "           1       0.45      0.83      0.58       189\n",
      "\n",
      "    accuracy                           0.46       423\n",
      "   macro avg       0.50      0.50      0.42       423\n",
      "weighted avg       0.50      0.46      0.40       423\n",
      "\n",
      "Accuracy List Length : 1682\n",
      "SYRMA.NS   1787\n",
      "Accuracy: 0.5131578947368421\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.69      0.57        36\n",
      "           1       0.56      0.35      0.43        40\n",
      "\n",
      "    accuracy                           0.51        76\n",
      "   macro avg       0.53      0.52      0.50        76\n",
      "weighted avg       0.53      0.51      0.50        76\n",
      "\n",
      "Accuracy List Length : 1683\n",
      "TAINWALCHM.NS   1788\n",
      "Accuracy: 0.5909090909090909\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       640\n",
      "           1       0.33      0.01      0.01       438\n",
      "\n",
      "    accuracy                           0.59      1078\n",
      "   macro avg       0.46      0.50      0.38      1078\n",
      "weighted avg       0.49      0.59      0.45      1078\n",
      "\n",
      "Accuracy List Length : 1684\n",
      "TAJGVK.NS   1789\n",
      "Accuracy: 0.5457089552238806\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.70       585\n",
      "           1       0.50      0.01      0.02       487\n",
      "\n",
      "    accuracy                           0.55      1072\n",
      "   macro avg       0.52      0.50      0.36      1072\n",
      "weighted avg       0.53      0.55      0.39      1072\n",
      "\n",
      "Accuracy List Length : 1685\n",
      "TAKE.NS   1790\n",
      "Accuracy: 0.5533742331288344\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       457\n",
      "           1       0.31      0.01      0.03       358\n",
      "\n",
      "    accuracy                           0.55       815\n",
      "   macro avg       0.44      0.49      0.37       815\n",
      "weighted avg       0.45      0.55      0.41       815\n",
      "\n",
      "Accuracy List Length : 1686\n",
      "TALBROAUTO.NS   1791\n",
      "Accuracy: 0.5476744186046512\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70       469\n",
      "           1       0.56      0.03      0.05       391\n",
      "\n",
      "    accuracy                           0.55       860\n",
      "   macro avg       0.55      0.50      0.38       860\n",
      "weighted avg       0.55      0.55      0.41       860\n",
      "\n",
      "Accuracy List Length : 1687\n",
      "TANLA.NS   1792\n",
      "Accuracy: 0.5985832349468713\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.75       510\n",
      "           1       0.38      0.01      0.03       337\n",
      "\n",
      "    accuracy                           0.60       847\n",
      "   macro avg       0.49      0.50      0.39       847\n",
      "weighted avg       0.52      0.60      0.46       847\n",
      "\n",
      "Accuracy List Length : 1688\n",
      "TARACHAND.NS   1793\n",
      "Accuracy: 0.5918367346938775\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.74       176\n",
      "           1       0.38      0.03      0.05       118\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.49      0.50      0.39       294\n",
      "weighted avg       0.51      0.59      0.46       294\n",
      "\n",
      "Accuracy List Length : 1689\n",
      "TARAPUR.NS   1794\n",
      "Accuracy: 0.6480938416422287\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78       439\n",
      "           1       0.60      0.04      0.07       243\n",
      "\n",
      "    accuracy                           0.65       682\n",
      "   macro avg       0.62      0.51      0.43       682\n",
      "weighted avg       0.63      0.65      0.53       682\n",
      "\n",
      "Accuracy List Length : 1690\n",
      "TARC.NS   1795\n",
      "Accuracy: 0.4716981132075472\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.83      0.62        82\n",
      "           1       0.33      0.09      0.14        77\n",
      "\n",
      "    accuracy                           0.47       159\n",
      "   macro avg       0.41      0.46      0.38       159\n",
      "weighted avg       0.42      0.47      0.39       159\n",
      "\n",
      "Accuracy List Length : 1691\n",
      "TARMAT.NS   1797\n",
      "Accuracy: 0.6058394160583942\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75       499\n",
      "           1       0.43      0.01      0.02       323\n",
      "\n",
      "    accuracy                           0.61       822\n",
      "   macro avg       0.52      0.50      0.39       822\n",
      "weighted avg       0.54      0.61      0.46       822\n",
      "\n",
      "Accuracy List Length : 1692\n",
      "TARSONS.NS   1798\n",
      "Accuracy: 0.5398230088495575\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70        62\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.54       113\n",
      "   macro avg       0.27      0.49      0.35       113\n",
      "weighted avg       0.30      0.54      0.38       113\n",
      "\n",
      "Accuracy List Length : 1693\n",
      "TASTYBITE.NS   1799\n",
      "Accuracy: 0.5145348837209303\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.99      0.67       173\n",
      "           1       0.83      0.03      0.06       171\n",
      "\n",
      "    accuracy                           0.51       344\n",
      "   macro avg       0.67      0.51      0.36       344\n",
      "weighted avg       0.67      0.51      0.37       344\n",
      "\n",
      "Accuracy List Length : 1694\n",
      "TATACHEM.NS   1800\n",
      "Accuracy: 0.5172900494001411\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.92      0.66       734\n",
      "           1       0.50      0.08      0.14       683\n",
      "\n",
      "    accuracy                           0.52      1417\n",
      "   macro avg       0.51      0.50      0.40      1417\n",
      "weighted avg       0.51      0.52      0.41      1417\n",
      "\n",
      "Accuracy List Length : 1695\n",
      "TATACOMM.NS   1801\n",
      "Accuracy: 0.5162488393686165\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       554\n",
      "           1       0.54      0.03      0.05       523\n",
      "\n",
      "    accuracy                           0.52      1077\n",
      "   macro avg       0.53      0.50      0.36      1077\n",
      "weighted avg       0.53      0.52      0.37      1077\n",
      "\n",
      "Accuracy List Length : 1696\n",
      "TATACONSUM.NS   1802\n",
      "Accuracy: 0.5098870056497176\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66       720\n",
      "           1       0.51      0.07      0.13       696\n",
      "\n",
      "    accuracy                           0.51      1416\n",
      "   macro avg       0.51      0.50      0.39      1416\n",
      "weighted avg       0.51      0.51      0.40      1416\n",
      "\n",
      "Accuracy List Length : 1697\n",
      "TATAELXSI.NS   1803\n",
      "Accuracy: 0.5376044568245125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.69       574\n",
      "           1       0.54      0.07      0.13       503\n",
      "\n",
      "    accuracy                           0.54      1077\n",
      "   macro avg       0.54      0.51      0.41      1077\n",
      "weighted avg       0.54      0.54      0.43      1077\n",
      "\n",
      "Accuracy List Length : 1698\n",
      "TATAINVEST.NS   1804\n",
      "Accuracy: 0.5723359209597741\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73       807\n",
      "           1       0.67      0.01      0.03       610\n",
      "\n",
      "    accuracy                           0.57      1417\n",
      "   macro avg       0.62      0.50      0.38      1417\n",
      "weighted avg       0.61      0.57      0.42      1417\n",
      "\n",
      "Accuracy List Length : 1699\n",
      "TATAMOTORS.NS   1805\n",
      "Accuracy: 0.533969010727056\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69       911\n",
      "           1       0.41      0.05      0.08       767\n",
      "\n",
      "    accuracy                           0.53      1678\n",
      "   macro avg       0.48      0.50      0.38      1678\n",
      "weighted avg       0.48      0.53      0.41      1678\n",
      "\n",
      "Accuracy List Length : 1700\n",
      "TATAPOWER.NS   1806\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.93      0.65       710\n",
      "           1       0.49      0.07      0.13       706\n",
      "\n",
      "    accuracy                           0.50      1416\n",
      "   macro avg       0.50      0.50      0.39      1416\n",
      "weighted avg       0.50      0.50      0.39      1416\n",
      "\n",
      "Accuracy List Length : 1701\n",
      "TATASTEEL.NS   1807\n",
      "Accuracy: 0.5045871559633027\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.90      0.64       709\n",
      "           1       0.52      0.11      0.18       708\n",
      "\n",
      "    accuracy                           0.50      1417\n",
      "   macro avg       0.51      0.50      0.41      1417\n",
      "weighted avg       0.51      0.50      0.41      1417\n",
      "\n",
      "Accuracy List Length : 1702\n",
      "TATATECH.NS   1808\n",
      "Accuracy: 0.6923076923076923\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        10\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.38      0.45      0.41        13\n",
      "weighted avg       0.58      0.69      0.63        13\n",
      "\n",
      "Accuracy List Length : 1703\n",
      "TATVA.NS   1809\n",
      "Accuracy: 0.5193798449612403\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        66\n",
      "           1       1.00      0.02      0.03        63\n",
      "\n",
      "    accuracy                           0.52       129\n",
      "   macro avg       0.76      0.51      0.36       129\n",
      "weighted avg       0.75      0.52      0.36       129\n",
      "\n",
      "Accuracy List Length : 1704\n",
      "TBZ.NS   1811\n",
      "Accuracy: 0.5256849315068494\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.96      0.68       311\n",
      "           1       0.39      0.03      0.05       273\n",
      "\n",
      "    accuracy                           0.53       584\n",
      "   macro avg       0.46      0.50      0.37       584\n",
      "weighted avg       0.46      0.53      0.39       584\n",
      "\n",
      "Accuracy List Length : 1705\n",
      "TCI.NS   1812\n",
      "Accuracy: 0.487012987012987\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.97      0.65       527\n",
      "           1       0.47      0.03      0.05       551\n",
      "\n",
      "    accuracy                           0.49      1078\n",
      "   macro avg       0.48      0.50      0.35      1078\n",
      "weighted avg       0.48      0.49      0.34      1078\n",
      "\n",
      "Accuracy List Length : 1706\n",
      "TCIEXP.NS   1813\n",
      "Accuracy: 0.5307262569832403\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       189\n",
      "           1       0.60      0.02      0.03       169\n",
      "\n",
      "    accuracy                           0.53       358\n",
      "   macro avg       0.56      0.50      0.36       358\n",
      "weighted avg       0.56      0.53      0.38       358\n",
      "\n",
      "Accuracy List Length : 1707\n",
      "TCIFINANCE.NS   1814\n",
      "Accuracy: 0.6188166828322017\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.99      0.76       640\n",
      "           1       0.42      0.01      0.02       391\n",
      "\n",
      "    accuracy                           0.62      1031\n",
      "   macro avg       0.52      0.50      0.39      1031\n",
      "weighted avg       0.54      0.62      0.48      1031\n",
      "\n",
      "Accuracy List Length : 1708\n",
      "TCLCONS.NS   1815\n",
      "Accuracy: 0.5663716814159292\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.71       445\n",
      "           1       0.54      0.05      0.10       346\n",
      "\n",
      "    accuracy                           0.57       791\n",
      "   macro avg       0.56      0.51      0.41       791\n",
      "weighted avg       0.56      0.57      0.45       791\n",
      "\n",
      "Accuracy List Length : 1709\n",
      "TCPLPACK.NS   1816\n",
      "Accuracy: 0.5348101265822784\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       167\n",
      "           1       0.75      0.02      0.04       149\n",
      "\n",
      "    accuracy                           0.53       316\n",
      "   macro avg       0.64      0.51      0.37       316\n",
      "weighted avg       0.63      0.53      0.38       316\n",
      "\n",
      "Accuracy List Length : 1710\n",
      "TCS.NS   1817\n",
      "Accuracy: 0.5298507462686567\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.40      0.48       566\n",
      "           1       0.50      0.67      0.57       506\n",
      "\n",
      "    accuracy                           0.53      1072\n",
      "   macro avg       0.54      0.54      0.52      1072\n",
      "weighted avg       0.54      0.53      0.52      1072\n",
      "\n",
      "Accuracy List Length : 1711\n",
      "TDPOWERSYS.NS   1818\n",
      "Accuracy: 0.5032467532467533\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.96      0.66       310\n",
      "           1       0.50      0.04      0.07       306\n",
      "\n",
      "    accuracy                           0.50       616\n",
      "   macro avg       0.50      0.50      0.36       616\n",
      "weighted avg       0.50      0.50      0.37       616\n",
      "\n",
      "Accuracy List Length : 1712\n",
      "TEAMLEASE.NS   1819\n",
      "Accuracy: 0.5037593984962406\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.84      0.63       198\n",
      "           1       0.52      0.17      0.26       201\n",
      "\n",
      "    accuracy                           0.50       399\n",
      "   macro avg       0.51      0.51      0.44       399\n",
      "weighted avg       0.51      0.50      0.44       399\n",
      "\n",
      "Accuracy List Length : 1713\n",
      "TECHM.NS   1820\n",
      "Accuracy: 0.5098265895953757\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.06      0.11       425\n",
      "           1       0.51      0.95      0.66       440\n",
      "\n",
      "    accuracy                           0.51       865\n",
      "   macro avg       0.51      0.50      0.38       865\n",
      "weighted avg       0.51      0.51      0.39       865\n",
      "\n",
      "Accuracy List Length : 1714\n",
      "TECHNOE.NS   1821\n",
      "Accuracy: 0.5586124401913876\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       465\n",
      "           1       0.55      0.03      0.06       371\n",
      "\n",
      "    accuracy                           0.56       836\n",
      "   macro avg       0.55      0.51      0.39       836\n",
      "weighted avg       0.55      0.56      0.42       836\n",
      "\n",
      "Accuracy List Length : 1715\n",
      "TECILCHEM.NS   1822\n",
      "Accuracy: 0.7272727272727273\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        31\n",
      "           1       1.00      0.08      0.14        13\n",
      "\n",
      "    accuracy                           0.73        44\n",
      "   macro avg       0.86      0.54      0.49        44\n",
      "weighted avg       0.80      0.73      0.63        44\n",
      "\n",
      "Accuracy List Length : 1716\n",
      "TEGA.NS   1823\n",
      "Accuracy: 0.5405405405405406\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.13      0.22        52\n",
      "           1       0.54      0.90      0.68        59\n",
      "\n",
      "    accuracy                           0.54       111\n",
      "   macro avg       0.54      0.52      0.45       111\n",
      "weighted avg       0.54      0.54      0.46       111\n",
      "\n",
      "Accuracy List Length : 1717\n",
      "TEJASNET.NS   1824\n",
      "Accuracy: 0.5438066465256798\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       180\n",
      "           1       0.50      0.03      0.06       151\n",
      "\n",
      "    accuracy                           0.54       331\n",
      "   macro avg       0.52      0.50      0.38       331\n",
      "weighted avg       0.52      0.54      0.41       331\n",
      "\n",
      "Accuracy List Length : 1718\n",
      "TEMBO.NS   1825\n",
      "Accuracy: 0.6190476190476191\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76       168\n",
      "           1       0.55      0.06      0.10       105\n",
      "\n",
      "    accuracy                           0.62       273\n",
      "   macro avg       0.58      0.51      0.43       273\n",
      "weighted avg       0.59      0.62      0.51       273\n",
      "\n",
      "Accuracy List Length : 1719\n",
      "TERASOFT.NS   1826\n",
      "Accuracy: 0.5617977528089888\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       195\n",
      "           1       0.73      0.05      0.09       161\n",
      "\n",
      "    accuracy                           0.56       356\n",
      "   macro avg       0.64      0.52      0.40       356\n",
      "weighted avg       0.63      0.56      0.43       356\n",
      "\n",
      "Accuracy List Length : 1720\n",
      "TEXINFRA.NS   1827\n",
      "Accuracy: 0.5607476635514018\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       548\n",
      "           1       0.42      0.05      0.09       415\n",
      "\n",
      "    accuracy                           0.56       963\n",
      "   macro avg       0.49      0.50      0.40       963\n",
      "weighted avg       0.50      0.56      0.44       963\n",
      "\n",
      "Accuracy List Length : 1721\n",
      "TEXMOPIPES.NS   1828\n",
      "Accuracy: 0.5658465991316932\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       390\n",
      "           1       0.60      0.01      0.02       301\n",
      "\n",
      "    accuracy                           0.57       691\n",
      "   macro avg       0.58      0.50      0.37       691\n",
      "weighted avg       0.58      0.57      0.42       691\n",
      "\n",
      "Accuracy List Length : 1722\n",
      "TEXRAIL.NS   1829\n",
      "Accuracy: 0.5295950155763239\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       512\n",
      "           1       0.40      0.01      0.02       451\n",
      "\n",
      "    accuracy                           0.53       963\n",
      "   macro avg       0.47      0.50      0.35       963\n",
      "weighted avg       0.47      0.53      0.38       963\n",
      "\n",
      "Accuracy List Length : 1723\n",
      "TFCILTD.NS   1830\n",
      "Accuracy: 0.5886722376973074\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       625\n",
      "           1       0.80      0.03      0.05       452\n",
      "\n",
      "    accuracy                           0.59      1077\n",
      "   macro avg       0.69      0.51      0.39      1077\n",
      "weighted avg       0.68      0.59      0.45      1077\n",
      "\n",
      "Accuracy List Length : 1724\n",
      "TFL.NS   1831\n",
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.73       492\n",
      "           1       0.45      0.03      0.05       348\n",
      "\n",
      "    accuracy                           0.58       840\n",
      "   macro avg       0.52      0.50      0.39       840\n",
      "weighted avg       0.53      0.58      0.45       840\n",
      "\n",
      "Accuracy List Length : 1725\n",
      "TGBHOTELS.NS   1832\n",
      "Accuracy: 0.563855421686747\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       470\n",
      "           1       0.33      0.01      0.01       360\n",
      "\n",
      "    accuracy                           0.56       830\n",
      "   macro avg       0.45      0.50      0.37       830\n",
      "weighted avg       0.46      0.56      0.41       830\n",
      "\n",
      "Accuracy List Length : 1726\n",
      "THANGAMAYL.NS   1833\n",
      "Accuracy: 0.5187319884726225\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       363\n",
      "           1       0.38      0.02      0.03       331\n",
      "\n",
      "    accuracy                           0.52       694\n",
      "   macro avg       0.45      0.50      0.35       694\n",
      "weighted avg       0.46      0.52      0.37       694\n",
      "\n",
      "Accuracy List Length : 1727\n",
      "THEINVEST.NS   1834\n",
      "Accuracy: 0.5460122699386503\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       178\n",
      "           1       0.50      0.03      0.06       148\n",
      "\n",
      "    accuracy                           0.55       326\n",
      "   macro avg       0.52      0.50      0.38       326\n",
      "weighted avg       0.53      0.55      0.41       326\n",
      "\n",
      "Accuracy List Length : 1728\n",
      "THEJO.NS   1835\n",
      "Accuracy: 0.6455026455026455\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78       242\n",
      "           1       0.75      0.02      0.04       136\n",
      "\n",
      "    accuracy                           0.65       378\n",
      "   macro avg       0.70      0.51      0.41       378\n",
      "weighted avg       0.68      0.65      0.52       378\n",
      "\n",
      "Accuracy List Length : 1729\n",
      "THEMISMED.NS   1836\n",
      "Accuracy: 0.5645933014354066\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72       464\n",
      "           1       0.83      0.03      0.05       372\n",
      "\n",
      "    accuracy                           0.56       836\n",
      "   macro avg       0.70      0.51      0.38       836\n",
      "weighted avg       0.68      0.56      0.42       836\n",
      "\n",
      "Accuracy List Length : 1730\n",
      "THERMAX.NS   1837\n",
      "Accuracy: 0.5018552875695733\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66       537\n",
      "           1       0.59      0.02      0.05       541\n",
      "\n",
      "    accuracy                           0.50      1078\n",
      "   macro avg       0.55      0.50      0.35      1078\n",
      "weighted avg       0.55      0.50      0.35      1078\n",
      "\n",
      "Accuracy List Length : 1731\n",
      "THOMASCOOK.NS   1838\n",
      "Accuracy: 0.5515320334261838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       589\n",
      "           1       0.65      0.02      0.04       488\n",
      "\n",
      "    accuracy                           0.55      1077\n",
      "   macro avg       0.60      0.51      0.38      1077\n",
      "weighted avg       0.59      0.55      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1732\n",
      "THOMASCOTT.NS   1839\n",
      "Accuracy: 0.7018425460636516\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82       415\n",
      "           1       0.56      0.10      0.18       182\n",
      "\n",
      "    accuracy                           0.70       597\n",
      "   macro avg       0.63      0.53      0.50       597\n",
      "weighted avg       0.66      0.70      0.62       597\n",
      "\n",
      "Accuracy List Length : 1733\n",
      "THYROCARE.NS   1840\n",
      "Accuracy: 0.5360824742268041\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       205\n",
      "           1       0.67      0.03      0.06       183\n",
      "\n",
      "    accuracy                           0.54       388\n",
      "   macro avg       0.60      0.51      0.38       388\n",
      "weighted avg       0.60      0.54      0.39       388\n",
      "\n",
      "Accuracy List Length : 1734\n",
      "TI.NS   1841\n",
      "Accuracy: 0.5623145400593472\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.71       380\n",
      "           1       0.48      0.04      0.08       294\n",
      "\n",
      "    accuracy                           0.56       674\n",
      "   macro avg       0.52      0.50      0.39       674\n",
      "weighted avg       0.53      0.56      0.43       674\n",
      "\n",
      "Accuracy List Length : 1735\n",
      "TIIL.NS   1842\n",
      "Accuracy: 0.5261282660332541\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.96      0.68       450\n",
      "           1       0.37      0.03      0.05       392\n",
      "\n",
      "    accuracy                           0.53       842\n",
      "   macro avg       0.45      0.49      0.37       842\n",
      "weighted avg       0.46      0.53      0.39       842\n",
      "\n",
      "Accuracy List Length : 1736\n",
      "TIINDIA.NS   1843\n",
      "Accuracy: 0.5095541401273885\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.17      0.26       155\n",
      "           1       0.51      0.84      0.63       159\n",
      "\n",
      "    accuracy                           0.51       314\n",
      "   macro avg       0.51      0.51      0.45       314\n",
      "weighted avg       0.51      0.51      0.45       314\n",
      "\n",
      "Accuracy List Length : 1737\n",
      "TIJARIA.NS   1844\n",
      "Accuracy: 0.5957446808510638\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       360\n",
      "           1       0.70      0.03      0.05       251\n",
      "\n",
      "    accuracy                           0.60       611\n",
      "   macro avg       0.65      0.51      0.40       611\n",
      "weighted avg       0.64      0.60      0.46       611\n",
      "\n",
      "Accuracy List Length : 1738\n",
      "TIL.NS   1845\n",
      "Accuracy: 0.5376044568245125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.70       590\n",
      "           1       0.33      0.02      0.04       487\n",
      "\n",
      "    accuracy                           0.54      1077\n",
      "   macro avg       0.44      0.49      0.37      1077\n",
      "weighted avg       0.45      0.54      0.40      1077\n",
      "\n",
      "Accuracy List Length : 1739\n",
      "TIMESGTY.NS   1846\n",
      "Accuracy: 0.5844155844155844\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.74       636\n",
      "           1       0.29      0.01      0.02       442\n",
      "\n",
      "    accuracy                           0.58      1078\n",
      "   macro avg       0.44      0.50      0.38      1078\n",
      "weighted avg       0.46      0.58      0.44      1078\n",
      "\n",
      "Accuracy List Length : 1740\n",
      "TIMETECHNO.NS   1847\n",
      "Accuracy: 0.549636803874092\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71       462\n",
      "           1       0.35      0.02      0.05       364\n",
      "\n",
      "    accuracy                           0.55       826\n",
      "   macro avg       0.45      0.49      0.38       826\n",
      "weighted avg       0.46      0.55      0.41       826\n",
      "\n",
      "Accuracy List Length : 1741\n",
      "TIMKEN.NS   1848\n",
      "Accuracy: 0.6268656716417911\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.77       674\n",
      "           1       0.47      0.04      0.08       398\n",
      "\n",
      "    accuracy                           0.63      1072\n",
      "   macro avg       0.55      0.51      0.42      1072\n",
      "weighted avg       0.57      0.63      0.51      1072\n",
      "\n",
      "Accuracy List Length : 1742\n",
      "TIPSFILMS.NS   1849\n",
      "Accuracy: 0.4857142857142857\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.57        34\n",
      "           1       0.50      0.28      0.36        36\n",
      "\n",
      "    accuracy                           0.49        70\n",
      "   macro avg       0.49      0.49      0.46        70\n",
      "weighted avg       0.49      0.49      0.46        70\n",
      "\n",
      "Accuracy List Length : 1743\n",
      "TIPSMUSIC.NS   1850\n",
      "Accuracy: 0.5478180129990715\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.70       586\n",
      "           1       0.60      0.02      0.05       491\n",
      "\n",
      "    accuracy                           0.55      1077\n",
      "   macro avg       0.57      0.51      0.38      1077\n",
      "weighted avg       0.57      0.55      0.40      1077\n",
      "\n",
      "Accuracy List Length : 1744\n",
      "TIRUMALCHM.NS   1851\n",
      "Accuracy: 0.5352504638218923\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       574\n",
      "           1       0.57      0.03      0.05       504\n",
      "\n",
      "    accuracy                           0.54      1078\n",
      "   macro avg       0.55      0.50      0.37      1078\n",
      "weighted avg       0.55      0.54      0.39      1078\n",
      "\n",
      "Accuracy List Length : 1745\n",
      "TIRUPATIFL.NS   1852\n",
      "Accuracy: 0.5741324921135647\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.72       174\n",
      "           1       0.83      0.07      0.13       143\n",
      "\n",
      "    accuracy                           0.57       317\n",
      "   macro avg       0.70      0.53      0.42       317\n",
      "weighted avg       0.69      0.57      0.45       317\n",
      "\n",
      "Accuracy List Length : 1746\n",
      "TITAGARH.NS   1853\n",
      "Accuracy: 0.5044699872286079\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.97      0.66       396\n",
      "           1       0.48      0.03      0.05       387\n",
      "\n",
      "    accuracy                           0.50       783\n",
      "   macro avg       0.49      0.50      0.36       783\n",
      "weighted avg       0.49      0.50      0.36       783\n",
      "\n",
      "Accuracy List Length : 1747\n",
      "TITAN.NS   1854\n",
      "Accuracy: 0.4954128440366973\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.88      0.63       703\n",
      "           1       0.50      0.11      0.19       714\n",
      "\n",
      "    accuracy                           0.50      1417\n",
      "   macro avg       0.50      0.50      0.41      1417\n",
      "weighted avg       0.50      0.50      0.41      1417\n",
      "\n",
      "Accuracy List Length : 1748\n",
      "TMB.NS   1855\n",
      "Accuracy: 0.5342465753424658\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.85      0.66        39\n",
      "           1       0.50      0.18      0.26        34\n",
      "\n",
      "    accuracy                           0.53        73\n",
      "   macro avg       0.52      0.51      0.46        73\n",
      "weighted avg       0.52      0.53      0.47        73\n",
      "\n",
      "Accuracy List Length : 1749\n",
      "TNPETRO.NS   1856\n",
      "Accuracy: 0.5812441968430826\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       625\n",
      "           1       0.53      0.02      0.04       452\n",
      "\n",
      "    accuracy                           0.58      1077\n",
      "   macro avg       0.56      0.50      0.39      1077\n",
      "weighted avg       0.56      0.58      0.44      1077\n",
      "\n",
      "Accuracy List Length : 1750\n",
      "TNPL.NS   1857\n",
      "Accuracy: 0.5228758169934641\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69       557\n",
      "           1       0.80      0.01      0.02       514\n",
      "\n",
      "    accuracy                           0.52      1071\n",
      "   macro avg       0.66      0.50      0.35      1071\n",
      "weighted avg       0.66      0.52      0.36      1071\n",
      "\n",
      "Accuracy List Length : 1751\n",
      "TNTELE.NS   1858\n",
      "Accuracy: 0.6492063492063492\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78       814\n",
      "           1       0.58      0.03      0.06       446\n",
      "\n",
      "    accuracy                           0.65      1260\n",
      "   macro avg       0.62      0.51      0.42      1260\n",
      "weighted avg       0.63      0.65      0.53      1260\n",
      "\n",
      "Accuracy List Length : 1752\n",
      "TOKYOPLAST.NS   1859\n",
      "Accuracy: 0.6326530612244898\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.78       683\n",
      "           1       0.00      0.00      0.00       395\n",
      "\n",
      "    accuracy                           0.63      1078\n",
      "   macro avg       0.32      0.50      0.39      1078\n",
      "weighted avg       0.40      0.63      0.49      1078\n",
      "\n",
      "Accuracy List Length : 1753\n",
      "TORNTPHARM.NS   1861\n",
      "Accuracy: 0.4972170686456401\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.03      0.05       541\n",
      "           1       0.50      0.97      0.66       537\n",
      "\n",
      "    accuracy                           0.50      1078\n",
      "   macro avg       0.49      0.50      0.35      1078\n",
      "weighted avg       0.49      0.50      0.35      1078\n",
      "\n",
      "Accuracy List Length : 1754\n",
      "TORNTPOWER.NS   1862\n",
      "Accuracy: 0.5316901408450704\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69       457\n",
      "           1       0.43      0.03      0.06       395\n",
      "\n",
      "    accuracy                           0.53       852\n",
      "   macro avg       0.48      0.50      0.37       852\n",
      "weighted avg       0.49      0.53      0.40       852\n",
      "\n",
      "Accuracy List Length : 1755\n",
      "TOTAL.NS   1863\n",
      "Accuracy: 0.6615384615384615\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79       216\n",
      "           1       0.44      0.04      0.07       109\n",
      "\n",
      "    accuracy                           0.66       325\n",
      "   macro avg       0.56      0.51      0.43       325\n",
      "weighted avg       0.59      0.66      0.55       325\n",
      "\n",
      "Accuracy List Length : 1756\n",
      "TOUCHWOOD.NS   1864\n",
      "Accuracy: 0.6026058631921825\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.75       183\n",
      "           1       0.62      0.04      0.08       124\n",
      "\n",
      "    accuracy                           0.60       307\n",
      "   macro avg       0.61      0.51      0.41       307\n",
      "weighted avg       0.61      0.60      0.48       307\n",
      "\n",
      "Accuracy List Length : 1757\n",
      "TPHQ.NS   1865\n",
      "Accuracy: 0.5457142857142857\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       192\n",
      "           1       0.45      0.03      0.06       158\n",
      "\n",
      "    accuracy                           0.55       350\n",
      "   macro avg       0.50      0.50      0.38       350\n",
      "weighted avg       0.51      0.55      0.41       350\n",
      "\n",
      "Accuracy List Length : 1758\n",
      "TPLPLASTEH.NS   1866\n",
      "Accuracy: 0.5770114942528736\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       252\n",
      "           1       0.40      0.01      0.02       183\n",
      "\n",
      "    accuracy                           0.58       435\n",
      "   macro avg       0.49      0.50      0.38       435\n",
      "weighted avg       0.50      0.58      0.43       435\n",
      "\n",
      "Accuracy List Length : 1759\n",
      "TRACXN.NS   1867\n",
      "Accuracy: 0.5147058823529411\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.76      0.63        37\n",
      "           1       0.44      0.23      0.30        31\n",
      "\n",
      "    accuracy                           0.51        68\n",
      "   macro avg       0.49      0.49      0.46        68\n",
      "weighted avg       0.49      0.51      0.48        68\n",
      "\n",
      "Accuracy List Length : 1760\n",
      "TREEHOUSE.NS   1870\n",
      "Accuracy: 0.5760517799352751\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       355\n",
      "           1       0.60      0.01      0.02       263\n",
      "\n",
      "    accuracy                           0.58       618\n",
      "   macro avg       0.59      0.50      0.38       618\n",
      "weighted avg       0.59      0.58      0.43       618\n",
      "\n",
      "Accuracy List Length : 1761\n",
      "TREJHARA.NS   1871\n",
      "Accuracy: 0.5214007782101168\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66       130\n",
      "           1       0.59      0.10      0.17       127\n",
      "\n",
      "    accuracy                           0.52       257\n",
      "   macro avg       0.55      0.52      0.42       257\n",
      "weighted avg       0.55      0.52      0.42       257\n",
      "\n",
      "Accuracy List Length : 1762\n",
      "TREL.NS   1872\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.88      0.67        16\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.27      0.44      0.33        28\n",
      "weighted avg       0.31      0.50      0.38        28\n",
      "\n",
      "Accuracy List Length : 1763\n",
      "TRENT.NS   1873\n",
      "Accuracy: 0.5273909006499535\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       571\n",
      "           1       0.43      0.02      0.04       506\n",
      "\n",
      "    accuracy                           0.53      1077\n",
      "   macro avg       0.48      0.50      0.36      1077\n",
      "weighted avg       0.48      0.53      0.38      1077\n",
      "\n",
      "Accuracy List Length : 1764\n",
      "TRF.NS   1874\n",
      "Accuracy: 0.5742857142857143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73       408\n",
      "           1       0.25      0.01      0.02       292\n",
      "\n",
      "    accuracy                           0.57       700\n",
      "   macro avg       0.41      0.49      0.37       700\n",
      "weighted avg       0.44      0.57      0.43       700\n",
      "\n",
      "Accuracy List Length : 1765\n",
      "TRIDENT.NS   1875\n",
      "Accuracy: 0.5868152274837511\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       632\n",
      "           1       0.50      0.02      0.03       445\n",
      "\n",
      "    accuracy                           0.59      1077\n",
      "   macro avg       0.54      0.50      0.38      1077\n",
      "weighted avg       0.55      0.59      0.45      1077\n",
      "\n",
      "Accuracy List Length : 1766\n",
      "TRIGYN.NS   1876\n",
      "Accuracy: 0.5793871866295265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73       632\n",
      "           1       0.21      0.01      0.01       445\n",
      "\n",
      "    accuracy                           0.58      1077\n",
      "   macro avg       0.40      0.49      0.37      1077\n",
      "weighted avg       0.43      0.58      0.44      1077\n",
      "\n",
      "Accuracy List Length : 1767\n",
      "TRITURBINE.NS   1877\n",
      "Accuracy: 0.49836065573770494\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66       308\n",
      "           1       0.30      0.01      0.02       302\n",
      "\n",
      "    accuracy                           0.50       610\n",
      "   macro avg       0.40      0.49      0.34       610\n",
      "weighted avg       0.40      0.50      0.34       610\n",
      "\n",
      "Accuracy List Length : 1768\n",
      "TRIVENI.NS   1878\n",
      "Accuracy: 0.5277777777777778\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.69       476\n",
      "           1       0.48      0.03      0.05       424\n",
      "\n",
      "    accuracy                           0.53       900\n",
      "   macro avg       0.50      0.50      0.37       900\n",
      "weighted avg       0.51      0.53      0.39       900\n",
      "\n",
      "Accuracy List Length : 1769\n",
      "TRU.NS   1879\n",
      "Accuracy: 0.6\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74        31\n",
      "           1       1.00      0.08      0.15        24\n",
      "\n",
      "    accuracy                           0.60        55\n",
      "   macro avg       0.79      0.54      0.45        55\n",
      "weighted avg       0.77      0.60      0.48        55\n",
      "\n",
      "Accuracy List Length : 1770\n",
      "TTKHLTCARE.NS   1880\n",
      "Accuracy: 0.5942857142857143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.74       418\n",
      "           1       0.43      0.02      0.04       282\n",
      "\n",
      "    accuracy                           0.59       700\n",
      "   macro avg       0.51      0.50      0.39       700\n",
      "weighted avg       0.53      0.59      0.46       700\n",
      "\n",
      "Accuracy List Length : 1771\n",
      "TTKPRESTIG.NS   1881\n",
      "Accuracy: 0.5231910946196661\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69       564\n",
      "           1       0.50      0.00      0.00       514\n",
      "\n",
      "    accuracy                           0.52      1078\n",
      "   macro avg       0.51      0.50      0.35      1078\n",
      "weighted avg       0.51      0.52      0.36      1078\n",
      "\n",
      "Accuracy List Length : 1772\n",
      "TTL.NS   1882\n",
      "Accuracy: 0.5517241379310345\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       462\n",
      "           1       0.67      0.01      0.02       379\n",
      "\n",
      "    accuracy                           0.55       841\n",
      "   macro avg       0.61      0.50      0.37       841\n",
      "weighted avg       0.60      0.55      0.40       841\n",
      "\n",
      "Accuracy List Length : 1773\n",
      "TTML.NS   1883\n",
      "Accuracy: 0.5768240343347639\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       668\n",
      "           1       0.60      0.02      0.05       497\n",
      "\n",
      "    accuracy                           0.58      1165\n",
      "   macro avg       0.59      0.51      0.39      1165\n",
      "weighted avg       0.59      0.58      0.44      1165\n",
      "\n",
      "Accuracy List Length : 1774\n",
      "TVSELECT.NS   1884\n",
      "Accuracy: 0.5918367346938775\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.74       648\n",
      "           1       0.31      0.02      0.04       430\n",
      "\n",
      "    accuracy                           0.59      1078\n",
      "   macro avg       0.45      0.50      0.39      1078\n",
      "weighted avg       0.48      0.59      0.46      1078\n",
      "\n",
      "Accuracy List Length : 1775\n",
      "TVSHLTD.NS   1885\n",
      "Accuracy: 0.5182072829131653\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       554\n",
      "           1       0.52      0.02      0.04       517\n",
      "\n",
      "    accuracy                           0.52      1071\n",
      "   macro avg       0.52      0.50      0.36      1071\n",
      "weighted avg       0.52      0.52      0.37      1071\n",
      "\n",
      "Accuracy List Length : 1776\n",
      "TVSMOTOR.NS   1886\n",
      "Accuracy: 0.5178268251273345\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       608\n",
      "           1       0.53      0.03      0.06       570\n",
      "\n",
      "    accuracy                           0.52      1178\n",
      "   macro avg       0.52      0.50      0.37      1178\n",
      "weighted avg       0.52      0.52      0.38      1178\n",
      "\n",
      "Accuracy List Length : 1777\n",
      "TVSSCS.NS   1887\n",
      "Accuracy: 0.4230769230769231\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.18      0.29        17\n",
      "           1       0.36      0.89      0.52         9\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.56      0.53      0.40        26\n",
      "weighted avg       0.62      0.42      0.37        26\n",
      "\n",
      "Accuracy List Length : 1778\n",
      "TVSSRICHAK.NS   1888\n",
      "Accuracy: 0.5451306413301663\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.70       458\n",
      "           1       0.55      0.02      0.03       384\n",
      "\n",
      "    accuracy                           0.55       842\n",
      "   macro avg       0.55      0.50      0.37       842\n",
      "weighted avg       0.55      0.55      0.40       842\n",
      "\n",
      "Accuracy List Length : 1779\n",
      "TVTODAY.NS   1889\n",
      "Accuracy: 0.5406218655967904\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.70       538\n",
      "           1       0.57      0.01      0.02       459\n",
      "\n",
      "    accuracy                           0.54       997\n",
      "   macro avg       0.56      0.50      0.36       997\n",
      "weighted avg       0.55      0.54      0.39       997\n",
      "\n",
      "Accuracy List Length : 1780\n",
      "TVVISION.NS   1890\n",
      "Accuracy: 0.6243243243243243\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77       231\n",
      "           1       0.00      0.00      0.00       139\n",
      "\n",
      "    accuracy                           0.62       370\n",
      "   macro avg       0.31      0.50      0.38       370\n",
      "weighted avg       0.39      0.62      0.48       370\n",
      "\n",
      "Accuracy List Length : 1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBL.NS   1891\n",
      "Accuracy: 0.5194805194805194\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.82      0.63       389\n",
      "           1       0.54      0.21      0.30       381\n",
      "\n",
      "    accuracy                           0.52       770\n",
      "   macro avg       0.53      0.52      0.47       770\n",
      "weighted avg       0.53      0.52      0.47       770\n",
      "\n",
      "Accuracy List Length : 1782\n",
      "UCAL.NS   1892\n",
      "Accuracy: 0.6\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        16\n",
      "           1       0.56      0.64      0.60        14\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.61      0.60      0.60        30\n",
      "\n",
      "Accuracy List Length : 1783\n",
      "UCOBANK.NS   1893\n",
      "Accuracy: 0.5450049455984174\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.70       552\n",
      "           1       0.46      0.01      0.03       459\n",
      "\n",
      "    accuracy                           0.55      1011\n",
      "   macro avg       0.50      0.50      0.36      1011\n",
      "weighted avg       0.51      0.55      0.40      1011\n",
      "\n",
      "Accuracy List Length : 1784\n",
      "UDS.NS   1895\n",
      "Accuracy: 0.42857142857142855\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.90      0.60        10\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.43        21\n",
      "   macro avg       0.23      0.45      0.30        21\n",
      "weighted avg       0.21      0.43      0.29        21\n",
      "\n",
      "Accuracy List Length : 1785\n",
      "UFLEX.NS   1896\n",
      "Accuracy: 0.5255338904363974\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       568\n",
      "           1       0.40      0.01      0.02       509\n",
      "\n",
      "    accuracy                           0.53      1077\n",
      "   macro avg       0.46      0.50      0.35      1077\n",
      "weighted avg       0.47      0.53      0.37      1077\n",
      "\n",
      "Accuracy List Length : 1786\n",
      "UFO.NS   1897\n",
      "Accuracy: 0.5688073394495413\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.96      0.72       257\n",
      "           1       0.09      0.01      0.01       179\n",
      "\n",
      "    accuracy                           0.57       436\n",
      "   macro avg       0.34      0.48      0.37       436\n",
      "weighted avg       0.38      0.57      0.43       436\n",
      "\n",
      "Accuracy List Length : 1787\n",
      "UGARSUGAR.NS   1898\n",
      "Accuracy: 0.5763473053892215\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73       393\n",
      "           1       0.25      0.01      0.03       275\n",
      "\n",
      "    accuracy                           0.58       668\n",
      "   macro avg       0.42      0.49      0.38       668\n",
      "weighted avg       0.45      0.58      0.44       668\n",
      "\n",
      "Accuracy List Length : 1788\n",
      "UGROCAP.NS   1899\n",
      "Accuracy: 0.5390625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.95      0.67        62\n",
      "           1       0.77      0.15      0.25        66\n",
      "\n",
      "    accuracy                           0.54       128\n",
      "   macro avg       0.64      0.55      0.46       128\n",
      "weighted avg       0.65      0.54      0.45       128\n",
      "\n",
      "Accuracy List Length : 1789\n",
      "UJJIVANSFB.NS   1900\n",
      "Accuracy: 0.5523809523809524\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       115\n",
      "           1       0.56      0.05      0.10        95\n",
      "\n",
      "    accuracy                           0.55       210\n",
      "   macro avg       0.55      0.51      0.40       210\n",
      "weighted avg       0.55      0.55      0.43       210\n",
      "\n",
      "Accuracy List Length : 1790\n",
      "ULTRACEMCO.NS   1901\n",
      "Accuracy: 0.5340802987861811\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.03      0.06       502\n",
      "           1       0.53      0.98      0.69       569\n",
      "\n",
      "    accuracy                           0.53      1071\n",
      "   macro avg       0.54      0.50      0.38      1071\n",
      "weighted avg       0.54      0.53      0.40      1071\n",
      "\n",
      "Accuracy List Length : 1791\n",
      "UMAEXPORTS.NS   1902\n",
      "Accuracy: 0.49473684210526314\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.94      0.65        48\n",
      "           1       0.40      0.04      0.08        47\n",
      "\n",
      "    accuracy                           0.49        95\n",
      "   macro avg       0.45      0.49      0.36        95\n",
      "weighted avg       0.45      0.49      0.37        95\n",
      "\n",
      "Accuracy List Length : 1792\n",
      "UMANGDAIRY.NS   1903\n",
      "Accuracy: 0.5501222493887531\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71       227\n",
      "           1       0.33      0.01      0.02       182\n",
      "\n",
      "    accuracy                           0.55       409\n",
      "   macro avg       0.44      0.50      0.36       409\n",
      "weighted avg       0.46      0.55      0.40       409\n",
      "\n",
      "Accuracy List Length : 1793\n",
      "UMESLTD.NS   1904\n",
      "Accuracy: 0.6904761904761905\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82       556\n",
      "           1       0.35      0.02      0.05       242\n",
      "\n",
      "    accuracy                           0.69       798\n",
      "   macro avg       0.53      0.50      0.43       798\n",
      "weighted avg       0.59      0.69      0.58       798\n",
      "\n",
      "Accuracy List Length : 1794\n",
      "UNICHEMLAB.NS   1905\n",
      "Accuracy: 0.512987012987013\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.91      0.66       571\n",
      "           1       0.40      0.07      0.12       507\n",
      "\n",
      "    accuracy                           0.51      1078\n",
      "   macro avg       0.46      0.49      0.39      1078\n",
      "weighted avg       0.47      0.51      0.41      1078\n",
      "\n",
      "Accuracy List Length : 1795\n",
      "UNIDT.NS   1906\n",
      "Accuracy: 0.5321637426900585\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.88      0.67        94\n",
      "           1       0.42      0.10      0.17        77\n",
      "\n",
      "    accuracy                           0.53       171\n",
      "   macro avg       0.48      0.49      0.42       171\n",
      "weighted avg       0.49      0.53      0.45       171\n",
      "\n",
      "Accuracy List Length : 1796\n",
      "UNIENTER.NS   1908\n",
      "Accuracy: 0.5478180129990715\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       591\n",
      "           1       0.48      0.03      0.05       486\n",
      "\n",
      "    accuracy                           0.55      1077\n",
      "   macro avg       0.52      0.50      0.38      1077\n",
      "weighted avg       0.52      0.55      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1797\n",
      "UNIINFO.NS   1909\n",
      "Accuracy: 0.6047297297297297\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       178\n",
      "           1       0.57      0.03      0.06       118\n",
      "\n",
      "    accuracy                           0.60       296\n",
      "   macro avg       0.59      0.51      0.41       296\n",
      "weighted avg       0.59      0.60      0.48       296\n",
      "\n",
      "Accuracy List Length : 1798\n",
      "UNIONBANK.NS   1910\n",
      "Accuracy: 0.5103189493433395\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.94      0.66       545\n",
      "           1       0.49      0.06      0.10       521\n",
      "\n",
      "    accuracy                           0.51      1066\n",
      "   macro avg       0.50      0.50      0.38      1066\n",
      "weighted avg       0.50      0.51      0.39      1066\n",
      "\n",
      "Accuracy List Length : 1799\n",
      "UNIPARTS.NS   1911\n",
      "Accuracy: 0.45901639344262296\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.78      0.60        32\n",
      "           1       0.30      0.10      0.15        29\n",
      "\n",
      "    accuracy                           0.46        61\n",
      "   macro avg       0.40      0.44      0.38        61\n",
      "weighted avg       0.40      0.46      0.39        61\n",
      "\n",
      "Accuracy List Length : 1800\n",
      "UNITECH.NS   1913\n",
      "Accuracy: 0.5816326530612245\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73       623\n",
      "           1       0.56      0.04      0.08       455\n",
      "\n",
      "    accuracy                           0.58      1078\n",
      "   macro avg       0.57      0.51      0.40      1078\n",
      "weighted avg       0.57      0.58      0.45      1078\n",
      "\n",
      "Accuracy List Length : 1801\n",
      "UNITEDPOLY.NS   1914\n",
      "Accuracy: 0.7594202898550725\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       266\n",
      "           1       0.46      0.29      0.36        79\n",
      "\n",
      "    accuracy                           0.76       345\n",
      "   macro avg       0.64      0.59      0.60       345\n",
      "weighted avg       0.73      0.76      0.74       345\n",
      "\n",
      "Accuracy List Length : 1802\n",
      "UNITEDTEA.NS   1915\n",
      "Accuracy: 0.5636623748211731\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.72       393\n",
      "           1       0.57      0.01      0.03       306\n",
      "\n",
      "    accuracy                           0.56       699\n",
      "   macro avg       0.57      0.50      0.37       699\n",
      "weighted avg       0.57      0.56      0.42       699\n",
      "\n",
      "Accuracy List Length : 1803\n",
      "UNIVASTU.NS   1916\n",
      "Accuracy: 0.6334519572953736\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77       179\n",
      "           1       0.45      0.05      0.09       102\n",
      "\n",
      "    accuracy                           0.63       281\n",
      "   macro avg       0.55      0.51      0.43       281\n",
      "weighted avg       0.57      0.63      0.52       281\n",
      "\n",
      "Accuracy List Length : 1804\n",
      "UNIVCABLES.NS   1917\n",
      "Accuracy: 0.5482374768089053\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       588\n",
      "           1       0.67      0.01      0.02       490\n",
      "\n",
      "    accuracy                           0.55      1078\n",
      "   macro avg       0.61      0.50      0.37      1078\n",
      "weighted avg       0.60      0.55      0.40      1078\n",
      "\n",
      "Accuracy List Length : 1805\n",
      "UNIVPHOTO.NS   1918\n",
      "Accuracy: 0.5373134328358209\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       112\n",
      "           1       0.17      0.01      0.02        89\n",
      "\n",
      "    accuracy                           0.54       201\n",
      "   macro avg       0.36      0.48      0.36       201\n",
      "weighted avg       0.38      0.54      0.40       201\n",
      "\n",
      "Accuracy List Length : 1806\n",
      "UNOMINDA.NS   1919\n",
      "Accuracy: 0.5207591933570581\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.99      0.68       436\n",
      "           1       0.62      0.02      0.04       407\n",
      "\n",
      "    accuracy                           0.52       843\n",
      "   macro avg       0.57      0.50      0.36       843\n",
      "weighted avg       0.57      0.52      0.37       843\n",
      "\n",
      "Accuracy List Length : 1807\n",
      "UPL.NS   1920\n",
      "Accuracy: 0.4897959183673469\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48       507\n",
      "           1       0.52      0.47      0.50       571\n",
      "\n",
      "    accuracy                           0.49      1078\n",
      "   macro avg       0.49      0.49      0.49      1078\n",
      "weighted avg       0.49      0.49      0.49      1078\n",
      "\n",
      "Accuracy List Length : 1808\n",
      "URAVI.NS   1921\n",
      "Accuracy: 0.7328767123287672\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84       215\n",
      "           1       0.47      0.09      0.15        77\n",
      "\n",
      "    accuracy                           0.73       292\n",
      "   macro avg       0.61      0.53      0.50       292\n",
      "weighted avg       0.67      0.73      0.66       292\n",
      "\n",
      "Accuracy List Length : 1809\n",
      "URJA.NS   1922\n",
      "Accuracy: 0.6075581395348837\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75       209\n",
      "           1       0.50      0.02      0.04       135\n",
      "\n",
      "    accuracy                           0.61       344\n",
      "   macro avg       0.55      0.50      0.40       344\n",
      "weighted avg       0.57      0.61      0.47       344\n",
      "\n",
      "Accuracy List Length : 1810\n",
      "USHAMART.NS   1923\n",
      "Accuracy: 0.5344202898550725\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.69       595\n",
      "           1       0.38      0.02      0.03       509\n",
      "\n",
      "    accuracy                           0.53      1104\n",
      "   macro avg       0.46      0.50      0.36      1104\n",
      "weighted avg       0.47      0.53      0.39      1104\n",
      "\n",
      "Accuracy List Length : 1811\n",
      "USK.NS   1924\n",
      "Accuracy: 0.5869565217391305\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        27\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.59        46\n",
      "   macro avg       0.29      0.50      0.37        46\n",
      "weighted avg       0.34      0.59      0.43        46\n",
      "\n",
      "Accuracy List Length : 1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTIAMC.NS   1925\n",
      "Accuracy: 0.4437869822485207\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.85      0.59        81\n",
      "           1       0.33      0.07      0.11        88\n",
      "\n",
      "    accuracy                           0.44       169\n",
      "   macro avg       0.40      0.46      0.35       169\n",
      "weighted avg       0.39      0.44      0.34       169\n",
      "\n",
      "Accuracy List Length : 1813\n",
      "UTKARSHBNK.NS   1926\n",
      "Accuracy: 0.45161290322580644\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60        13\n",
      "           1       1.00      0.06      0.11        18\n",
      "\n",
      "    accuracy                           0.45        31\n",
      "   macro avg       0.72      0.53      0.35        31\n",
      "weighted avg       0.76      0.45      0.31        31\n",
      "\n",
      "Accuracy List Length : 1814\n",
      "UTTAMSUGAR.NS   1927\n",
      "Accuracy: 0.5497737556561086\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71       490\n",
      "           1       0.36      0.01      0.02       394\n",
      "\n",
      "    accuracy                           0.55       884\n",
      "   macro avg       0.46      0.50      0.37       884\n",
      "weighted avg       0.47      0.55      0.40       884\n",
      "\n",
      "Accuracy List Length : 1815\n",
      "V2RETAIL.NS   1929\n",
      "Accuracy: 0.5565006075334143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71       452\n",
      "           1       0.64      0.04      0.07       371\n",
      "\n",
      "    accuracy                           0.56       823\n",
      "   macro avg       0.60      0.51      0.39       823\n",
      "weighted avg       0.59      0.56      0.42       823\n",
      "\n",
      "Accuracy List Length : 1816\n",
      "VADILALIND.NS   1930\n",
      "Accuracy: 0.5318471337579618\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.69       337\n",
      "           1       0.40      0.02      0.04       291\n",
      "\n",
      "    accuracy                           0.53       628\n",
      "   macro avg       0.47      0.50      0.36       628\n",
      "weighted avg       0.47      0.53      0.39       628\n",
      "\n",
      "Accuracy List Length : 1817\n",
      "VAIBHAVGBL.NS   1931\n",
      "Accuracy: 0.5557809330628803\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       544\n",
      "           1       0.70      0.02      0.03       442\n",
      "\n",
      "    accuracy                           0.56       986\n",
      "   macro avg       0.63      0.51      0.37       986\n",
      "weighted avg       0.62      0.56      0.41       986\n",
      "\n",
      "Accuracy List Length : 1818\n",
      "VAISHALI.NS   1932\n",
      "Accuracy: 0.6160990712074303\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76       202\n",
      "           1       0.20      0.01      0.02       121\n",
      "\n",
      "    accuracy                           0.62       323\n",
      "   macro avg       0.41      0.49      0.39       323\n",
      "weighted avg       0.46      0.62      0.48       323\n",
      "\n",
      "Accuracy List Length : 1819\n",
      "VAKRANGEE.NS   1933\n",
      "Accuracy: 0.5322033898305085\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       464\n",
      "           1       0.63      0.04      0.08       421\n",
      "\n",
      "    accuracy                           0.53       885\n",
      "   macro avg       0.58      0.51      0.38       885\n",
      "weighted avg       0.58      0.53      0.40       885\n",
      "\n",
      "Accuracy List Length : 1820\n",
      "VALIANTLAB.NS   1934\n",
      "Accuracy: 0.42857142857142855\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         9\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.43        21\n",
      "   macro avg       0.21      0.50      0.30        21\n",
      "weighted avg       0.18      0.43      0.26        21\n",
      "\n",
      "Accuracy List Length : 1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIANTORG.NS   1935\n",
      "Accuracy: 0.6235294117647059\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.99      0.76       104\n",
      "           1       0.75      0.05      0.09        66\n",
      "\n",
      "    accuracy                           0.62       170\n",
      "   macro avg       0.69      0.52      0.42       170\n",
      "weighted avg       0.67      0.62      0.50       170\n",
      "\n",
      "Accuracy List Length : 1822\n",
      "VARDHACRLC.NS   1936\n",
      "Accuracy: 0.5820158102766798\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74       590\n",
      "           1       0.33      0.00      0.00       422\n",
      "\n",
      "    accuracy                           0.58      1012\n",
      "   macro avg       0.46      0.50      0.37      1012\n",
      "weighted avg       0.48      0.58      0.43      1012\n",
      "\n",
      "Accuracy List Length : 1823\n",
      "VARDMNPOLY.NS   1937\n",
      "Accuracy: 0.5238095238095238\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       565\n",
      "           1       0.33      0.01      0.02       506\n",
      "\n",
      "    accuracy                           0.52      1071\n",
      "   macro avg       0.43      0.50      0.35      1071\n",
      "weighted avg       0.43      0.52      0.37      1071\n",
      "\n",
      "Accuracy List Length : 1824\n",
      "VARROC.NS   1938\n",
      "Accuracy: 0.5428571428571428\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.91      0.68       150\n",
      "           1       0.54      0.12      0.19       130\n",
      "\n",
      "    accuracy                           0.54       280\n",
      "   macro avg       0.54      0.51      0.44       280\n",
      "weighted avg       0.54      0.54      0.45       280\n",
      "\n",
      "Accuracy List Length : 1825\n",
      "VASCONEQ.NS   1939\n",
      "Accuracy: 0.5654676258992806\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72       398\n",
      "           1       0.27      0.01      0.02       297\n",
      "\n",
      "    accuracy                           0.57       695\n",
      "   macro avg       0.42      0.50      0.37       695\n",
      "weighted avg       0.44      0.57      0.42       695\n",
      "\n",
      "Accuracy List Length : 1826\n",
      "VASWANI.NS   1940\n",
      "Accuracy: 0.5639344262295082\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       347\n",
      "           1       0.40      0.02      0.04       263\n",
      "\n",
      "    accuracy                           0.56       610\n",
      "   macro avg       0.48      0.50      0.38       610\n",
      "weighted avg       0.50      0.56      0.43       610\n",
      "\n",
      "Accuracy List Length : 1827\n",
      "VBL.NS   1941\n",
      "Accuracy: 0.5179063360881543\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.09      0.15       176\n",
      "           1       0.52      0.93      0.66       187\n",
      "\n",
      "    accuracy                           0.52       363\n",
      "   macro avg       0.52      0.51      0.41       363\n",
      "weighted avg       0.52      0.52      0.41       363\n",
      "\n",
      "Accuracy List Length : 1828\n",
      "VCL.NS   1942\n",
      "Accuracy: 0.7340425531914894\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.84        68\n",
      "           1       0.67      0.08      0.14        26\n",
      "\n",
      "    accuracy                           0.73        94\n",
      "   macro avg       0.70      0.53      0.49        94\n",
      "weighted avg       0.72      0.73      0.65        94\n",
      "\n",
      "Accuracy List Length : 1829\n",
      "VEDL.NS   1943\n",
      "Accuracy: 0.5419901199717714\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.68       765\n",
      "           1       0.51      0.10      0.17       652\n",
      "\n",
      "    accuracy                           0.54      1417\n",
      "   macro avg       0.53      0.51      0.43      1417\n",
      "weighted avg       0.53      0.54      0.45      1417\n",
      "\n",
      "Accuracy List Length : 1830\n",
      "VEEDOL.NS   1944\n",
      "Accuracy: 0.5236406619385343\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.99      0.68       441\n",
      "           1       0.57      0.02      0.04       405\n",
      "\n",
      "    accuracy                           0.52       846\n",
      "   macro avg       0.55      0.50      0.36       846\n",
      "weighted avg       0.55      0.52      0.37       846\n",
      "\n",
      "Accuracy List Length : 1831\n",
      "VENKEYS.NS   1945\n",
      "Accuracy: 0.5264623955431755\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       568\n",
      "           1       0.44      0.01      0.02       509\n",
      "\n",
      "    accuracy                           0.53      1077\n",
      "   macro avg       0.49      0.50      0.35      1077\n",
      "weighted avg       0.49      0.53      0.37      1077\n",
      "\n",
      "Accuracy List Length : 1832\n",
      "VENUSPIPES.NS   1946\n",
      "Accuracy: 0.5955056179775281\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.39      0.44        36\n",
      "           1       0.64      0.74      0.68        53\n",
      "\n",
      "    accuracy                           0.60        89\n",
      "   macro avg       0.57      0.56      0.56        89\n",
      "weighted avg       0.58      0.60      0.58        89\n",
      "\n",
      "Accuracy List Length : 1833\n",
      "VENUSREM.NS   1947\n",
      "Accuracy: 0.8916372202591284\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       755\n",
      "           1       0.54      0.14      0.22        94\n",
      "\n",
      "    accuracy                           0.89       849\n",
      "   macro avg       0.72      0.56      0.58       849\n",
      "weighted avg       0.86      0.89      0.86       849\n",
      "\n",
      "Accuracy List Length : 1834\n",
      "VERANDA.NS   1948\n",
      "Accuracy: 0.5684210526315789\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71        55\n",
      "           1       0.43      0.07      0.13        40\n",
      "\n",
      "    accuracy                           0.57        95\n",
      "   macro avg       0.50      0.50      0.42        95\n",
      "weighted avg       0.52      0.57      0.47        95\n",
      "\n",
      "Accuracy List Length : 1835\n",
      "VERTOZ.NS   1949\n",
      "Accuracy: 0.5691318327974276\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       176\n",
      "           1       0.67      0.01      0.03       135\n",
      "\n",
      "    accuracy                           0.57       311\n",
      "   macro avg       0.62      0.50      0.38       311\n",
      "weighted avg       0.61      0.57      0.42       311\n",
      "\n",
      "Accuracy List Length : 1836\n",
      "VESUVIUS.NS   1950\n",
      "Accuracy: 0.5162488393686165\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.97      0.68       564\n",
      "           1       0.32      0.01      0.03       513\n",
      "\n",
      "    accuracy                           0.52      1077\n",
      "   macro avg       0.42      0.49      0.35      1077\n",
      "weighted avg       0.42      0.52      0.37      1077\n",
      "\n",
      "Accuracy List Length : 1837\n",
      "VETO.NS   1951\n",
      "Accuracy: 0.5547945205479452\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       242\n",
      "           1       0.57      0.02      0.04       196\n",
      "\n",
      "    accuracy                           0.55       438\n",
      "   macro avg       0.56      0.50      0.37       438\n",
      "weighted avg       0.56      0.55      0.41       438\n",
      "\n",
      "Accuracy List Length : 1838\n",
      "VGUARD.NS   1952\n",
      "Accuracy: 0.516497461928934\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.83      0.64       413\n",
      "           1       0.48      0.17      0.25       375\n",
      "\n",
      "    accuracy                           0.52       788\n",
      "   macro avg       0.50      0.50      0.45       788\n",
      "weighted avg       0.50      0.52      0.46       788\n",
      "\n",
      "Accuracy List Length : 1839\n",
      "VHL.NS   1953\n",
      "Accuracy: 0.5543175487465181\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.71       599\n",
      "           1       0.25      0.00      0.00       478\n",
      "\n",
      "    accuracy                           0.55      1077\n",
      "   macro avg       0.40      0.50      0.36      1077\n",
      "weighted avg       0.42      0.55      0.40      1077\n",
      "\n",
      "Accuracy List Length : 1840\n",
      "VHLTD.NS   1954\n",
      "Accuracy: 0.6274509803921569\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.77       517\n",
      "           1       0.39      0.03      0.06       299\n",
      "\n",
      "    accuracy                           0.63       816\n",
      "   macro avg       0.51      0.50      0.41       816\n",
      "weighted avg       0.55      0.63      0.51       816\n",
      "\n",
      "Accuracy List Length : 1841\n",
      "VIDHIING.NS   1955\n",
      "Accuracy: 0.553030303030303\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.88      0.69       227\n",
      "           1       0.41      0.11      0.18       169\n",
      "\n",
      "    accuracy                           0.55       396\n",
      "   macro avg       0.49      0.50      0.43       396\n",
      "weighted avg       0.50      0.55      0.47       396\n",
      "\n",
      "Accuracy List Length : 1842\n",
      "VIJAYA.NS   1956\n",
      "Accuracy: 0.5121951219512195\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.67      0.58        61\n",
      "           1       0.52      0.35      0.42        62\n",
      "\n",
      "    accuracy                           0.51       123\n",
      "   macro avg       0.51      0.51      0.50       123\n",
      "weighted avg       0.52      0.51      0.50       123\n",
      "\n",
      "Accuracy List Length : 1843\n",
      "VIJIFIN.NS   1957\n",
      "Accuracy: 0.6728232189973615\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80       259\n",
      "           1       0.30      0.03      0.05       120\n",
      "\n",
      "    accuracy                           0.67       379\n",
      "   macro avg       0.49      0.50      0.42       379\n",
      "weighted avg       0.56      0.67      0.56       379\n",
      "\n",
      "Accuracy List Length : 1844\n",
      "VIKASECO.NS   1958\n",
      "Accuracy: 0.5927152317880795\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.98      0.74       360\n",
      "           1       0.43      0.02      0.05       244\n",
      "\n",
      "    accuracy                           0.59       604\n",
      "   macro avg       0.51      0.50      0.39       604\n",
      "weighted avg       0.53      0.59      0.46       604\n",
      "\n",
      "Accuracy List Length : 1845\n",
      "VIKASLIFE.NS   1959\n",
      "Accuracy: 0.7041666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81       154\n",
      "           1       0.80      0.23      0.36        86\n",
      "\n",
      "    accuracy                           0.70       240\n",
      "   macro avg       0.75      0.60      0.58       240\n",
      "weighted avg       0.73      0.70      0.65       240\n",
      "\n",
      "Accuracy List Length : 1846\n",
      "VIMTALABS.NS   1960\n",
      "Accuracy: 0.5350389321468298\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.70       480\n",
      "           1       0.57      0.01      0.02       419\n",
      "\n",
      "    accuracy                           0.54       899\n",
      "   macro avg       0.55      0.50      0.36       899\n",
      "weighted avg       0.55      0.54      0.38       899\n",
      "\n",
      "Accuracy List Length : 1847\n",
      "VINATIORGA.NS   1961\n",
      "Accuracy: 0.5041551246537396\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.99      0.67       364\n",
      "           1       0.50      0.01      0.02       358\n",
      "\n",
      "    accuracy                           0.50       722\n",
      "   macro avg       0.50      0.50      0.34       722\n",
      "weighted avg       0.50      0.50      0.35       722\n",
      "\n",
      "Accuracy List Length : 1848\n",
      "VINDHYATEL.NS   1963\n",
      "Accuracy: 0.5589600742804085\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       605\n",
      "           1       0.41      0.01      0.03       472\n",
      "\n",
      "    accuracy                           0.56      1077\n",
      "   macro avg       0.49      0.50      0.37      1077\n",
      "weighted avg       0.50      0.56      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1849\n",
      "VINEETLAB.NS   1964\n",
      "Accuracy: 0.5955882352941176\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74        79\n",
      "           1       0.75      0.05      0.10        57\n",
      "\n",
      "    accuracy                           0.60       136\n",
      "   macro avg       0.67      0.52      0.42       136\n",
      "weighted avg       0.66      0.60      0.47       136\n",
      "\n",
      "Accuracy List Length : 1850\n",
      "VINNY.NS   1965\n",
      "Accuracy: 0.7509433962264151\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86       201\n",
      "           1       0.33      0.03      0.06        64\n",
      "\n",
      "    accuracy                           0.75       265\n",
      "   macro avg       0.55      0.51      0.46       265\n",
      "weighted avg       0.66      0.75      0.66       265\n",
      "\n",
      "Accuracy List Length : 1851\n",
      "VINYLINDIA.NS   1966\n",
      "Accuracy: 0.5889724310776943\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       467\n",
      "           1       0.67      0.02      0.04       331\n",
      "\n",
      "    accuracy                           0.59       798\n",
      "   macro avg       0.63      0.51      0.39       798\n",
      "weighted avg       0.62      0.59      0.45       798\n",
      "\n",
      "Accuracy List Length : 1852\n",
      "VIPCLOTHNG.NS   1967\n",
      "Accuracy: 0.5342298288508558\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.69       441\n",
      "           1       0.33      0.01      0.02       377\n",
      "\n",
      "    accuracy                           0.53       818\n",
      "   macro avg       0.44      0.50      0.36       818\n",
      "weighted avg       0.44      0.53      0.38       818\n",
      "\n",
      "Accuracy List Length : 1853\n",
      "VIPIND.NS   1968\n",
      "Accuracy: 0.564531104921077\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72       607\n",
      "           1       0.57      0.01      0.02       470\n",
      "\n",
      "    accuracy                           0.56      1077\n",
      "   macro avg       0.57      0.50      0.37      1077\n",
      "weighted avg       0.57      0.56      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1854\n",
      "VIPULLTD.NS   1969\n",
      "Accuracy: 0.5942857142857143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74       415\n",
      "           1       0.57      0.01      0.03       285\n",
      "\n",
      "    accuracy                           0.59       700\n",
      "   macro avg       0.58      0.50      0.39       700\n",
      "weighted avg       0.59      0.59      0.45       700\n",
      "\n",
      "Accuracy List Length : 1855\n",
      "VIRINCHI.NS   1970\n",
      "Accuracy: 0.5476190476190477\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71        23\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.55        42\n",
      "   macro avg       0.27      0.50      0.35        42\n",
      "weighted avg       0.30      0.55      0.39        42\n",
      "\n",
      "Accuracy List Length : 1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\TANUJ\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISAKAIND.NS   1971\n",
      "Accuracy: 0.5394614670380687\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.70       578\n",
      "           1       0.67      0.01      0.02       499\n",
      "\n",
      "    accuracy                           0.54      1077\n",
      "   macro avg       0.60      0.50      0.36      1077\n",
      "weighted avg       0.60      0.54      0.39      1077\n",
      "\n",
      "Accuracy List Length : 1857\n",
      "VISHNU.NS   1972\n",
      "Accuracy: 0.5303370786516854\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       233\n",
      "           1       0.62      0.04      0.07       212\n",
      "\n",
      "    accuracy                           0.53       445\n",
      "   macro avg       0.57      0.51      0.38       445\n",
      "weighted avg       0.57      0.53      0.39       445\n",
      "\n",
      "Accuracy List Length : 1858\n",
      "VISHWARAJ.NS   1973\n",
      "Accuracy: 0.5321100917431193\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.94      0.69       122\n",
      "           1       0.12      0.01      0.02        96\n",
      "\n",
      "    accuracy                           0.53       218\n",
      "   macro avg       0.34      0.48      0.36       218\n",
      "weighted avg       0.36      0.53      0.40       218\n",
      "\n",
      "Accuracy List Length : 1859\n",
      "VIVIDHA.NS   1974\n",
      "Accuracy: 0.6904315196998124\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81       371\n",
      "           1       0.43      0.06      0.10       162\n",
      "\n",
      "    accuracy                           0.69       533\n",
      "   macro avg       0.56      0.51      0.46       533\n",
      "weighted avg       0.62      0.69      0.60       533\n",
      "\n",
      "Accuracy List Length : 1860\n",
      "VLEGOV.NS   1975\n",
      "Accuracy: 0.5185185185185185\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.57      0.38         7\n",
      "           1       0.77      0.50      0.61        20\n",
      "\n",
      "    accuracy                           0.52        27\n",
      "   macro avg       0.53      0.54      0.49        27\n",
      "weighted avg       0.64      0.52      0.55        27\n",
      "\n",
      "Accuracy List Length : 1861\n",
      "VLSFINANCE.NS   1976\n",
      "Accuracy: 0.5705009276437848\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.99      0.72       617\n",
      "           1       0.42      0.01      0.02       461\n",
      "\n",
      "    accuracy                           0.57      1078\n",
      "   macro avg       0.49      0.50      0.37      1078\n",
      "weighted avg       0.51      0.57      0.42      1078\n",
      "\n",
      "Accuracy List Length : 1862\n",
      "VMART.NS   1977\n",
      "Accuracy: 0.5211009174311927\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.84      0.65       288\n",
      "           1       0.48      0.16      0.24       257\n",
      "\n",
      "    accuracy                           0.52       545\n",
      "   macro avg       0.50      0.50      0.44       545\n",
      "weighted avg       0.50      0.52      0.46       545\n",
      "\n",
      "Accuracy List Length : 1863\n",
      "VOLTAMP.NS   1979\n",
      "Accuracy: 0.5342624854819977\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       458\n",
      "           1       0.60      0.01      0.03       403\n",
      "\n",
      "    accuracy                           0.53       861\n",
      "   macro avg       0.57      0.50      0.36       861\n",
      "weighted avg       0.56      0.53      0.38       861\n",
      "\n",
      "Accuracy List Length : 1864\n",
      "VOLTAS.NS   1980\n",
      "Accuracy: 0.5102040816326531\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.10      0.16       535\n",
      "           1       0.51      0.92      0.65       543\n",
      "\n",
      "    accuracy                           0.51      1078\n",
      "   macro avg       0.52      0.51      0.41      1078\n",
      "weighted avg       0.52      0.51      0.41      1078\n",
      "\n",
      "Accuracy List Length : 1865\n",
      "VPRPL.NS   1981\n",
      "Accuracy: 0.6\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.25      0.38        12\n",
      "           1       0.57      0.92      0.71        13\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.66      0.59      0.54        25\n",
      "weighted avg       0.66      0.60      0.55        25\n",
      "\n",
      "Accuracy List Length : 1866\n",
      "VRLLOG.NS   1983\n",
      "Accuracy: 0.547945205479452\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       240\n",
      "           1       0.50      0.01      0.02       198\n",
      "\n",
      "    accuracy                           0.55       438\n",
      "   macro avg       0.52      0.50      0.36       438\n",
      "weighted avg       0.53      0.55      0.40       438\n",
      "\n",
      "Accuracy List Length : 1867\n",
      "VSSL.NS   1984\n",
      "Accuracy: 0.5025728987993139\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.67       294\n",
      "           1       0.44      0.01      0.03       289\n",
      "\n",
      "    accuracy                           0.50       583\n",
      "   macro avg       0.47      0.50      0.35       583\n",
      "weighted avg       0.47      0.50      0.35       583\n",
      "\n",
      "Accuracy List Length : 1868\n",
      "VSTIND.NS   1985\n",
      "Accuracy: 0.5092764378478665\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.96      0.67       561\n",
      "           1       0.29      0.02      0.03       517\n",
      "\n",
      "    accuracy                           0.51      1078\n",
      "   macro avg       0.40      0.49      0.35      1078\n",
      "weighted avg       0.41      0.51      0.36      1078\n",
      "\n",
      "Accuracy List Length : 1869\n",
      "VSTL.NS   1986\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "Accuracy List Length : 1870\n",
      "VSTTILLERS.NS   1987\n",
      "Accuracy: 0.5151515151515151\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.95      0.68       334\n",
      "           1       0.24      0.02      0.03       293\n",
      "\n",
      "    accuracy                           0.52       627\n",
      "   macro avg       0.38      0.48      0.35       627\n",
      "weighted avg       0.39      0.52      0.38       627\n",
      "\n",
      "Accuracy List Length : 1871\n",
      "VTL.NS   1988\n",
      "Accuracy: 0.47075208913649025\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.04      0.07       558\n",
      "           1       0.48      0.94      0.63       519\n",
      "\n",
      "    accuracy                           0.47      1077\n",
      "   macro avg       0.43      0.49      0.35      1077\n",
      "weighted avg       0.43      0.47      0.34      1077\n",
      "\n",
      "Accuracy List Length : 1872\n",
      "WABAG.NS   1990\n",
      "Accuracy: 0.5173978819969742\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.97      0.68       347\n",
      "           1       0.31      0.01      0.02       314\n",
      "\n",
      "    accuracy                           0.52       661\n",
      "   macro avg       0.41      0.49      0.35       661\n",
      "weighted avg       0.42      0.52      0.37       661\n",
      "\n",
      "Accuracy List Length : 1873\n",
      "WALCHANNAG.NS   1991\n",
      "Accuracy: 0.552460538532962\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       587\n",
      "           1       0.68      0.03      0.06       490\n",
      "\n",
      "    accuracy                           0.55      1077\n",
      "   macro avg       0.62      0.51      0.38      1077\n",
      "weighted avg       0.61      0.55      0.41      1077\n",
      "\n",
      "Accuracy List Length : 1874\n",
      "WANBURY.NS   1992\n",
      "Accuracy: 0.54739336492891\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       466\n",
      "           1       0.44      0.04      0.08       378\n",
      "\n",
      "    accuracy                           0.55       844\n",
      "   macro avg       0.50      0.50      0.39       844\n",
      "weighted avg       0.50      0.55      0.42       844\n",
      "\n",
      "Accuracy List Length : 1875\n",
      "WEALTH.NS   1994\n",
      "Accuracy: 0.7296511627906976\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.99      0.84       249\n",
      "           1       0.67      0.04      0.08        95\n",
      "\n",
      "    accuracy                           0.73       344\n",
      "   macro avg       0.70      0.52      0.46       344\n",
      "weighted avg       0.71      0.73      0.63       344\n",
      "\n",
      "Accuracy List Length : 1876\n",
      "WEBELSOLAR.NS   1995\n",
      "Accuracy: 0.5385542168674698\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.69       446\n",
      "           1       0.52      0.03      0.05       384\n",
      "\n",
      "    accuracy                           0.54       830\n",
      "   macro avg       0.53      0.50      0.37       830\n",
      "weighted avg       0.53      0.54      0.40       830\n",
      "\n",
      "Accuracy List Length : 1877\n",
      "WEIZMANIND.NS   1996\n",
      "Accuracy: 0.5793871866295265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73       612\n",
      "           1       0.70      0.05      0.08       465\n",
      "\n",
      "    accuracy                           0.58      1077\n",
      "   macro avg       0.64      0.52      0.41      1077\n",
      "weighted avg       0.63      0.58      0.45      1077\n",
      "\n",
      "Accuracy List Length : 1878\n",
      "WEL.NS   1997\n",
      "Accuracy: 0.6222222222222222\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.99      0.76       139\n",
      "           1       0.60      0.03      0.07        86\n",
      "\n",
      "    accuracy                           0.62       225\n",
      "   macro avg       0.61      0.51      0.41       225\n",
      "weighted avg       0.61      0.62      0.50       225\n",
      "\n",
      "Accuracy List Length : 1879\n",
      "WELCORP.NS   1998\n",
      "Accuracy: 0.5714285714285714\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.72       669\n",
      "           1       0.56      0.06      0.11       514\n",
      "\n",
      "    accuracy                           0.57      1183\n",
      "   macro avg       0.57      0.51      0.41      1183\n",
      "weighted avg       0.57      0.57      0.45      1183\n",
      "\n",
      "Accuracy List Length : 1880\n",
      "WELENT.NS   1999\n",
      "Accuracy: 0.49842931937172774\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.97      0.66       478\n",
      "           1       0.46      0.03      0.05       477\n",
      "\n",
      "    accuracy                           0.50       955\n",
      "   macro avg       0.48      0.50      0.36       955\n",
      "weighted avg       0.48      0.50      0.36       955\n",
      "\n",
      "Accuracy List Length : 1881\n",
      "WELINV.NS   2000\n",
      "Accuracy: 0.7051792828685259\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.99      0.83       710\n",
      "           1       0.40      0.01      0.03       294\n",
      "\n",
      "    accuracy                           0.71      1004\n",
      "   macro avg       0.55      0.50      0.43      1004\n",
      "weighted avg       0.62      0.71      0.59      1004\n",
      "\n",
      "Accuracy List Length : 1882\n",
      "WELSPUNLIV.NS   2001\n",
      "Accuracy: 0.5343968095712861\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       536\n",
      "           1       0.50      0.02      0.03       467\n",
      "\n",
      "    accuracy                           0.53      1003\n",
      "   macro avg       0.52      0.50      0.36      1003\n",
      "weighted avg       0.52      0.53      0.39      1003\n",
      "\n",
      "Accuracy List Length : 1883\n",
      "WENDT.NS   2002\n",
      "Accuracy: 0.5080645161290323\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.94      0.66       447\n",
      "           1       0.44      0.05      0.09       421\n",
      "\n",
      "    accuracy                           0.51       868\n",
      "   macro avg       0.48      0.49      0.38       868\n",
      "weighted avg       0.48      0.51      0.39       868\n",
      "\n",
      "Accuracy List Length : 1884\n",
      "WESTLIFE.NS   2003\n",
      "Accuracy: 0.4911504424778761\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.39      0.43       110\n",
      "           1       0.50      0.59      0.54       116\n",
      "\n",
      "    accuracy                           0.49       226\n",
      "   macro avg       0.49      0.49      0.48       226\n",
      "weighted avg       0.49      0.49      0.49       226\n",
      "\n",
      "Accuracy List Length : 1885\n",
      "WEWIN.NS   2004\n",
      "Accuracy: 0.7107142857142857\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83       203\n",
      "           1       0.30      0.04      0.07        77\n",
      "\n",
      "    accuracy                           0.71       280\n",
      "   macro avg       0.51      0.50      0.45       280\n",
      "weighted avg       0.61      0.71      0.62       280\n",
      "\n",
      "Accuracy List Length : 1886\n",
      "WHEELS.NS   2005\n",
      "Accuracy: 0.5283194057567316\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       571\n",
      "           1       0.33      0.00      0.01       506\n",
      "\n",
      "    accuracy                           0.53      1077\n",
      "   macro avg       0.43      0.50      0.35      1077\n",
      "weighted avg       0.44      0.53      0.37      1077\n",
      "\n",
      "Accuracy List Length : 1887\n",
      "WHIRLPOOL.NS   2006\n",
      "Accuracy: 0.6902985074626866\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81       750\n",
      "           1       0.37      0.04      0.08       322\n",
      "\n",
      "    accuracy                           0.69      1072\n",
      "   macro avg       0.54      0.51      0.45      1072\n",
      "weighted avg       0.60      0.69      0.59      1072\n",
      "\n",
      "Accuracy List Length : 1888\n",
      "WILLAMAGOR.NS   2007\n",
      "Accuracy: 0.5797773654916512\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73       626\n",
      "           1       0.00      0.00      0.00       452\n",
      "\n",
      "    accuracy                           0.58      1078\n",
      "   macro avg       0.29      0.50      0.37      1078\n",
      "weighted avg       0.34      0.58      0.43      1078\n",
      "\n",
      "Accuracy List Length : 1889\n",
      "WINDLAS.NS   2008\n",
      "Accuracy: 0.48031496062992124\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.21      0.30        67\n",
      "           1       0.47      0.78      0.59        60\n",
      "\n",
      "    accuracy                           0.48       127\n",
      "   macro avg       0.49      0.50      0.44       127\n",
      "weighted avg       0.50      0.48      0.43       127\n",
      "\n",
      "Accuracy List Length : 1890\n",
      "WINDMACHIN.NS   2009\n",
      "Accuracy: 0.5751633986928104\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73       618\n",
      "           1       0.44      0.02      0.03       453\n",
      "\n",
      "    accuracy                           0.58      1071\n",
      "   macro avg       0.51      0.50      0.38      1071\n",
      "weighted avg       0.52      0.58      0.43      1071\n",
      "\n",
      "Accuracy List Length : 1891\n",
      "WINSOME.NS   2010\n",
      "Accuracy: 0.6920222634508348\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.82       747\n",
      "           1       0.44      0.01      0.02       331\n",
      "\n",
      "    accuracy                           0.69      1078\n",
      "   macro avg       0.57      0.50      0.42      1078\n",
      "weighted avg       0.62      0.69      0.57      1078\n",
      "\n",
      "Accuracy List Length : 1892\n",
      "WIPL.NS   2011\n",
      "Accuracy: 0.5571847507331378\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.70       193\n",
      "           1       0.43      0.07      0.12       148\n",
      "\n",
      "    accuracy                           0.56       341\n",
      "   macro avg       0.50      0.50      0.41       341\n",
      "weighted avg       0.51      0.56      0.45       341\n",
      "\n",
      "Accuracy List Length : 1893\n",
      "WIPRO.NS   2012\n",
      "Accuracy: 0.48976711362032466\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.91      0.63       688\n",
      "           1       0.52      0.09      0.16       729\n",
      "\n",
      "    accuracy                           0.49      1417\n",
      "   macro avg       0.50      0.50      0.40      1417\n",
      "weighted avg       0.51      0.49      0.39      1417\n",
      "\n",
      "Accuracy List Length : 1894\n",
      "WOCKPHARMA.NS   2013\n",
      "Accuracy: 0.5296846011131725\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       566\n",
      "           1       0.54      0.07      0.12       512\n",
      "\n",
      "    accuracy                           0.53      1078\n",
      "   macro avg       0.53      0.51      0.40      1078\n",
      "weighted avg       0.53      0.53      0.42      1078\n",
      "\n",
      "Accuracy List Length : 1895\n",
      "WONDERLA.NS   2014\n",
      "Accuracy: 0.5670103092783505\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.98      0.71       265\n",
      "           1       0.75      0.07      0.12       220\n",
      "\n",
      "    accuracy                           0.57       485\n",
      "   macro avg       0.65      0.52      0.42       485\n",
      "weighted avg       0.65      0.57      0.45       485\n",
      "\n",
      "Accuracy List Length : 1896\n",
      "WORTH.NS   2015\n",
      "Accuracy: 0.5628930817610063\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       180\n",
      "           1       0.44      0.03      0.05       138\n",
      "\n",
      "    accuracy                           0.56       318\n",
      "   macro avg       0.51      0.50      0.39       318\n",
      "weighted avg       0.51      0.56      0.43       318\n",
      "\n",
      "Accuracy List Length : 1897\n",
      "WSI.NS   2016\n",
      "Accuracy: 0.6532356532356532\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79       537\n",
      "           1       0.42      0.02      0.03       282\n",
      "\n",
      "    accuracy                           0.65       819\n",
      "   macro avg       0.54      0.50      0.41       819\n",
      "weighted avg       0.57      0.65      0.53       819\n",
      "\n",
      "Accuracy List Length : 1898\n",
      "WSTCSTPAPR.NS   2017\n",
      "Accuracy: 0.5102040816326531\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67       555\n",
      "           1       0.38      0.02      0.03       523\n",
      "\n",
      "    accuracy                           0.51      1078\n",
      "   macro avg       0.45      0.50      0.35      1078\n",
      "weighted avg       0.45      0.51      0.36      1078\n",
      "\n",
      "Accuracy List Length : 1899\n",
      "XCHANGING.NS   2018\n",
      "Accuracy: 0.5543710021321961\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       519\n",
      "           1       0.56      0.01      0.02       419\n",
      "\n",
      "    accuracy                           0.55       938\n",
      "   macro avg       0.55      0.50      0.37       938\n",
      "weighted avg       0.55      0.55      0.40       938\n",
      "\n",
      "Accuracy List Length : 1900\n",
      "XELPMOC.NS   2019\n",
      "Accuracy: 0.5158730158730159\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.95      0.67       132\n",
      "           1       0.40      0.03      0.06       120\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.46      0.49      0.37       252\n",
      "weighted avg       0.46      0.52      0.38       252\n",
      "\n",
      "Accuracy List Length : 1901\n",
      "XPROINDIA.NS   2020\n",
      "Accuracy: 0.5350966429298067\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.69       535\n",
      "           1       0.32      0.02      0.03       448\n",
      "\n",
      "    accuracy                           0.54       983\n",
      "   macro avg       0.43      0.49      0.36       983\n",
      "weighted avg       0.44      0.54      0.39       983\n",
      "\n",
      "Accuracy List Length : 1902\n",
      "YASHO.NS   2022\n",
      "Accuracy: 0.38461538461538464\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.20      0.27        15\n",
      "           1       0.37      0.64      0.47        11\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.40      0.42      0.37        26\n",
      "weighted avg       0.40      0.38      0.35        26\n",
      "\n",
      "Accuracy List Length : 1903\n",
      "YATHARTH.NS   2023\n",
      "Accuracy: 0.5517241379310345\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.23      0.32        13\n",
      "           1       0.57      0.81      0.67        16\n",
      "\n",
      "    accuracy                           0.55        29\n",
      "   macro avg       0.53      0.52      0.49        29\n",
      "weighted avg       0.54      0.55      0.51        29\n",
      "\n",
      "Accuracy List Length : 1904\n",
      "YATRA.NS   2024\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.65        12\n",
      "           1       0.33      0.10      0.15        10\n",
      "\n",
      "    accuracy                           0.50        22\n",
      "   macro avg       0.43      0.47      0.40        22\n",
      "weighted avg       0.44      0.50      0.42        22\n",
      "\n",
      "Accuracy List Length : 1905\n",
      "YESBANK.NS   2025\n",
      "Accuracy: 0.5233441910966341\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.96      0.68       484\n",
      "           1       0.47      0.04      0.08       437\n",
      "\n",
      "    accuracy                           0.52       921\n",
      "   macro avg       0.50      0.50      0.38       921\n",
      "weighted avg       0.50      0.52      0.39       921\n",
      "\n",
      "Accuracy List Length : 1906\n",
      "YUKEN.NS   2026\n",
      "Accuracy: 0.464\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.98      0.63        57\n",
      "           1       0.67      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.46       125\n",
      "   macro avg       0.56      0.51      0.34       125\n",
      "weighted avg       0.57      0.46      0.32       125\n",
      "\n",
      "Accuracy List Length : 1907\n",
      "ZAGGLE.NS   2027\n",
      "Accuracy: 0.5454545454545454\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.23      0.38        13\n",
      "           1       0.47      1.00      0.64         9\n",
      "\n",
      "    accuracy                           0.55        22\n",
      "   macro avg       0.74      0.62      0.51        22\n",
      "weighted avg       0.78      0.55      0.48        22\n",
      "\n",
      "Accuracy List Length : 1908\n",
      "ZEEL.NS   2028\n",
      "Accuracy: 0.46146703806870937\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.07      0.12       591\n",
      "           1       0.45      0.94      0.61       486\n",
      "\n",
      "    accuracy                           0.46      1077\n",
      "   macro avg       0.52      0.50      0.37      1077\n",
      "weighted avg       0.52      0.46      0.34      1077\n",
      "\n",
      "Accuracy List Length : 1909\n",
      "ZEELEARN.NS   2029\n",
      "Accuracy: 0.5475460122699386\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71       359\n",
      "           1       0.40      0.01      0.03       293\n",
      "\n",
      "    accuracy                           0.55       652\n",
      "   macro avg       0.47      0.50      0.37       652\n",
      "weighted avg       0.48      0.55      0.40       652\n",
      "\n",
      "Accuracy List Length : 1910\n",
      "ZEEMEDIA.NS   2030\n",
      "Accuracy: 0.5667600373482726\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       610\n",
      "           1       0.45      0.03      0.06       461\n",
      "\n",
      "    accuracy                           0.57      1071\n",
      "   macro avg       0.51      0.50      0.39      1071\n",
      "weighted avg       0.52      0.57      0.43      1071\n",
      "\n",
      "Accuracy List Length : 1911\n",
      "ZENITHEXPO.NS   2031\n",
      "Accuracy: 0.7168059424326834\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.99      0.83       774\n",
      "           1       0.44      0.03      0.05       303\n",
      "\n",
      "    accuracy                           0.72      1077\n",
      "   macro avg       0.58      0.51      0.44      1077\n",
      "weighted avg       0.64      0.72      0.61      1077\n",
      "\n",
      "Accuracy List Length : 1912\n",
      "ZENITHSTL.NS   2032\n",
      "Accuracy: 0.6670673076923077\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       555\n",
      "           1       0.50      0.03      0.05       277\n",
      "\n",
      "    accuracy                           0.67       832\n",
      "   macro avg       0.59      0.51      0.43       832\n",
      "weighted avg       0.61      0.67      0.55       832\n",
      "\n",
      "Accuracy List Length : 1913\n",
      "ZENSARTECH.NS   2033\n",
      "Accuracy: 0.5292479108635098\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       574\n",
      "           1       0.36      0.01      0.02       503\n",
      "\n",
      "    accuracy                           0.53      1077\n",
      "   macro avg       0.44      0.50      0.35      1077\n",
      "weighted avg       0.45      0.53      0.38      1077\n",
      "\n",
      "Accuracy List Length : 1914\n",
      "ZENTEC.NS   2034\n",
      "Accuracy: 0.5746606334841629\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73       258\n",
      "           1       0.36      0.03      0.05       184\n",
      "\n",
      "    accuracy                           0.57       442\n",
      "   macro avg       0.47      0.50      0.39       442\n",
      "weighted avg       0.49      0.57      0.44       442\n",
      "\n",
      "Accuracy List Length : 1915\n",
      "ZFCVINDIA.NS   2035\n",
      "Accuracy: 0.5322128851540616\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69       572\n",
      "           1       0.43      0.01      0.02       499\n",
      "\n",
      "    accuracy                           0.53      1071\n",
      "   macro avg       0.48      0.50      0.36      1071\n",
      "weighted avg       0.48      0.53      0.38      1071\n",
      "\n",
      "Accuracy List Length : 1916\n",
      "ZIMLAB.NS   2036\n",
      "Accuracy: 0.5625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71        35\n",
      "           1       0.67      0.07      0.12        29\n",
      "\n",
      "    accuracy                           0.56        64\n",
      "   macro avg       0.61      0.52      0.42        64\n",
      "weighted avg       0.61      0.56      0.44        64\n",
      "\n",
      "Accuracy List Length : 1917\n",
      "ZODIAC.NS   2037\n",
      "Accuracy: 0.5246636771300448\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.08      0.15       112\n",
      "           1       0.51      0.97      0.67       111\n",
      "\n",
      "    accuracy                           0.52       223\n",
      "   macro avg       0.63      0.53      0.41       223\n",
      "weighted avg       0.63      0.52      0.41       223\n",
      "\n",
      "Accuracy List Length : 1918\n",
      "ZODIACLOTH.NS   2038\n",
      "Accuracy: 0.5673166202414113\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72       609\n",
      "           1       0.62      0.01      0.02       468\n",
      "\n",
      "    accuracy                           0.57      1077\n",
      "   macro avg       0.60      0.50      0.37      1077\n",
      "weighted avg       0.59      0.57      0.42      1077\n",
      "\n",
      "Accuracy List Length : 1919\n",
      "ZOMATO.NS   2039\n",
      "Accuracy: 0.5615384615384615\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.15      0.24        60\n",
      "           1       0.56      0.91      0.69        70\n",
      "\n",
      "    accuracy                           0.56       130\n",
      "   macro avg       0.58      0.53      0.47       130\n",
      "weighted avg       0.58      0.56      0.48       130\n",
      "\n",
      "Accuracy List Length : 1920\n",
      "ZOTA.NS   2040\n",
      "Accuracy: 0.5029585798816568\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.67       170\n",
      "           1       0.50      0.02      0.03       168\n",
      "\n",
      "    accuracy                           0.50       338\n",
      "   macro avg       0.50      0.50      0.35       338\n",
      "weighted avg       0.50      0.50      0.35       338\n",
      "\n",
      "Accuracy List Length : 1921\n",
      "ZUARI.NS   2041\n",
      "Accuracy: 0.5385996409335727\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       308\n",
      "           1       0.25      0.02      0.03       249\n",
      "\n",
      "    accuracy                           0.54       557\n",
      "   macro avg       0.40      0.49      0.36       557\n",
      "weighted avg       0.41      0.54      0.40       557\n",
      "\n",
      "Accuracy List Length : 1922\n",
      "ZUARIIND.NS   2042\n",
      "Accuracy: 0.5116063138347261\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.99      0.67       547\n",
      "           1       0.64      0.02      0.03       530\n",
      "\n",
      "    accuracy                           0.51      1077\n",
      "   macro avg       0.58      0.50      0.35      1077\n",
      "weighted avg       0.58      0.51      0.36      1077\n",
      "\n",
      "Accuracy List Length : 1923\n",
      "ZYDUSLIFE.NS   2043\n",
      "Accuracy: 0.5037783375314862\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.96      0.66       602\n",
      "           1       0.48      0.04      0.08       589\n",
      "\n",
      "    accuracy                           0.50      1191\n",
      "   macro avg       0.49      0.50      0.37      1191\n",
      "weighted avg       0.49      0.50      0.37      1191\n",
      "\n",
      "Accuracy List Length : 1924\n",
      "ZYDUSWELL.NS   2044\n",
      "Accuracy: 0.5134370579915134\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.88      0.65       364\n",
      "           1       0.49      0.13      0.20       343\n",
      "\n",
      "    accuracy                           0.51       707\n",
      "   macro avg       0.51      0.50      0.43       707\n",
      "weighted avg       0.51      0.51      0.43       707\n",
      "\n",
      "Accuracy List Length : 1925\n"
     ]
    }
   ],
   "source": [
    "for index, row in stock_list.iloc[1658:].iterrows():\n",
    "    stock=row['SYMBOL']+\".NS\"\n",
    "    data=fetch_data(stock)\n",
    "    data=preprocess_data(data)\n",
    "    model_dir=f\"./modelsNS/{stock}/\"\n",
    "    if not os.path.exists(model_dir):\n",
    "                os.mkdir(model_dir)\n",
    "    accuracy_list.to_csv(\"Accuracy_Data.csv\",index=False)\n",
    "    # Define features (X) and target (y)\n",
    "    features = data[['open-close', 'high-low', 'Volume', 'is_quarter_end','SMA_10','SMA_50',\"SMA_200\",'EMA_10','EMA_50',\"EMA_200\"]]\n",
    "    target = np.where(data['Close'].shift(-1) > data['Close'], 1, 0)  # 1 foSr price increase, 0 otherwise\n",
    "    if not data.empty:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # Initialize and train the model\n",
    "        model = SVC(kernel='poly', probability=True, random_state=42)  \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the scaler and model for reuse\n",
    "        \n",
    "        dump(scaler, f\"{model_dir}{stock}_scaler.joblib\")\n",
    "        dump(model, f\"{model_dir}{stock}_predictor.joblib\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        print(stock,\" \",index)\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        stock_accuracy=pd.DataFrame({\"Symbol\":[row['SYMBOL']],\"Accuracy\":[accuracy_score(y_test,y_pred)*100]})\n",
    "        accuracy_list=pd.concat([accuracy_list,stock_accuracy])\n",
    "        print(\"Accuracy List Length :\",len(accuracy_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02bae035-00ac-4d50-8f0d-e2eadfec3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list.to_csv(\"Accuracy_Data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d531d-1620-4f00-9a1c-e1069a43b488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
