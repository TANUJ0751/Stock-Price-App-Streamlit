{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e61db464-5580-482d-a984-f553ce0a122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump,load\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def fetch_data(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(period=\"max\")  # Fetch 5 years of data\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0817f7a2-988f-40ed-b25a-be8733531885",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list=pd.read_csv('NSE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "421a56ca-0add-461d-a395-17c359f3d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data):\n",
    "    # Feature engineering: Create relevant columns\n",
    "    data['open-close'] = data['Open'] - data['Close']\n",
    "    data['high-low'] = data['High'] - data['Low']\n",
    "    data['price-change'] = data['Close'].pct_change()\n",
    "    data['is_quarter_end'] = np.where(data['Date'].dt.month % 3 == 0, 1, 0)\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['SMA_200'] = data['Close'].rolling(window=200).mean()\n",
    "    data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "    data['EMA_200'] = data['Close'].ewm(span=200, adjust=False).mean()\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['Dividends', 'Stock Splits'], axis=1, errors='ignore')\n",
    "    data.dropna(inplace=True)  # Handle missing values\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fac55b-fd50-41b1-9597-3cc75a65a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20MICRONS.NS\n",
      "Accuracy: 0.5473684210526316\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71       423\n",
      "           1       0.18      0.01      0.01       337\n",
      "\n",
      "    accuracy                           0.55       760\n",
      "   macro avg       0.37      0.49      0.36       760\n",
      "weighted avg       0.39      0.55      0.40       760\n",
      "\n",
      "21STCENMGM.NS\n",
      "Accuracy: 0.5230263157894737\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.97      0.67       152\n",
      "           1       0.71      0.08      0.14       152\n",
      "\n",
      "    accuracy                           0.52       304\n",
      "   macro avg       0.61      0.52      0.41       304\n",
      "weighted avg       0.61      0.52      0.41       304\n",
      "\n",
      "360ONE.NS\n",
      "Accuracy: 0.43243243243243246\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.91      0.59       101\n",
      "           1       0.31      0.03      0.06       121\n",
      "\n",
      "    accuracy                           0.43       222\n",
      "   macro avg       0.37      0.47      0.33       222\n",
      "weighted avg       0.37      0.43      0.30       222\n",
      "\n",
      "3IINFOLTD.NS\n",
      "Accuracy: 0.5965665236051502\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75       554\n",
      "           1       0.67      0.01      0.02       378\n",
      "\n",
      "    accuracy                           0.60       932\n",
      "   macro avg       0.63      0.50      0.38       932\n",
      "weighted avg       0.62      0.60      0.45       932\n",
      "\n",
      "3MINDIA.NS\n",
      "Accuracy: 0.5431754874651811\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.70       586\n",
      "           1       0.45      0.01      0.02       491\n",
      "\n",
      "    accuracy                           0.54      1077\n",
      "   macro avg       0.50      0.50      0.36      1077\n",
      "weighted avg       0.50      0.54      0.39      1077\n",
      "\n",
      "3PLAND.NS\n",
      "Accuracy: 0.6548223350253807\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.79       506\n",
      "           1       0.71      0.06      0.11       282\n",
      "\n",
      "    accuracy                           0.65       788\n",
      "   macro avg       0.68      0.52      0.45       788\n",
      "weighted avg       0.67      0.65      0.54       788\n",
      "\n",
      "5PAISA.NS\n",
      "Accuracy: 0.5480769230769231\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       173\n",
      "           1       0.40      0.03      0.05       139\n",
      "\n",
      "    accuracy                           0.55       312\n",
      "   macro avg       0.48      0.50      0.38       312\n",
      "weighted avg       0.48      0.55      0.41       312\n",
      "\n",
      "63MOONS.NS\n",
      "Accuracy: 0.5324675324675324\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.96      0.69       490\n",
      "           1       0.52      0.05      0.09       434\n",
      "\n",
      "    accuracy                           0.53       924\n",
      "   macro avg       0.53      0.50      0.39       924\n",
      "weighted avg       0.53      0.53      0.41       924\n",
      "\n",
      "A2ZINFRA.NS\n",
      "Accuracy: 0.5843558282208589\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.73       382\n",
      "           1       0.47      0.03      0.05       270\n",
      "\n",
      "    accuracy                           0.58       652\n",
      "   macro avg       0.53      0.50      0.39       652\n",
      "weighted avg       0.54      0.58      0.45       652\n",
      "\n",
      "AAATECH.NS\n",
      "Accuracy: 0.5853658536585366\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73        94\n",
      "           1       0.62      0.07      0.13        70\n",
      "\n",
      "    accuracy                           0.59       164\n",
      "   macro avg       0.60      0.52      0.43       164\n",
      "weighted avg       0.60      0.59      0.47       164\n",
      "\n",
      "AAKASH.NS\n",
      "Accuracy: 0.6411149825783972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.78       182\n",
      "           1       0.62      0.05      0.09       105\n",
      "\n",
      "    accuracy                           0.64       287\n",
      "   macro avg       0.63      0.52      0.43       287\n",
      "weighted avg       0.64      0.64      0.52       287\n",
      "\n",
      "AAREYDRUGS.NS\n",
      "Accuracy: 0.5625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.72        74\n",
      "           1       0.25      0.02      0.03        54\n",
      "\n",
      "    accuracy                           0.56       128\n",
      "   macro avg       0.41      0.49      0.38       128\n",
      "weighted avg       0.44      0.56      0.43       128\n",
      "\n",
      "AARON.NS\n",
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.68       145\n",
      "           1       0.47      0.06      0.11       125\n",
      "\n",
      "    accuracy                           0.53       270\n",
      "   macro avg       0.50      0.50      0.40       270\n",
      "weighted avg       0.51      0.53      0.42       270\n",
      "\n",
      "AARTECH.NS\n",
      "Accuracy: 0.5454545454545454\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57        19\n",
      "           1       0.47      0.57      0.52        14\n",
      "\n",
      "    accuracy                           0.55        33\n",
      "   macro avg       0.55      0.55      0.54        33\n",
      "weighted avg       0.56      0.55      0.55        33\n",
      "\n",
      "AARTIDRUGS.NS\n",
      "Accuracy: 0.504930966469428\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67       515\n",
      "           1       0.42      0.02      0.03       499\n",
      "\n",
      "    accuracy                           0.50      1014\n",
      "   macro avg       0.46      0.50      0.35      1014\n",
      "weighted avg       0.46      0.50      0.35      1014\n",
      "\n",
      "AARTIIND.NS\n",
      "Accuracy: 0.474025974025974\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63       521\n",
      "           1       0.41      0.04      0.08       557\n",
      "\n",
      "    accuracy                           0.47      1078\n",
      "   macro avg       0.44      0.49      0.35      1078\n",
      "weighted avg       0.44      0.47      0.34      1078\n",
      "\n",
      "AARTIPHARM.NS\n",
      "Accuracy: 0.4727272727272727\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.83      0.62        29\n",
      "           1       0.29      0.08      0.12        26\n",
      "\n",
      "    accuracy                           0.47        55\n",
      "   macro avg       0.39      0.45      0.37        55\n",
      "weighted avg       0.40      0.47      0.39        55\n",
      "\n",
      "AARTISURF.NS\n",
      "Accuracy: 0.5274725274725275\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69        97\n",
      "           1       0.33      0.01      0.02        85\n",
      "\n",
      "    accuracy                           0.53       182\n",
      "   macro avg       0.43      0.50      0.36       182\n",
      "weighted avg       0.44      0.53      0.38       182\n",
      "\n",
      "AARVEEDEN.NS\n",
      "Accuracy: 0.5357561547479485\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.99      0.70       456\n",
      "           1       0.56      0.01      0.02       397\n",
      "\n",
      "    accuracy                           0.54       853\n",
      "   macro avg       0.55      0.50      0.36       853\n",
      "weighted avg       0.54      0.54      0.38       853\n",
      "\n",
      "AARVI.NS\n",
      "Accuracy: 0.5993690851735016\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75       193\n",
      "           1       0.20      0.01      0.02       124\n",
      "\n",
      "    accuracy                           0.60       317\n",
      "   macro avg       0.40      0.49      0.38       317\n",
      "weighted avg       0.45      0.60      0.46       317\n",
      "\n",
      "AAVAS.NS\n",
      "Accuracy: 0.4962686567164179\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.85      0.64       139\n",
      "           1       0.42      0.12      0.18       129\n",
      "\n",
      "    accuracy                           0.50       268\n",
      "   macro avg       0.46      0.48      0.41       268\n",
      "weighted avg       0.46      0.50      0.42       268\n",
      "\n",
      "ABAN.NS\n",
      "Accuracy: 0.5294117647058824\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.98      0.69       568\n",
      "           1       0.48      0.02      0.04       503\n",
      "\n",
      "    accuracy                           0.53      1071\n",
      "   macro avg       0.50      0.50      0.36      1071\n",
      "weighted avg       0.51      0.53      0.38      1071\n",
      "\n",
      "ABB.NS\n",
      "Accuracy: 0.5166975881261595\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.97      0.67       548\n",
      "           1       0.62      0.05      0.08       530\n",
      "\n",
      "    accuracy                           0.52      1078\n",
      "   macro avg       0.56      0.51      0.38      1078\n",
      "weighted avg       0.56      0.52      0.38      1078\n",
      "\n",
      "ABBOTINDIA.NS\n",
      "Accuracy: 0.6688432835820896\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80       704\n",
      "           1       0.69      0.07      0.12       368\n",
      "\n",
      "    accuracy                           0.67      1072\n",
      "   macro avg       0.68      0.52      0.46      1072\n",
      "weighted avg       0.67      0.67      0.56      1072\n",
      "\n",
      "ABCAPITAL.NS\n",
      "Accuracy: 0.5186335403726708\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.95      0.66       158\n",
      "           1       0.68      0.10      0.18       164\n",
      "\n",
      "    accuracy                           0.52       322\n",
      "   macro avg       0.59      0.53      0.42       322\n",
      "weighted avg       0.59      0.52      0.42       322\n",
      "\n",
      "ABFRL.NS\n",
      "Accuracy: 0.5123809523809524\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.92      0.67       287\n",
      "           1       0.20      0.03      0.04       238\n",
      "\n",
      "    accuracy                           0.51       525\n",
      "   macro avg       0.37      0.47      0.36       525\n",
      "weighted avg       0.38      0.51      0.39       525\n",
      "\n",
      "ABINFRA.NS\n",
      "Accuracy: 0.7807017543859649\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88       179\n",
      "           1       0.40      0.04      0.07        49\n",
      "\n",
      "    accuracy                           0.78       228\n",
      "   macro avg       0.59      0.51      0.47       228\n",
      "weighted avg       0.71      0.78      0.70       228\n",
      "\n",
      "ABMINTLLTD.NS\n",
      "Accuracy: 0.7052631578947368\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       268\n",
      "           1       0.50      0.07      0.12       112\n",
      "\n",
      "    accuracy                           0.71       380\n",
      "   macro avg       0.61      0.52      0.47       380\n",
      "weighted avg       0.65      0.71      0.62       380\n",
      "\n",
      "ABREL.NS\n",
      "Accuracy: 0.530367231638418\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.96      0.68       741\n",
      "           1       0.58      0.05      0.10       675\n",
      "\n",
      "    accuracy                           0.53      1416\n",
      "   macro avg       0.55      0.51      0.39      1416\n",
      "weighted avg       0.55      0.53      0.40      1416\n",
      "\n",
      "ABSLAMC.NS\n",
      "Accuracy: 0.5210084033613446\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        61\n",
      "           1       1.00      0.02      0.03        58\n",
      "\n",
      "    accuracy                           0.52       119\n",
      "   macro avg       0.76      0.51      0.36       119\n",
      "weighted avg       0.75      0.52      0.37       119\n",
      "\n",
      "ACC.NS\n",
      "Accuracy: 0.5051067780872794\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.05      0.09       541\n",
      "           1       0.50      0.97      0.66       536\n",
      "\n",
      "    accuracy                           0.51      1077\n",
      "   macro avg       0.55      0.51      0.37      1077\n",
      "weighted avg       0.55      0.51      0.37      1077\n",
      "\n",
      "ACCELYA.NS\n",
      "Accuracy: 0.5431754874651811\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70       589\n",
      "           1       0.38      0.01      0.02       488\n",
      "\n",
      "    accuracy                           0.54      1077\n",
      "   macro avg       0.46      0.50      0.36      1077\n",
      "weighted avg       0.47      0.54      0.39      1077\n",
      "\n",
      "ACCURACY.NS\n",
      "Accuracy: 0.6071428571428571\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.75       174\n",
      "           1       0.17      0.01      0.02       106\n",
      "\n",
      "    accuracy                           0.61       280\n",
      "   macro avg       0.39      0.49      0.39       280\n",
      "weighted avg       0.45      0.61      0.48       280\n",
      "\n",
      "ACE.NS\n",
      "Accuracy: 0.5168408826945412\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       447\n",
      "           1       0.45      0.02      0.04       414\n",
      "\n",
      "    accuracy                           0.52       861\n",
      "   macro avg       0.48      0.50      0.36       861\n",
      "weighted avg       0.49      0.52      0.37       861\n",
      "\n",
      "ACEINTEG.NS\n",
      "Accuracy: 0.8054711246200608\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       270\n",
      "           1       0.27      0.05      0.09        59\n",
      "\n",
      "    accuracy                           0.81       329\n",
      "   macro avg       0.55      0.51      0.49       329\n",
      "weighted avg       0.73      0.81      0.75       329\n",
      "\n",
      "ACI.NS\n",
      "Accuracy: 0.515625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.85      0.64        33\n",
      "           1       0.50      0.16      0.24        31\n",
      "\n",
      "    accuracy                           0.52        64\n",
      "   macro avg       0.51      0.50      0.44        64\n",
      "weighted avg       0.51      0.52      0.45        64\n",
      "\n",
      "ACL.NS\n",
      "Accuracy: 0.6094224924012158\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75       401\n",
      "           1       0.50      0.02      0.04       257\n",
      "\n",
      "    accuracy                           0.61       658\n",
      "   macro avg       0.56      0.50      0.40       658\n",
      "weighted avg       0.57      0.61      0.48       658\n",
      "\n",
      "ACLGATI.NS\n",
      "Accuracy: 0.5727590221187427\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73       490\n",
      "           1       0.67      0.01      0.02       369\n",
      "\n",
      "    accuracy                           0.57       859\n",
      "   macro avg       0.62      0.50      0.37       859\n",
      "weighted avg       0.61      0.57      0.42       859\n",
      "\n",
      "ADANIENSOL.NS\n",
      "Accuracy: 0.4444444444444444\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.71      0.62        17\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.27      0.35      0.31        27\n",
      "weighted avg       0.34      0.44      0.39        27\n",
      "\n",
      "ADANIENT.NS\n",
      "Accuracy: 0.5102040816326531\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.06      0.11       525\n",
      "           1       0.51      0.93      0.66       553\n",
      "\n",
      "    accuracy                           0.51      1078\n",
      "   macro avg       0.50      0.50      0.39      1078\n",
      "weighted avg       0.50      0.51      0.39      1078\n",
      "\n",
      "ADANIGREEN.NS\n",
      "Accuracy: 0.5865724381625441\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.29      0.39       131\n",
      "           1       0.58      0.84      0.69       152\n",
      "\n",
      "    accuracy                           0.59       283\n",
      "   macro avg       0.60      0.57      0.54       283\n",
      "weighted avg       0.59      0.59      0.55       283\n",
      "\n",
      "ADANIPORTS.NS\n",
      "Accuracy: 0.5068493150684932\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.05      0.08       399\n",
      "           1       0.51      0.96      0.66       404\n",
      "\n",
      "    accuracy                           0.51       803\n",
      "   macro avg       0.53      0.50      0.37       803\n",
      "weighted avg       0.53      0.51      0.37       803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in stock_list.iloc[:].iterrows():\n",
    "    stock=row['SYMBOL']+\".NS\"\n",
    "    data=fetch_data(stock)\n",
    "    data=preprocess_data(data)\n",
    "    model_dir=f\"./modelsNS/{stock}/\"\n",
    "    if not os.path.exists(model_dir):\n",
    "                os.mkdir(model_dir)\n",
    "    # Define features (X) and target (y)\n",
    "    features = data[['open-close', 'high-low', 'Volume', 'is_quarter_end','SMA_10','SMA_50',\"SMA_200\",'EMA_10','EMA_50',\"EMA_200\"]]\n",
    "    target = np.where(data['Close'].shift(-1) > data['Close'], 1, 0)  # 1 foSr price increase, 0 otherwise\n",
    "    if not data.empty:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # Initialize and train the model\n",
    "        model = SVC(kernel='poly', probability=True, random_state=42)  \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the scaler and model for reuse\n",
    "        \n",
    "        dump(scaler, f\"{model_dir}{stock}_scaler.joblib\")\n",
    "        dump(model, f\"{model_dir}{stock}_predictor.joblib\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        print(stock)\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff60dec-481a-4eb4-85e0-6cc0c8e8997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da5d2c-225b-44a2-b3d8-f611ec3085f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da4031-af98-4709-a04b-a0dcef208f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04672655-1b1b-495a-aa0c-698f26445bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeed251-d8e3-45ea-b59b-bb192be290f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load saved model and scaler\n",
    "scaler1 = load('scaler.joblib')\n",
    "model1 = load('stock_price_predictor.joblib')\n",
    "\n",
    "# Example new data\n",
    "new_data = [[5.0, -2.0, 1e7, 0,77.53,77.1,76.1,78.05,77.29,76.49]]  # Replace with actual feature values\n",
    "new_data_scaled = scaler1.transform(new_data)\n",
    "prediction = model1.predict(new_data_scaled)\n",
    "probability = model1.predict_proba(new_data_scaled)\n",
    "\n",
    "print(\"Prediction:\", \"Up\" if prediction[0] == 1 else \"Down\")\n",
    "print(\"Probability of Price Increase:\", probability[0][1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
